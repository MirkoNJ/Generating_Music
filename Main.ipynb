{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#% reset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import midi_musical_matrix\n",
    "import data\n",
    "import multi_training\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "from MyFunctions import Input_Kernel, LSTM_TimeWise_Training_Layer, LSTM_NoteWise_Layer, Loss_Function\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Fugue1 (1)\n",
      "Loaded Fugue1\n",
      "Skip bad file =  Fugue11\n",
      "Loaded Fugue12 (1)\n",
      "Skip bad file =  Fugue12\n",
      "Skip bad file =  Fugue13\n",
      "Skip bad file =  Fugue15\n",
      "Loaded Fugue16\n",
      "Loaded Fugue17\n",
      "Loaded Fugue18\n",
      "Skip bad file =  Fugue19\n",
      "Loaded Fugue2\n",
      "Loaded Fugue20\n",
      "Loaded Fugue22\n",
      "Loaded Fugue23\n",
      "Loaded Fugue24\n",
      "Loaded Fugue3 (1)\n",
      "Loaded Fugue3\n",
      "Loaded Fugue4\n",
      "Loaded Fugue5 (1)\n",
      "Loaded Fugue5\n",
      "Skip bad file =  Fugue6\n",
      "Loaded Fugue7 (1)\n",
      "Loaded Fugue7\n",
      "Loaded Fugue8 (1)\n",
      "Loaded Fugue8\n",
      "Loaded Fugue9 (1)\n",
      "Loaded Fugue9\n",
      "\n",
      "Number of training pieces =  22\n",
      "Sample of State Input Batch: shape =  (15, 78, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "# Import All Training Data\n",
    "# Convert Entire Music .MIDI set to list of musical 'pieces'\n",
    "# During training runs, getPieceBatch will return a tensor for Note_State_Batch, and corresponding Note_State_Expand\n",
    "# Note_State_Expand will be fed into the graph input, and Note_State_Batch will be used for the loss function.\n",
    "\n",
    "# Import Midi files to list\n",
    "Working_Directory = os.getcwd()\n",
    "Training_Midi_Folder = Working_Directory + \"/Midi_Files/Bach_Handpicked\"\n",
    "max_time_steps = 256 # only files atleast this many 16th note steps are saved\n",
    "\n",
    "practice_batch_size = 15\n",
    "practice_num_timesteps = 128\n",
    "\n",
    "\n",
    "training_pieces = multi_training.loadPieces(Training_Midi_Folder, max_time_steps)\n",
    "print('')\n",
    "print('Number of training pieces = ', len(training_pieces))\n",
    "\n",
    "# Generate sample Note State Matrix for dimension measurement and numerical checking purposes\n",
    "# (Using external code to generate the Note State Matrix but using our own NoteInputForm (as defined in author's code) function\n",
    "_, sample_state = multi_training.getPieceBatch(training_pieces, practice_batch_size, practice_num_timesteps)\n",
    "sample_state = np.array(sample_state)\n",
    "sample_state = np.swapaxes(sample_state, axis1=1, axis2=2)\n",
    "print('Sample of State Input Batch: shape = ', sample_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note_State_Batch Placeholder Shape =  (?, 78, ?, 2)\n",
      "Note_State_Expand output Shape =  (?, 78, ?, 80)\n"
     ]
    }
   ],
   "source": [
    "# Beginning of Model Graph:\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#input_size = sample_state.shape[-1]\n",
    "num_notes = sample_state.shape[1]\n",
    "\n",
    "\n",
    "#place holder inputs\n",
    "# num_batches and num_time steps are variable lengths.  These values do not affect the model parameters\n",
    "# Dimension(0) =  num_batches. Dimension(2) = num_time_steps\n",
    "\n",
    "#final_t_sample_run = np.zeros((batch_size, num_notes, 1, 2)) #start every batch with zero previous input\n",
    "\n",
    "\n",
    "        \n",
    "Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 2])\n",
    "#prev_t_sample = tf.placeholder(dtype=tf.float32, shape=[None, num_notes,1,2])\n",
    "time_init = tf.placeholder(dtype=tf.int32, shape=())\n",
    "#Generates expanded tensor input to LSTM-timewise layer\n",
    "Note_State_Expand = Input_Kernel(Note_State_Batch, Midi_low=24, Midi_high=101, time_init=time_init)\n",
    "\n",
    "print('Note_State_Batch Placeholder Shape = ', Note_State_Batch.get_shape())\n",
    "print('Note_State_Expand output Shape = ', Note_State_Expand.get_shape())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_expand shape =  (15, 78, 128, 80)\n",
      "MIDI note_0, t_0 =  [ 24.]\n",
      "MIDI note_1, t_0 =  [ 25.]\n",
      "MIDI note_2, t_0 =  [ 26.]\n",
      "MIDI note_0, t_0 =  [ 24.]\n",
      "MIDI note_0, t_1 =  [ 24.]\n",
      "MIDI note_0, t_29 =  [ 24.]\n",
      "\n",
      "pitchclass note_0, t_0 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_1, t_0 =  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_11, t_0 =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "pitchclass note_0, t_0 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_0, t_1 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_0, t_29 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "sample state local vicinity =  [[0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "calculated vicinity note_45, t_29 =  [ 0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "calculated context note_45, t_29 =  [ 1.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "actual all note plays at, t_29 =  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0]\n",
      "\n",
      "beat note_0, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_1, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_2, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_0, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_0, t_1 =  [ 0.  1.  0.  0.]\n",
      "beat note_0, t_29 =  [ 0.  1.  1.  1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Input Kernel on sample data\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sample_expand = sess.run(Note_State_Expand, feed_dict={Note_State_Batch: sample_state, time_init: 1})\n",
    "\n",
    "\n",
    "\n",
    "#check MIDI note\n",
    "print('sample_expand shape = ', sample_expand.shape)\n",
    "print('MIDI note_0, t_0 = ', sample_expand[0,0,0,[0]]) \n",
    "print('MIDI note_1, t_0 = ', sample_expand[0,1,0,[0]])  \n",
    "print('MIDI note_2, t_0 = ', sample_expand[0,2,0,[0]]) \n",
    "\n",
    "print('MIDI note_0, t_0 = ', sample_expand[0,0,0,[0]]) \n",
    "print('MIDI note_0, t_1 = ', sample_expand[0,0,1,[0]])  \n",
    "print('MIDI note_0, t_29 = ', sample_expand[0,0,29,[0]]) \n",
    "print('') \n",
    "\n",
    "#check pitchclass\n",
    "print('pitchclass note_0, t_0 = ', sample_expand[0,0,0,1:13]) \n",
    "print('pitchclass note_1, t_0 = ', sample_expand[0,1,0,1:13])  \n",
    "print('pitchclass note_11, t_0 = ', sample_expand[0,11,0,1:13]) \n",
    "\n",
    "print('pitchclass note_0, t_0 = ', sample_expand[0,0,0,1:13]) \n",
    "print('pitchclass note_0, t_1 = ', sample_expand[0,0,1,1:13])  \n",
    "print('pitchclass note_0, t_29 = ', sample_expand[0,0,29,1:13]) \n",
    "print('') \n",
    "\n",
    "#check vicinity\n",
    "print('sample state local vicinity = ', sample_state[0,33:58,29,:])\n",
    "print('calculated vicinity note_45, t_29 = ', sample_expand[0,45,29,13:63])\n",
    "print('')\n",
    "\n",
    "#check  context\n",
    "print('calculated context note_45, t_29 = ', sample_expand[0,45,29,63:75])\n",
    "print('actual all note plays at, t_29 = ', sample_state[0,:,29,0])\n",
    "print('')\n",
    "\n",
    "#check beat\n",
    "print('beat note_0, t_0 = ', sample_expand[0,0,0,75:79]) \n",
    "print('beat note_1, t_0 = ', sample_expand[0,1,0,75:79])  \n",
    "print('beat note_2, t_0 = ', sample_expand[0,2,0,75:79]) \n",
    "\n",
    "print('beat note_0, t_0 = ', sample_expand[0,0,0,75:79]) \n",
    "print('beat note_0, t_1 = ', sample_expand[0,0,1,75:79])  \n",
    "print('beat note_0, t_29 = ', sample_expand[0,0,29,75:79]) \n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-wise output shape =  (?, 78, ?, 10)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#lSTM Time Wise Training Graph \n",
    "#tf.reset_default_graph()\n",
    "#Note_State_Expand = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 80])\n",
    "#Note_State_Expand_val = np.ones((10,78,128,80))\n",
    "\n",
    "num_t_units=[10]\n",
    "output_keep_prob = tf.placeholder(dtype=tf.float32, shape=())\n",
    "\n",
    "# Generate initial state (at t=0) placeholder\n",
    "timewise_state=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    timewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]]) #None = batch_size * num_notes\n",
    "    timewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]])\n",
    "    timewise_state.append(LSTMStateTuple(timewise_h, timewise_c))\n",
    "\n",
    "timewise_state=tuple(timewise_state)\n",
    "\n",
    "\n",
    "timewise_out, timewise_state_out = LSTM_TimeWise_Training_Layer(input_data=Note_State_Expand, state_init=timewise_state, output_keep_prob=output_keep_prob)\n",
    "\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())\n",
    "print(len(timewise_state_out))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_out shape =  (?, 78, ?, 2)\n",
      "generated samples shape =  (?, 78, ?, 2)\n"
     ]
    }
   ],
   "source": [
    "#LSTM Note Wise Graph\n",
    "#tf.reset_default_graph()\n",
    "#num_notes=78\n",
    "#Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 2])\n",
    "#Note_State_Batch_val = np.zeros((10,78,128,2))\n",
    "#timewise_out = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 50])\n",
    "#output_keep_prob=1\n",
    "num_n_units = [10]\n",
    "\n",
    "# Generate initial state (at n=0) placeholder\n",
    "notewise_state=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    notewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]]) #None = batch_size * num_timesteps\n",
    "    notewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]])\n",
    "    notewise_state.append(LSTMStateTuple(notewise_h, notewise_c))\n",
    "\n",
    "notewise_state=tuple(notewise_state)\n",
    "\n",
    "\n",
    "y_out, note_gen_out = LSTM_NoteWise_Layer(timewise_out, state_init=notewise_state, output_keep_prob=output_keep_prob)\n",
    "\n",
    "p_out = tf.sigmoid(y_out)\n",
    "print('y_out shape = ', y_out.get_shape())\n",
    "print('generated samples shape = ', note_gen_out.get_shape())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test for Notewise-LSTM\n",
    "#num_timesteps=5\n",
    "#batch_size=7\n",
    "#timewise_out_val = np.random.randn(batch_size, 78, num_timesteps, 50)*10\n",
    "\n",
    "notewise_state_val=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    c_n = np.zeros((batch_size*num_timesteps, num_n_units[i])) #start every batch with zero state in LSTM time cells\n",
    "    h_n = np.zeros((batch_size*num_timesteps, num_n_units[i]))\n",
    "    notewise_state_val.append(LSTMStateTuple(h_n, c_n))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    feed_dict = {timewise_out: timewise_out_val, notewise_state: notewise_state_val}\n",
    "    y_out_run, note_gen_out_run, p_out_run = sess.run([y_out, note_gen_out, p_out], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57015109  0.37799257]\n",
      " [ 0.56050414  0.28474435]\n",
      " [ 0.81526381  0.51652592]\n",
      " [ 0.51000327  0.47562233]\n",
      " [ 0.45483524  0.42948249]\n",
      " [ 0.41522047  0.58680546]\n",
      " [ 0.34573999  0.39803994]\n",
      " [ 0.64800113  0.63286799]\n",
      " [ 0.58131123  0.69331133]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(p_out_run[0,1:10,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note_State_Batch:  Tensor(\"Placeholder:0\", shape=(?, 78, ?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Loss Function and Optimizer\n",
    "\n",
    "#y_out_val = np.random.randn(1, 78, 128, 2, 2)*5\n",
    "\n",
    "\n",
    "loss, log_likelihood = Loss_Function(Note_State_Batch, y_out)\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate = 1).minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test for Loss Graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cross_entropy_out, loss_out = sess.run([cross_entropy, loss], feed_dict={Note_State_Batch: Note_State_Batch_val, timewise_out: timewise_out_val, notewise_state: notewise_state_val})\n",
    "\n",
    "    \n",
    "print('cross entropy out shape = ', cross_entropy_out.shape)\n",
    "print('loss = ', loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining new batch of pieces\n",
      "epoch =  0 ; loss =  0.3628 ; scaled log likelihood =  -28.2984\n",
      "error =  [49131 25488]\n",
      "num_1 =  [3945 1554]\n",
      "epoch =  1 ; loss =  0.361815 ; scaled log likelihood =  -28.2215\n",
      "epoch =  2 ; loss =  0.361527 ; scaled log likelihood =  -28.1991\n",
      "epoch =  3 ; loss =  0.361019 ; scaled log likelihood =  -28.1595\n",
      "epoch =  4 ; loss =  0.360616 ; scaled log likelihood =  -28.1281\n",
      "epoch =  5 ; loss =  0.360094 ; scaled log likelihood =  -28.0873\n",
      "epoch =  6 ; loss =  0.359951 ; scaled log likelihood =  -28.0762\n",
      "epoch =  7 ; loss =  0.359442 ; scaled log likelihood =  -28.0365\n",
      "epoch =  8 ; loss =  0.359015 ; scaled log likelihood =  -28.0031\n",
      "epoch =  9 ; loss =  0.358496 ; scaled log likelihood =  -27.9627\n",
      "epoch =  10 ; loss =  0.358354 ; scaled log likelihood =  -27.9516\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "N_epochs = 10\n",
    "loss_hist=[]\n",
    "restore_model_name = None\n",
    "save_model_name = 'Practice_sigmoid'\n",
    "batch_size = 10\n",
    "num_timesteps = 128\n",
    "keep_prob=.75\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # try to restore the pre_trained\n",
    "    if restore_model_name is not None:\n",
    "        print(\"Load the model from: {}\".format(restore_model_name))\n",
    "        saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "    # Initial States\n",
    "    timewise_state_val=[]\n",
    "    for i in range(len(num_t_units)):\n",
    "        c_t = np.zeros((batch_size*num_notes, num_t_units[i])) #start every batch with zero state in LSTM time cells\n",
    "        h_t = np.zeros((batch_size*num_notes, num_t_units[i]))\n",
    "        timewise_state_val.append(LSTMStateTuple(h_t, c_t))\n",
    "        \n",
    "    notewise_state_val=[]\n",
    "    for i in range(len(num_n_units)):\n",
    "        c_n = np.zeros((batch_size*num_timesteps, num_n_units[i])) #start every batch with zero state in LSTM time cells\n",
    "        h_n = np.zeros((batch_size*num_timesteps, num_n_units[i]))\n",
    "        notewise_state_val.append(LSTMStateTuple(h_n, c_n))\n",
    "    \n",
    "  \n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(N_epochs+1):\n",
    "        \n",
    "        #Generate random batch of training data        \n",
    "        if (epoch % 100 == 0):         \n",
    "            print('Obtaining new batch of pieces')\n",
    "            _, batch_input_state = multi_training.getPieceBatch(training_pieces, batch_size, num_timesteps) # not using their 'convolution' filter\n",
    "            batch_input_state = np.array(batch_input_state)\n",
    "            batch_input_state = np.swapaxes(batch_input_state, axis1=1, axis2=2)           \n",
    "            #print('sum = ',sum(sum(sum(sum(batch_input_state)))) )\n",
    "        \n",
    "        \"\"\"\n",
    "        print('Note_State_Batch shape = ', Note_State_Batch.get_shape())\n",
    "        print('batch_input_state shape = ', batch_input_state.shape)\n",
    "        print('')\n",
    "        print('timewise_state shape = ', Note_State_Batch.get_shape())\n",
    "        print('timewise_state_val shape = ', batch_input_state.shape)      \n",
    "        print('')\n",
    "        print('notewise_state shape = ', Note_State_Batch.get_shape())\n",
    "        print('notewise_state_val shape = ', batch_input_state.shape)\n",
    "        ('')\n",
    "        print('time_init shape = ', time_init.get_shape())\n",
    "        \"\"\"\n",
    "    \n",
    "        feed_dict = {Note_State_Batch: batch_input_state, timewise_state: timewise_state_val, notewise_state: notewise_state_val, time_init: 0, output_keep_prob: keep_prob}\n",
    "        #try:\n",
    "        loss_run, log_likelihood_run, _, note_gen_out_run = sess.run([loss, log_likelihood, optimizer, note_gen_out], feed_dict=feed_dict)\n",
    "        #except:\n",
    "        #   save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "        #    print(\"Model saved in file: %s\" % save_path)\n",
    "        print('epoch = ', epoch, '; loss = ', loss_run, '; scaled log likelihood = ', log_likelihood_run)\n",
    "        loss_hist.append(loss_run)\n",
    "        \n",
    "        if (epoch % 500 ==0):\n",
    "            error = sum(sum(sum(abs(batch_input_state[:,:,1:,:] - note_gen_out_run[:,:,:-1,:]))))\n",
    "            num_1 = sum(sum(sum(abs(batch_input_state[:,:,1:,:]))))\n",
    "            print('error = ', error)\n",
    "            print('num_1 = ', num_1)\n",
    "        if (epoch % 100 == 0) & (epoch > 0):\n",
    "            save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "    #save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "    #print(\" Final Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error =  [3520 1723]\n",
      "num_1 =  [3824 1511]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#print(square_error/mag)\n",
    "#print('Actual input = ', batch_input_state[:,:,1,:])\n",
    "#print('Output predicting this input = ', note_gen_out_run[:,:,0,:])\n",
    "error = sum(sum(sum(abs(batch_input_state[:,:,1:,:] - note_gen_out_run[:,:,:-1,:]))))\n",
    "num_1 = sum(sum(sum(abs(batch_input_state[:,:,1:,:]))))\n",
    "print('error = ', error)\n",
    "print('num_1 = ', num_1)\n",
    "#for v in range(len(tf.trainable_variables())):\n",
    "#    print(tf.trainable_variables()[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1000 % 100 == 0) & (1000 > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoQU7iIiRej/A01GyEVaTcavAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f230a261be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist, label=\"Loss History\")\n",
    "plt.legend()\n",
    "plt.show\n",
    "len(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: Practice_fb_artic\n",
      "INFO:tensorflow:Restoring parameters from model/Practice_fb_artic\n",
      "Timestep =  0\n",
      "Timestep =  50\n",
      "Timestep =  100\n",
      "Timestep =  150\n",
      "Timestep =  200\n",
      "Timestep =  250\n",
      "(5, 78, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# Music Generation\n",
    "# input = initial note vector\n",
    "# for t = 1:Tsong\n",
    "#    input --> input kernel\n",
    "#    run through 1 'call' of Model LSTM with present parameters / states\n",
    "#    run through note-wise LSTM block as normally done to produce vector of generated samples\n",
    "#    input = generated samples\n",
    "#    music_sequence.append(input)\n",
    "\n",
    "# store batch of music sequences in .MIDI files\n",
    "\n",
    "\n",
    "#Load Model\n",
    "restore_model_name = 'Practice_fb_artic'\n",
    "\n",
    "#Length of generated music\n",
    "T_gen = 16*16\n",
    "batch_gen_size = 5\n",
    "keep_prob = 1\n",
    "\n",
    "# start with initial Note_State_Batch with 't' dimension = 1 (can still a batch of samples run in parallel)\n",
    "notes_gen_initial = np.zeros((batch_gen_size, num_notes, 1,2))\n",
    "\n",
    "# Initial States\n",
    "notes_gen = notes_gen_initial\n",
    "    \n",
    "timewise_state_val=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    c = np.zeros((batch_gen_size*num_notes, num_t_units[i])) #start first time step with zero state in LSTM time cells\n",
    "    h = np.zeros((batch_gen_size*num_notes, num_t_units[i]))\n",
    "    timewise_state_val.append(LSTMStateTuple(h, c))\n",
    "        \n",
    "notewise_state_val=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    c = np.zeros((batch_gen_size*1, num_n_units[i])) #start every batch with zero state in LSTM time cells\n",
    "    h = np.zeros((batch_gen_size*1, num_n_units[i]))\n",
    "    notewise_state_val.append(LSTMStateTuple(h, c))\n",
    "        \n",
    "notes_gen_arr=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    print(\"Load the model from: {}\".format(restore_model_name))\n",
    "    saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "\n",
    "    for t in range(T_gen):\n",
    "        feed_dict = {Note_State_Batch: notes_gen, timewise_state: timewise_state_val, notewise_state: notewise_state_val, time_init: t % 16, output_keep_prob: keep_prob}    \n",
    "        timewise_state_val, notes_gen = np.squeeze(sess.run([timewise_state_out, note_gen_out], feed_dict = feed_dict), axis=2)\n",
    "        #print('notes_gen shape = ', notes_gen.shape)\n",
    "        #notes_gen = np.squeeze(notes_gen, axis=2)\n",
    "        notes_gen_arr.append(np.squeeze(notes_gen))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if t % 50 == 0:\n",
    "            print('Timestep = ', t)\n",
    "    \n",
    "notes_gen_out = np.stack(notes_gen_arr, axis=2)\n",
    "print(notes_gen_out.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 256, 78, 2)\n"
     ]
    }
   ],
   "source": [
    "# Save Generate Notes to .MIDI file\n",
    "\n",
    "notes_gen_out = np.swapaxes(notes_gen_out, axis1=1, axis2=2)\n",
    "print(notes_gen_out.shape)\n",
    "#_, notes_gen_out = Utils.multi_training.getPieceBatch(training_pieces)\n",
    "\n",
    "\n",
    "#print(test_batch.shape)\n",
    "for iter in range(4):\n",
    "    file = 'Generated_Midi_Files/Practice_fb_artic' + str(iter)\n",
    "    midi_out = midi_musical_matrix.noteStateMatrixToMidi(notes_gen_out[iter,:,:,:], name=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to Experiment with:\n",
    "- different T length or variable length T from batch-to-batch for training\n",
    "- categorize music, either through (unsupervised) clustering or (supervised) labeled music folders.  For clustering, the model would possibly find 'k' 'centroids' in an unsupervised manner each with its own music distribution, so during the music generation stage, 1 of these centroids would be selected for a piece of music.  \n",
    "- use encoder to reduce dimensionality of each note vector (vector of 79 notes in 1 time step), similiar to encoding the words from the tweets in homework 3 (i.e. there are restricted combinations of notes that can be played simultaneously)\n",
    "- more advanced sampling/exploring for training/music generation.  This may help prevent the algorithm from getting 'stuck' on a chord, or "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
