{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#% reset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import midi_musical_matrix\n",
    "import data\n",
    "import multi_training\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "from MyFunctions import Input_Kernel, LSTM_TimeWise_Training_Layer, LSTM_NoteWise_Layer, Loss_Function\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip bad file =  Fugue12\n",
      "Loaded schub5\n",
      "Loaded tri2\n",
      "Loaded sinfon1 (1)\n",
      "Loaded 01Prelude\n",
      "Loaded Prelude12\n",
      "Loaded BRAND3\n",
      "Loaded Fugue8\n",
      "Loaded Fugue22\n",
      "Loaded Prelude21\n",
      "Loaded 04Bourree\n",
      "Loaded BSGJG_H\n",
      "Loaded Fugue18\n",
      "Loaded 11Jesu\n",
      "Loaded Fugue5\n",
      "Loaded sinfon4\n",
      "Skip bad file =  Fugue19\n",
      "Loaded Fugue4\n",
      "Loaded unfin\n",
      "Loaded can4\n",
      "Loaded Fugue17\n",
      "Loaded 04Prelude\n",
      "Loaded sinfon12\n",
      "Skip bad file =  Prelude20\n",
      "Loaded dou2\n",
      "Loaded prefug5\n",
      "Loaded prefug3\n",
      "Loaded gig1\n",
      "Loaded catech6\n",
      "Loaded prefug7\n",
      "Loaded BRAND43\n",
      "Loaded 08Freueteuch\n",
      "Loaded dou1\n",
      "Loaded Fugue9 (1)\n",
      "Loaded Fugue7 (1)\n",
      "Loaded toccata1\n",
      "Loaded sinfon1\n",
      "Loaded BRAND51\n",
      "Loaded invent13\n",
      "Loaded sinfon14\n",
      "Loaded 01Allemande\n",
      "Loaded Fugue3\n",
      "Skip bad file =  Prelude13\n",
      "Loaded Prelude5\n",
      "Loaded cnt1\n",
      "Loaded sinfon3\n",
      "Loaded cnt3\n",
      "Loaded 09Ermuntredich\n",
      "Loaded invent7\n",
      "Loaded Prelude8 (1)\n",
      "Loaded invent5\n",
      "Loaded cap2\n",
      "Loaded 15ChristlaginTode\n",
      "Loaded BRAND53\n",
      "Loaded sin2\n",
      "Loaded Prelude3 (1)\n",
      "Loaded Prelude2 (1)\n",
      "Loaded invent14\n",
      "Loaded 10AustieferNot\n",
      "Loaded inver2\n",
      "Loaded 13Alleinzudir\n",
      "Loaded Fugue7\n",
      "Loaded BSGJG_K\n",
      "Loaded BRAND1\n",
      "Loaded Fugue16\n",
      "Loaded BRAND52\n",
      "Loaded invent15\n",
      "Loaded invent11\n",
      "Loaded schub6\n",
      "Loaded Prelude23\n",
      "Loaded catech10\n",
      "Skip bad file =  Prelude15\n",
      "Loaded fuguegm\n",
      "Loaded invent1\n",
      "Loaded invent2\n",
      "Loaded catech8\n",
      "Loaded Fugue3 (1)\n",
      "Loaded prefug8\n",
      "Loaded trio3a\n",
      "Loaded pre1\n",
      "Loaded Prelude16\n",
      "Loaded Prelude12 (1)\n",
      "Loaded cnt1 (1)\n",
      "Loaded Fugue12 (1)\n",
      "Loaded prefug1\n",
      "Loaded sinfon8\n",
      "Loaded Prelude2\n",
      "Skip bad file =  Prelude19\n",
      "Loaded BSGJG_G\n",
      "Loaded Fugue5 (1)\n",
      "Loaded Prelude10\n",
      "Skip bad file =  Fugue13\n",
      "Skip bad file =  Prelude14\n",
      "Loaded Prelude7\n",
      "Loaded 14OHerreGott\n",
      "Skip bad file =  Fugue15\n",
      "Loaded Fugue1\n",
      "Loaded tri1\n",
      "Skip bad file =  Fugue6\n",
      "Loaded 04Allemande\n",
      "Loaded BSGJG_I\n",
      "Loaded orgel19\n",
      "Loaded cnt2\n",
      "Loaded Fugue1 (1)\n",
      "Loaded Prelude1 (1)\n",
      "Loaded BSGJG_B\n",
      "Loaded prefug2\n",
      "Loaded catech7\n",
      "Loaded Prelude1\n",
      "Loaded 02Ichdankdir\n",
      "Loaded Fugue20\n",
      "Loaded sinfon9\n",
      "Loaded Prelude22\n",
      "Loaded catech9\n",
      "Skip bad file =  Fugue11\n",
      "Loaded Fugue8 (1)\n",
      "Loaded reg2\n",
      "Loaded 05AnWasserflussen\n",
      "Loaded toccata2\n",
      "Loaded Fugue23\n",
      "Loaded Prelude6\n",
      "Loaded catech1\n",
      "Loaded Fugue2\n",
      "Skip bad file =  Prelude24\n",
      "Loaded reg1\n",
      "Loaded Fugue24\n",
      "Loaded mir2\n",
      "Loaded BSGJG_J\n",
      "Loaded Fugue9\n",
      "Loaded fuguecm\n",
      "Loaded inver1\n",
      "\n",
      "Number of training pieces =  119\n",
      "Sample of State Input Batch: shape =  (15, 78, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "# Import All Training Data\n",
    "# Convert Entire Music .MIDI set to list of musical 'pieces'\n",
    "# During training runs, getPieceBatch will return a tensor for Note_State_Batch, and corresponding Note_State_Expand\n",
    "# Note_State_Expand will be fed into the graph input, and Note_State_Batch will be used for the loss function.\n",
    "\n",
    "# Import Midi files to list\n",
    "Working_Directory = os.getcwd()\n",
    "Training_Midi_Folder = Working_Directory + \"/Midi_Files/Bach\"\n",
    "max_time_steps = 256 # only files atleast this many 16th note steps are saved\n",
    "\n",
    "practice_batch_size = 15\n",
    "practice_num_timesteps = 128\n",
    "\n",
    "\n",
    "training_pieces = multi_training.loadPieces(Training_Midi_Folder, max_time_steps)\n",
    "print('')\n",
    "print('Number of training pieces = ', len(training_pieces))\n",
    "\n",
    "# Generate sample Note State Matrix for dimension measurement and numerical checking purposes\n",
    "# (Using external code to generate the Note State Matrix but using our own NoteInputForm (as defined in author's code) function\n",
    "_, sample_state = multi_training.getPieceBatch(training_pieces, practice_batch_size, practice_num_timesteps)\n",
    "sample_state = np.array(sample_state)\n",
    "sample_state = np.swapaxes(sample_state, axis1=1, axis2=2)\n",
    "print('Sample of State Input Batch: shape = ', sample_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note_State_Batch Placeholder Shape =  (?, 78, ?, 2)\n",
      "Note_State_Expand output Shape =  (?, 78, ?, 80)\n"
     ]
    }
   ],
   "source": [
    "# Beginning of Model Graph:\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#input_size = sample_state.shape[-1]\n",
    "num_notes = sample_state.shape[1]\n",
    "\n",
    "\n",
    "#place holder inputs\n",
    "# num_batches and num_time steps are variable lengths.  These values do not affect the model parameters\n",
    "# Dimension(0) =  num_batches. Dimension(2) = num_time_steps\n",
    "\n",
    "#final_t_sample_run = np.zeros((batch_size, num_notes, 1, 2)) #start every batch with zero previous input\n",
    "\n",
    "\n",
    "        \n",
    "Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 2])\n",
    "#prev_t_sample = tf.placeholder(dtype=tf.float32, shape=[None, num_notes,1,2])\n",
    "time_init = tf.placeholder(dtype=tf.int32, shape=())\n",
    "#Generates expanded tensor input to LSTM-timewise layer\n",
    "Note_State_Expand = Input_Kernel(Note_State_Batch, Midi_low=24, Midi_high=101, time_init=time_init)\n",
    "\n",
    "print('Note_State_Batch Placeholder Shape = ', Note_State_Batch.get_shape())\n",
    "print('Note_State_Expand output Shape = ', Note_State_Expand.get_shape())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_expand shape =  (15, 78, 128, 80)\n",
      "MIDI note_0, t_0 =  [ 24.]\n",
      "MIDI note_1, t_0 =  [ 25.]\n",
      "MIDI note_2, t_0 =  [ 26.]\n",
      "MIDI note_0, t_0 =  [ 24.]\n",
      "MIDI note_0, t_1 =  [ 24.]\n",
      "MIDI note_0, t_29 =  [ 24.]\n",
      "\n",
      "pitchclass note_0, t_0 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_1, t_0 =  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_11, t_0 =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "pitchclass note_0, t_0 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_0, t_1 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_0, t_29 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "sample state local vicinity =  [[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "calculated vicinity note_45, t_29 =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "calculated context note_45, t_29 =  [  4.04136706e-08  -1.76295600e-08   9.99999404e-01   3.41732687e-08\n",
      "   1.47644073e-07   9.99999702e-01   9.37714191e-08   2.97936076e-09\n",
      "  -8.20579373e-08   9.99999881e-01   1.49011612e-08   8.97341010e-08]\n",
      "actual all note plays at, t_29 =  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0]\n",
      "\n",
      "beat note_0, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_1, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_2, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_0, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_0, t_1 =  [ 0.  1.  0.  0.]\n",
      "beat note_0, t_29 =  [ 0.  1.  1.  1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Input Kernel on sample data\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sample_expand = sess.run(Note_State_Expand, feed_dict={Note_State_Batch: sample_state, time_init: 1})\n",
    "\n",
    "\n",
    "\n",
    "#check MIDI note\n",
    "print('sample_expand shape = ', sample_expand.shape)\n",
    "print('MIDI note_0, t_0 = ', sample_expand[0,0,0,[0]]) \n",
    "print('MIDI note_1, t_0 = ', sample_expand[0,1,0,[0]])  \n",
    "print('MIDI note_2, t_0 = ', sample_expand[0,2,0,[0]]) \n",
    "\n",
    "print('MIDI note_0, t_0 = ', sample_expand[0,0,0,[0]]) \n",
    "print('MIDI note_0, t_1 = ', sample_expand[0,0,1,[0]])  \n",
    "print('MIDI note_0, t_29 = ', sample_expand[0,0,29,[0]]) \n",
    "print('') \n",
    "\n",
    "#check pitchclass\n",
    "print('pitchclass note_0, t_0 = ', sample_expand[0,0,0,1:13]) \n",
    "print('pitchclass note_1, t_0 = ', sample_expand[0,1,0,1:13])  \n",
    "print('pitchclass note_11, t_0 = ', sample_expand[0,11,0,1:13]) \n",
    "\n",
    "print('pitchclass note_0, t_0 = ', sample_expand[0,0,0,1:13]) \n",
    "print('pitchclass note_0, t_1 = ', sample_expand[0,0,1,1:13])  \n",
    "print('pitchclass note_0, t_29 = ', sample_expand[0,0,29,1:13]) \n",
    "print('') \n",
    "\n",
    "#check vicinity\n",
    "print('sample state local vicinity = ', sample_state[0,33:58,29,:])\n",
    "print('calculated vicinity note_45, t_29 = ', sample_expand[0,45,29,13:63])\n",
    "print('')\n",
    "\n",
    "#check  context\n",
    "print('calculated context note_45, t_29 = ', sample_expand[0,45,29,63:75])\n",
    "print('actual all note plays at, t_29 = ', sample_state[0,:,29,0])\n",
    "print('')\n",
    "\n",
    "#check beat\n",
    "print('beat note_0, t_0 = ', sample_expand[0,0,0,75:79]) \n",
    "print('beat note_1, t_0 = ', sample_expand[0,1,0,75:79])  \n",
    "print('beat note_2, t_0 = ', sample_expand[0,2,0,75:79]) \n",
    "\n",
    "print('beat note_0, t_0 = ', sample_expand[0,0,0,75:79]) \n",
    "print('beat note_0, t_1 = ', sample_expand[0,0,1,75:79])  \n",
    "print('beat note_0, t_29 = ', sample_expand[0,0,29,75:79]) \n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-wise output shape =  (?, 78, ?, 200)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#lSTM Time Wise Training Graph \n",
    "#tf.reset_default_graph()\n",
    "#Note_State_Expand = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 80])\n",
    "#Note_State_Expand_val = np.ones((10,78,128,80))\n",
    "\n",
    "num_t_units=[300,200]\n",
    "output_keep_prob = tf.placeholder(dtype=tf.float32, shape=())\n",
    "\n",
    "# Generate initial state (at t=0) placeholder\n",
    "timewise_state=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    timewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]]) #None = batch_size * num_notes\n",
    "    timewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]])\n",
    "    timewise_state.append(LSTMStateTuple(timewise_h, timewise_c))\n",
    "\n",
    "timewise_state=tuple(timewise_state)\n",
    "\n",
    "\n",
    "timewise_out, timewise_state_out = LSTM_TimeWise_Training_Layer(input_data=Note_State_Expand, state_init=timewise_state, output_keep_prob=output_keep_prob)\n",
    "\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())\n",
    "print(len(timewise_state_out))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_out shape =  (?, 78, ?, 2, 2)\n",
      "generated samples shape =  (?, 78, ?, 2)\n"
     ]
    }
   ],
   "source": [
    "#LSTM Note Wise Graph\n",
    "#tf.reset_default_graph()\n",
    "#timewise_out = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 50])\n",
    "\n",
    "num_n_units = [100,50]\n",
    "\n",
    "# Generate initial state (at n=0) placeholder\n",
    "notewise_state=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    notewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]]) #None = batch_size * num_timesteps\n",
    "    notewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]])\n",
    "    notewise_state.append(LSTMStateTuple(notewise_h, notewise_c))\n",
    "\n",
    "notewise_state=tuple(notewise_state)\n",
    "\n",
    "\n",
    "y_out, note_gen_out = LSTM_NoteWise_Layer(timewise_out, state_init=notewise_state, output_keep_prob=output_keep_prob)\n",
    "\n",
    "\n",
    "print('y_out shape = ', y_out.get_shape())\n",
    "print('generated samples shape = ', note_gen_out.get_shape())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_align shape = :  (?, ?, ?, ?, ?)\n",
      "Note_State_Batch_align shape = :  (?, ?, ?, ?)\n"
     ]
    }
   ],
   "source": [
    "# Loss Function and Optimizer\n",
    "\n",
    "#y_out_val = np.random.randn(1, 78, 128, 2, 2)*5\n",
    "\n",
    "\n",
    "loss, cross_entropy = Loss_Function(Note_State_Batch, y_out)\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate = 1).minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run(tf.global_variables_initializer())\n",
    "#    cross_entropy_out, loss_out = sess.run([cross_entropy, loss], feed_dict={y_out: y_out_val, Note_State_Batch: batch_input_state})\n",
    "#print('cross entropy shape = ', cross_entropy_out.shape)\n",
    "#print('loss = ', loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining new batch of pieces\n",
      "epoch =  0 ; loss =  0.698937\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  1 ; loss =  0.671152\n",
      "epoch =  2 ; loss =  0.656158\n",
      "epoch =  3 ; loss =  0.64548\n",
      "epoch =  4 ; loss =  0.635729\n",
      "epoch =  5 ; loss =  0.62747\n",
      "epoch =  6 ; loss =  0.617929\n",
      "epoch =  7 ; loss =  0.608594\n",
      "epoch =  8 ; loss =  0.600378\n",
      "epoch =  9 ; loss =  0.592904\n",
      "epoch =  10 ; loss =  0.585964\n",
      "epoch =  11 ; loss =  0.579343\n",
      "epoch =  12 ; loss =  0.573893\n",
      "epoch =  13 ; loss =  0.566723\n",
      "epoch =  14 ; loss =  0.557982\n",
      "epoch =  15 ; loss =  0.54883\n",
      "epoch =  16 ; loss =  0.53913\n",
      "epoch =  17 ; loss =  0.531932\n",
      "epoch =  18 ; loss =  0.523768\n",
      "epoch =  19 ; loss =  0.517374\n",
      "epoch =  20 ; loss =  0.511961\n",
      "epoch =  21 ; loss =  0.507406\n",
      "epoch =  22 ; loss =  0.502359\n",
      "epoch =  23 ; loss =  0.495964\n",
      "epoch =  24 ; loss =  0.484505\n",
      "epoch =  25 ; loss =  0.474616\n",
      "epoch =  26 ; loss =  0.463629\n",
      "epoch =  27 ; loss =  0.454367\n",
      "epoch =  28 ; loss =  0.446123\n",
      "epoch =  29 ; loss =  0.437807\n",
      "epoch =  30 ; loss =  0.431238\n",
      "epoch =  31 ; loss =  0.421955\n",
      "epoch =  32 ; loss =  0.414678\n",
      "epoch =  33 ; loss =  0.407858\n",
      "epoch =  34 ; loss =  0.401131\n",
      "epoch =  35 ; loss =  0.394797\n",
      "epoch =  36 ; loss =  0.391366\n",
      "epoch =  37 ; loss =  0.390224\n",
      "epoch =  38 ; loss =  0.396185\n",
      "epoch =  39 ; loss =  0.403852\n",
      "epoch =  40 ; loss =  0.385319\n",
      "epoch =  41 ; loss =  0.368271\n",
      "epoch =  42 ; loss =  0.350875\n",
      "epoch =  43 ; loss =  0.342794\n",
      "epoch =  44 ; loss =  0.337888\n",
      "epoch =  45 ; loss =  0.331812\n",
      "epoch =  46 ; loss =  0.326085\n",
      "epoch =  47 ; loss =  0.320292\n",
      "epoch =  48 ; loss =  0.31367\n",
      "epoch =  49 ; loss =  0.310633\n",
      "epoch =  50 ; loss =  0.303661\n",
      "epoch =  51 ; loss =  0.299278\n",
      "epoch =  52 ; loss =  0.294544\n",
      "epoch =  53 ; loss =  0.288659\n",
      "epoch =  54 ; loss =  0.285769\n",
      "epoch =  55 ; loss =  0.28288\n",
      "epoch =  56 ; loss =  0.27757\n",
      "epoch =  57 ; loss =  0.273223\n",
      "epoch =  58 ; loss =  0.268999\n",
      "epoch =  59 ; loss =  0.266323\n",
      "epoch =  60 ; loss =  0.262338\n",
      "epoch =  61 ; loss =  0.259318\n",
      "epoch =  62 ; loss =  0.255358\n",
      "epoch =  63 ; loss =  0.253322\n",
      "epoch =  64 ; loss =  0.251197\n",
      "epoch =  65 ; loss =  0.250619\n",
      "epoch =  66 ; loss =  0.250188\n",
      "epoch =  67 ; loss =  0.245595\n",
      "epoch =  68 ; loss =  0.241808\n",
      "epoch =  69 ; loss =  0.2379\n",
      "epoch =  70 ; loss =  0.234357\n",
      "epoch =  71 ; loss =  0.230801\n",
      "epoch =  72 ; loss =  0.228989\n",
      "epoch =  73 ; loss =  0.226247\n",
      "epoch =  74 ; loss =  0.224642\n",
      "epoch =  75 ; loss =  0.222511\n",
      "epoch =  76 ; loss =  0.220567\n",
      "epoch =  77 ; loss =  0.2189\n",
      "epoch =  78 ; loss =  0.218518\n",
      "epoch =  79 ; loss =  0.215375\n",
      "epoch =  80 ; loss =  0.215297\n",
      "epoch =  81 ; loss =  0.213069\n",
      "epoch =  82 ; loss =  0.212104\n",
      "epoch =  83 ; loss =  0.209611\n",
      "epoch =  84 ; loss =  0.206934\n",
      "epoch =  85 ; loss =  0.206266\n",
      "epoch =  86 ; loss =  0.203472\n",
      "epoch =  87 ; loss =  0.201793\n",
      "epoch =  88 ; loss =  0.199889\n",
      "epoch =  89 ; loss =  0.199732\n",
      "epoch =  90 ; loss =  0.198748\n",
      "epoch =  91 ; loss =  0.196411\n",
      "epoch =  92 ; loss =  0.196363\n",
      "epoch =  93 ; loss =  0.195215\n",
      "epoch =  94 ; loss =  0.193809\n",
      "epoch =  95 ; loss =  0.193412\n",
      "epoch =  96 ; loss =  0.19215\n",
      "epoch =  97 ; loss =  0.189893\n",
      "epoch =  98 ; loss =  0.188718\n",
      "epoch =  99 ; loss =  0.189041\n",
      "Obtaining new batch of pieces\n",
      "epoch =  100 ; loss =  0.187749\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  101 ; loss =  0.186207\n",
      "epoch =  102 ; loss =  0.186364\n",
      "epoch =  103 ; loss =  0.18321\n",
      "epoch =  104 ; loss =  0.182845\n",
      "epoch =  105 ; loss =  0.182963\n",
      "epoch =  106 ; loss =  0.181965\n",
      "epoch =  107 ; loss =  0.181097\n",
      "epoch =  108 ; loss =  0.181115\n",
      "epoch =  109 ; loss =  0.179066\n",
      "epoch =  110 ; loss =  0.178503\n",
      "epoch =  111 ; loss =  0.177698\n",
      "epoch =  112 ; loss =  0.17759\n",
      "epoch =  113 ; loss =  0.176646\n",
      "epoch =  114 ; loss =  0.177408\n",
      "epoch =  115 ; loss =  0.175715\n",
      "epoch =  116 ; loss =  0.175042\n",
      "epoch =  117 ; loss =  0.17438\n",
      "epoch =  118 ; loss =  0.173911\n",
      "epoch =  119 ; loss =  0.172835\n",
      "epoch =  120 ; loss =  0.1729\n",
      "epoch =  121 ; loss =  0.172249\n",
      "epoch =  122 ; loss =  0.170767\n",
      "epoch =  123 ; loss =  0.171375\n",
      "epoch =  124 ; loss =  0.170393\n",
      "epoch =  125 ; loss =  0.168896\n",
      "epoch =  126 ; loss =  0.169379\n",
      "epoch =  127 ; loss =  0.167902\n",
      "epoch =  128 ; loss =  0.168311\n",
      "epoch =  129 ; loss =  0.168104\n",
      "epoch =  130 ; loss =  0.167319\n",
      "epoch =  131 ; loss =  0.167198\n",
      "epoch =  132 ; loss =  0.165892\n",
      "epoch =  133 ; loss =  0.165884\n",
      "epoch =  134 ; loss =  0.164973\n",
      "epoch =  135 ; loss =  0.164793\n",
      "epoch =  136 ; loss =  0.163997\n",
      "epoch =  137 ; loss =  0.163525\n",
      "epoch =  138 ; loss =  0.164376\n",
      "epoch =  139 ; loss =  0.164224\n",
      "epoch =  140 ; loss =  0.16282\n",
      "epoch =  141 ; loss =  0.161958\n",
      "epoch =  142 ; loss =  0.161834\n",
      "epoch =  143 ; loss =  0.161155\n",
      "epoch =  144 ; loss =  0.161268\n",
      "epoch =  145 ; loss =  0.161385\n",
      "epoch =  146 ; loss =  0.160385\n",
      "epoch =  147 ; loss =  0.15956\n",
      "epoch =  148 ; loss =  0.159662\n",
      "epoch =  149 ; loss =  0.160549\n",
      "epoch =  150 ; loss =  0.159255\n",
      "epoch =  151 ; loss =  0.159289\n",
      "epoch =  152 ; loss =  0.159069\n",
      "epoch =  153 ; loss =  0.158287\n",
      "epoch =  154 ; loss =  0.157589\n",
      "epoch =  155 ; loss =  0.156903\n",
      "epoch =  156 ; loss =  0.157696\n",
      "epoch =  157 ; loss =  0.157267\n",
      "epoch =  158 ; loss =  0.156379\n",
      "epoch =  159 ; loss =  0.156326\n",
      "epoch =  160 ; loss =  0.156568\n",
      "epoch =  161 ; loss =  0.155714\n",
      "epoch =  162 ; loss =  0.155716\n",
      "epoch =  163 ; loss =  0.154706\n",
      "epoch =  164 ; loss =  0.155051\n",
      "epoch =  165 ; loss =  0.153819\n",
      "epoch =  166 ; loss =  0.154745\n",
      "epoch =  167 ; loss =  0.153876\n",
      "epoch =  168 ; loss =  0.155095\n",
      "epoch =  169 ; loss =  0.153421\n",
      "epoch =  170 ; loss =  0.153369\n",
      "epoch =  171 ; loss =  0.153287\n",
      "epoch =  172 ; loss =  0.152273\n",
      "epoch =  173 ; loss =  0.152097\n",
      "epoch =  174 ; loss =  0.152599\n",
      "epoch =  175 ; loss =  0.152023\n",
      "epoch =  176 ; loss =  0.151665\n",
      "epoch =  177 ; loss =  0.151437\n",
      "epoch =  178 ; loss =  0.151029\n",
      "epoch =  179 ; loss =  0.150618\n",
      "epoch =  180 ; loss =  0.150572\n",
      "epoch =  181 ; loss =  0.150425\n",
      "epoch =  182 ; loss =  0.15019\n",
      "epoch =  183 ; loss =  0.150061\n",
      "epoch =  184 ; loss =  0.149742\n",
      "epoch =  185 ; loss =  0.149748\n",
      "epoch =  186 ; loss =  0.149267\n",
      "epoch =  187 ; loss =  0.148795\n",
      "epoch =  188 ; loss =  0.147945\n",
      "epoch =  189 ; loss =  0.149029\n",
      "epoch =  190 ; loss =  0.148331\n",
      "epoch =  191 ; loss =  0.149073\n",
      "epoch =  192 ; loss =  0.148256\n",
      "epoch =  193 ; loss =  0.148513\n",
      "epoch =  194 ; loss =  0.147938\n",
      "epoch =  195 ; loss =  0.148437\n",
      "epoch =  196 ; loss =  0.147179\n",
      "epoch =  197 ; loss =  0.146854\n",
      "epoch =  198 ; loss =  0.149045\n",
      "epoch =  199 ; loss =  0.146683\n",
      "Obtaining new batch of pieces\n",
      "epoch =  200 ; loss =  0.144049\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  201 ; loss =  0.143144\n",
      "epoch =  202 ; loss =  0.142563\n",
      "epoch =  203 ; loss =  0.143022\n",
      "epoch =  204 ; loss =  0.142678\n",
      "epoch =  205 ; loss =  0.143111\n",
      "epoch =  206 ; loss =  0.142756\n",
      "epoch =  207 ; loss =  0.142342\n",
      "epoch =  208 ; loss =  0.142256\n",
      "epoch =  209 ; loss =  0.141366\n",
      "epoch =  210 ; loss =  0.141635\n",
      "epoch =  211 ; loss =  0.140677\n",
      "epoch =  212 ; loss =  0.140189\n",
      "epoch =  213 ; loss =  0.142063\n",
      "epoch =  214 ; loss =  0.141615\n",
      "epoch =  215 ; loss =  0.140289\n",
      "epoch =  216 ; loss =  0.139826\n",
      "epoch =  217 ; loss =  0.13977\n",
      "epoch =  218 ; loss =  0.140457\n",
      "epoch =  219 ; loss =  0.139496\n",
      "epoch =  220 ; loss =  0.140094\n",
      "epoch =  221 ; loss =  0.138805\n",
      "epoch =  222 ; loss =  0.140145\n",
      "epoch =  223 ; loss =  0.138165\n",
      "epoch =  224 ; loss =  0.139337\n",
      "epoch =  225 ; loss =  0.138393\n",
      "epoch =  226 ; loss =  0.137729\n",
      "epoch =  227 ; loss =  0.137648\n",
      "epoch =  228 ; loss =  0.13846\n",
      "epoch =  229 ; loss =  0.137946\n",
      "epoch =  230 ; loss =  0.137403\n",
      "epoch =  231 ; loss =  0.13813\n",
      "epoch =  232 ; loss =  0.136183\n",
      "epoch =  233 ; loss =  0.137765\n",
      "epoch =  234 ; loss =  0.137118\n",
      "epoch =  235 ; loss =  0.138404\n",
      "epoch =  236 ; loss =  0.137397\n",
      "epoch =  237 ; loss =  0.137071\n",
      "epoch =  238 ; loss =  0.13697\n",
      "epoch =  239 ; loss =  0.137835\n",
      "epoch =  240 ; loss =  0.135872\n",
      "epoch =  241 ; loss =  0.13674\n",
      "epoch =  242 ; loss =  0.13613\n",
      "epoch =  243 ; loss =  0.135495\n",
      "epoch =  244 ; loss =  0.135216\n",
      "epoch =  245 ; loss =  0.135378\n",
      "epoch =  246 ; loss =  0.1353\n",
      "epoch =  247 ; loss =  0.135547\n",
      "epoch =  248 ; loss =  0.134678\n",
      "epoch =  249 ; loss =  0.133882\n",
      "epoch =  250 ; loss =  0.133656\n",
      "epoch =  251 ; loss =  0.134164\n",
      "epoch =  252 ; loss =  0.135409\n",
      "epoch =  253 ; loss =  0.133876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  254 ; loss =  0.13343\n",
      "epoch =  255 ; loss =  0.134758\n",
      "epoch =  256 ; loss =  0.133282\n",
      "epoch =  257 ; loss =  0.133847\n",
      "epoch =  258 ; loss =  0.133672\n",
      "epoch =  259 ; loss =  0.132541\n",
      "epoch =  260 ; loss =  0.132815\n",
      "epoch =  261 ; loss =  0.133178\n",
      "epoch =  262 ; loss =  0.133773\n",
      "epoch =  263 ; loss =  0.133146\n",
      "epoch =  264 ; loss =  0.132923\n",
      "epoch =  265 ; loss =  0.13197\n",
      "epoch =  266 ; loss =  0.131726\n",
      "epoch =  267 ; loss =  0.13154\n",
      "epoch =  268 ; loss =  0.131613\n",
      "epoch =  269 ; loss =  0.132383\n",
      "epoch =  270 ; loss =  0.132676\n",
      "epoch =  271 ; loss =  0.132553\n",
      "epoch =  272 ; loss =  0.131793\n",
      "epoch =  273 ; loss =  0.133055\n",
      "epoch =  274 ; loss =  0.131051\n",
      "epoch =  275 ; loss =  0.132008\n",
      "epoch =  276 ; loss =  0.131056\n",
      "epoch =  277 ; loss =  0.1313\n",
      "epoch =  278 ; loss =  0.13097\n",
      "epoch =  279 ; loss =  0.131294\n",
      "epoch =  280 ; loss =  0.130612\n",
      "epoch =  281 ; loss =  0.130779\n",
      "epoch =  282 ; loss =  0.130299\n",
      "epoch =  283 ; loss =  0.130376\n",
      "epoch =  284 ; loss =  0.131217\n",
      "epoch =  285 ; loss =  0.131007\n",
      "epoch =  286 ; loss =  0.131273\n",
      "epoch =  287 ; loss =  0.129949\n",
      "epoch =  288 ; loss =  0.130162\n",
      "epoch =  289 ; loss =  0.129865\n",
      "epoch =  290 ; loss =  0.13364\n",
      "epoch =  291 ; loss =  0.132042\n",
      "epoch =  292 ; loss =  0.130036\n",
      "epoch =  293 ; loss =  0.129298\n",
      "epoch =  294 ; loss =  0.128358\n",
      "epoch =  295 ; loss =  0.129722\n",
      "epoch =  296 ; loss =  0.128974\n",
      "epoch =  297 ; loss =  0.128397\n",
      "epoch =  298 ; loss =  0.12932\n",
      "epoch =  299 ; loss =  0.128995\n",
      "Obtaining new batch of pieces\n",
      "epoch =  300 ; loss =  0.133645\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  301 ; loss =  0.133896\n",
      "epoch =  302 ; loss =  0.134113\n",
      "epoch =  303 ; loss =  0.132117\n",
      "epoch =  304 ; loss =  0.133032\n",
      "epoch =  305 ; loss =  0.132832\n",
      "epoch =  306 ; loss =  0.133085\n",
      "epoch =  307 ; loss =  0.130678\n",
      "epoch =  308 ; loss =  0.130489\n",
      "epoch =  309 ; loss =  0.130874\n",
      "epoch =  310 ; loss =  0.130586\n",
      "epoch =  311 ; loss =  0.12933\n",
      "epoch =  312 ; loss =  0.130703\n",
      "epoch =  313 ; loss =  0.129571\n",
      "epoch =  314 ; loss =  0.130425\n",
      "epoch =  315 ; loss =  0.132002\n",
      "epoch =  316 ; loss =  0.129823\n",
      "epoch =  317 ; loss =  0.130661\n",
      "epoch =  318 ; loss =  0.129662\n",
      "epoch =  319 ; loss =  0.129284\n",
      "epoch =  320 ; loss =  0.129041\n",
      "epoch =  321 ; loss =  0.128787\n",
      "epoch =  322 ; loss =  0.12977\n",
      "epoch =  323 ; loss =  0.128276\n",
      "epoch =  324 ; loss =  0.128773\n",
      "epoch =  325 ; loss =  0.128051\n",
      "epoch =  326 ; loss =  0.127851\n",
      "epoch =  327 ; loss =  0.129145\n",
      "epoch =  328 ; loss =  0.129741\n",
      "epoch =  329 ; loss =  0.12873\n",
      "epoch =  330 ; loss =  0.127768\n",
      "epoch =  331 ; loss =  0.129305\n",
      "epoch =  332 ; loss =  0.129532\n",
      "epoch =  333 ; loss =  0.128125\n",
      "epoch =  334 ; loss =  0.127791\n",
      "epoch =  335 ; loss =  0.127648\n",
      "epoch =  336 ; loss =  0.128104\n",
      "epoch =  337 ; loss =  0.127098\n",
      "epoch =  338 ; loss =  0.128199\n",
      "epoch =  339 ; loss =  0.127293\n",
      "epoch =  340 ; loss =  0.128348\n",
      "epoch =  341 ; loss =  0.12772\n",
      "epoch =  342 ; loss =  0.127419\n",
      "epoch =  343 ; loss =  0.129195\n",
      "epoch =  344 ; loss =  0.127447\n",
      "epoch =  345 ; loss =  0.12698\n",
      "epoch =  346 ; loss =  0.125973\n",
      "epoch =  347 ; loss =  0.126548\n",
      "epoch =  348 ; loss =  0.12752\n",
      "epoch =  349 ; loss =  0.126548\n",
      "epoch =  350 ; loss =  0.126703\n",
      "epoch =  351 ; loss =  0.125244\n",
      "epoch =  352 ; loss =  0.126499\n",
      "epoch =  353 ; loss =  0.126563\n",
      "epoch =  354 ; loss =  0.127329\n",
      "epoch =  355 ; loss =  0.125573\n",
      "epoch =  356 ; loss =  0.12584\n",
      "epoch =  357 ; loss =  0.124741\n",
      "epoch =  358 ; loss =  0.127034\n",
      "epoch =  359 ; loss =  0.125493\n",
      "epoch =  360 ; loss =  0.125775\n",
      "epoch =  361 ; loss =  0.125554\n",
      "epoch =  362 ; loss =  0.1257\n",
      "epoch =  363 ; loss =  0.125671\n",
      "epoch =  364 ; loss =  0.126124\n",
      "epoch =  365 ; loss =  0.125787\n",
      "epoch =  366 ; loss =  0.125888\n",
      "epoch =  367 ; loss =  0.125196\n",
      "epoch =  368 ; loss =  0.125225\n",
      "epoch =  369 ; loss =  0.125424\n",
      "epoch =  370 ; loss =  0.128024\n",
      "epoch =  371 ; loss =  0.124515\n",
      "epoch =  372 ; loss =  0.124647\n",
      "epoch =  373 ; loss =  0.123823\n",
      "epoch =  374 ; loss =  0.123689\n",
      "epoch =  375 ; loss =  0.124418\n",
      "epoch =  376 ; loss =  0.12478\n",
      "epoch =  377 ; loss =  0.125831\n",
      "epoch =  378 ; loss =  0.123662\n",
      "epoch =  379 ; loss =  0.124476\n",
      "epoch =  380 ; loss =  0.123923\n",
      "epoch =  381 ; loss =  0.124442\n",
      "epoch =  382 ; loss =  0.12392\n",
      "epoch =  383 ; loss =  0.125023\n",
      "epoch =  384 ; loss =  0.124565\n",
      "epoch =  385 ; loss =  0.12429\n",
      "epoch =  386 ; loss =  0.12335\n",
      "epoch =  387 ; loss =  0.123662\n",
      "epoch =  388 ; loss =  0.123957\n",
      "epoch =  389 ; loss =  0.123656\n",
      "epoch =  390 ; loss =  0.122274\n",
      "epoch =  391 ; loss =  0.12383\n",
      "epoch =  392 ; loss =  0.123607\n",
      "epoch =  393 ; loss =  0.122989\n",
      "epoch =  394 ; loss =  0.124041\n",
      "epoch =  395 ; loss =  0.12423\n",
      "epoch =  396 ; loss =  0.123116\n",
      "epoch =  397 ; loss =  0.123524\n",
      "epoch =  398 ; loss =  0.122732\n",
      "epoch =  399 ; loss =  0.123177\n",
      "Obtaining new batch of pieces\n",
      "epoch =  400 ; loss =  0.120123\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  401 ; loss =  0.118576\n",
      "epoch =  402 ; loss =  0.118737\n",
      "epoch =  403 ; loss =  0.117905\n",
      "epoch =  404 ; loss =  0.118065\n",
      "epoch =  405 ; loss =  0.117512\n",
      "epoch =  406 ; loss =  0.117457\n",
      "epoch =  407 ; loss =  0.117558\n",
      "epoch =  408 ; loss =  0.117126\n",
      "epoch =  409 ; loss =  0.116814\n",
      "epoch =  410 ; loss =  0.116788\n",
      "epoch =  411 ; loss =  0.117214\n",
      "epoch =  412 ; loss =  0.11604\n",
      "epoch =  413 ; loss =  0.116885\n",
      "epoch =  414 ; loss =  0.11602\n",
      "epoch =  415 ; loss =  0.116262\n",
      "epoch =  416 ; loss =  0.116063\n",
      "epoch =  417 ; loss =  0.115431\n",
      "epoch =  418 ; loss =  0.115901\n",
      "epoch =  419 ; loss =  0.115499\n",
      "epoch =  420 ; loss =  0.115536\n",
      "epoch =  421 ; loss =  0.115178\n",
      "epoch =  422 ; loss =  0.115237\n",
      "epoch =  423 ; loss =  0.115575\n",
      "epoch =  424 ; loss =  0.114984\n",
      "epoch =  425 ; loss =  0.115136\n",
      "epoch =  426 ; loss =  0.114211\n",
      "epoch =  427 ; loss =  0.115342\n",
      "epoch =  428 ; loss =  0.115422\n",
      "epoch =  429 ; loss =  0.114096\n",
      "epoch =  430 ; loss =  0.114972\n",
      "epoch =  431 ; loss =  0.114899\n",
      "epoch =  432 ; loss =  0.114294\n",
      "epoch =  433 ; loss =  0.113434\n",
      "epoch =  434 ; loss =  0.114309\n",
      "epoch =  435 ; loss =  0.114447\n",
      "epoch =  436 ; loss =  0.114132\n",
      "epoch =  437 ; loss =  0.11489\n",
      "epoch =  438 ; loss =  0.114165\n",
      "epoch =  439 ; loss =  0.11433\n",
      "epoch =  440 ; loss =  0.114131\n",
      "epoch =  441 ; loss =  0.114003\n",
      "epoch =  442 ; loss =  0.11294\n",
      "epoch =  443 ; loss =  0.113692\n",
      "epoch =  444 ; loss =  0.113335\n",
      "epoch =  445 ; loss =  0.113024\n",
      "epoch =  446 ; loss =  0.113573\n",
      "epoch =  447 ; loss =  0.113964\n",
      "epoch =  448 ; loss =  0.113644\n",
      "epoch =  449 ; loss =  0.11319\n",
      "epoch =  450 ; loss =  0.113371\n",
      "epoch =  451 ; loss =  0.114191\n",
      "epoch =  452 ; loss =  0.113278\n",
      "epoch =  453 ; loss =  0.11394\n",
      "epoch =  454 ; loss =  0.113595\n",
      "epoch =  455 ; loss =  0.112071\n",
      "epoch =  456 ; loss =  0.113907\n",
      "epoch =  457 ; loss =  0.114462\n",
      "epoch =  458 ; loss =  0.112651\n",
      "epoch =  459 ; loss =  0.112961\n",
      "epoch =  460 ; loss =  0.112539\n",
      "epoch =  461 ; loss =  0.112929\n",
      "epoch =  462 ; loss =  0.112484\n",
      "epoch =  463 ; loss =  0.113294\n",
      "epoch =  464 ; loss =  0.112902\n",
      "epoch =  465 ; loss =  0.112566\n",
      "epoch =  466 ; loss =  0.11204\n",
      "epoch =  467 ; loss =  0.112881\n",
      "epoch =  468 ; loss =  0.111846\n",
      "epoch =  469 ; loss =  0.112426\n",
      "epoch =  470 ; loss =  0.112318\n",
      "epoch =  471 ; loss =  0.11182\n",
      "epoch =  472 ; loss =  0.112278\n",
      "epoch =  473 ; loss =  0.112768\n",
      "epoch =  474 ; loss =  0.112039\n",
      "epoch =  475 ; loss =  0.111376\n",
      "epoch =  476 ; loss =  0.1113\n",
      "epoch =  477 ; loss =  0.111507\n",
      "epoch =  478 ; loss =  0.112266\n",
      "epoch =  479 ; loss =  0.111251\n",
      "epoch =  480 ; loss =  0.112436\n",
      "epoch =  481 ; loss =  0.11254\n",
      "epoch =  482 ; loss =  0.111048\n",
      "epoch =  483 ; loss =  0.111572\n",
      "epoch =  484 ; loss =  0.111427\n",
      "epoch =  485 ; loss =  0.111742\n",
      "epoch =  486 ; loss =  0.111568\n",
      "epoch =  487 ; loss =  0.11156\n",
      "epoch =  488 ; loss =  0.111876\n",
      "epoch =  489 ; loss =  0.112471\n",
      "epoch =  490 ; loss =  0.110912\n",
      "epoch =  491 ; loss =  0.111275\n",
      "epoch =  492 ; loss =  0.111567\n",
      "epoch =  493 ; loss =  0.111381\n",
      "epoch =  494 ; loss =  0.112133\n",
      "epoch =  495 ; loss =  0.111158\n",
      "epoch =  496 ; loss =  0.11075\n",
      "epoch =  497 ; loss =  0.110753\n",
      "epoch =  498 ; loss =  0.111232\n",
      "epoch =  499 ; loss =  0.111034\n",
      "Obtaining new batch of pieces\n",
      "epoch =  500 ; loss =  0.112619\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  501 ; loss =  0.113027\n",
      "epoch =  502 ; loss =  0.112685\n",
      "epoch =  503 ; loss =  0.112468\n",
      "epoch =  504 ; loss =  0.112894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  505 ; loss =  0.112334\n",
      "epoch =  506 ; loss =  0.113166\n",
      "epoch =  507 ; loss =  0.114027\n",
      "epoch =  508 ; loss =  0.112503\n",
      "epoch =  509 ; loss =  0.112665\n",
      "epoch =  510 ; loss =  0.112057\n",
      "epoch =  511 ; loss =  0.112698\n",
      "epoch =  512 ; loss =  0.112402\n",
      "epoch =  513 ; loss =  0.113934\n",
      "epoch =  514 ; loss =  0.112776\n",
      "epoch =  515 ; loss =  0.112428\n",
      "epoch =  516 ; loss =  0.111429\n",
      "epoch =  517 ; loss =  0.111702\n",
      "epoch =  518 ; loss =  0.110867\n",
      "epoch =  519 ; loss =  0.111555\n",
      "epoch =  520 ; loss =  0.111072\n",
      "epoch =  521 ; loss =  0.111398\n",
      "epoch =  522 ; loss =  0.110892\n",
      "epoch =  523 ; loss =  0.110439\n",
      "epoch =  524 ; loss =  0.110493\n",
      "epoch =  525 ; loss =  0.110806\n",
      "epoch =  526 ; loss =  0.110967\n",
      "epoch =  527 ; loss =  0.112152\n",
      "epoch =  528 ; loss =  0.114055\n",
      "epoch =  529 ; loss =  0.11154\n",
      "epoch =  530 ; loss =  0.111646\n",
      "epoch =  531 ; loss =  0.110389\n",
      "epoch =  532 ; loss =  0.111266\n",
      "epoch =  533 ; loss =  0.110369\n",
      "epoch =  534 ; loss =  0.11079\n",
      "epoch =  535 ; loss =  0.110434\n",
      "epoch =  536 ; loss =  0.109777\n",
      "epoch =  537 ; loss =  0.111028\n",
      "epoch =  538 ; loss =  0.111121\n",
      "epoch =  539 ; loss =  0.110228\n",
      "epoch =  540 ; loss =  0.110273\n",
      "epoch =  541 ; loss =  0.110924\n",
      "epoch =  542 ; loss =  0.111389\n",
      "epoch =  543 ; loss =  0.110573\n",
      "epoch =  544 ; loss =  0.111677\n",
      "epoch =  545 ; loss =  0.110665\n",
      "epoch =  546 ; loss =  0.110525\n",
      "epoch =  547 ; loss =  0.11063\n",
      "epoch =  548 ; loss =  0.110947\n",
      "epoch =  549 ; loss =  0.11048\n",
      "epoch =  550 ; loss =  0.111508\n",
      "epoch =  551 ; loss =  0.110589\n",
      "epoch =  552 ; loss =  0.109578\n",
      "epoch =  553 ; loss =  0.110038\n",
      "epoch =  554 ; loss =  0.110135\n",
      "epoch =  555 ; loss =  0.109848\n",
      "epoch =  556 ; loss =  0.109968\n",
      "epoch =  557 ; loss =  0.109849\n",
      "epoch =  558 ; loss =  0.11015\n",
      "epoch =  559 ; loss =  0.109741\n",
      "epoch =  560 ; loss =  0.109663\n",
      "epoch =  561 ; loss =  0.109513\n",
      "epoch =  562 ; loss =  0.109075\n",
      "epoch =  563 ; loss =  0.10975\n",
      "epoch =  564 ; loss =  0.10952\n",
      "epoch =  565 ; loss =  0.109704\n",
      "epoch =  566 ; loss =  0.110194\n",
      "epoch =  567 ; loss =  0.109206\n",
      "epoch =  568 ; loss =  0.109611\n",
      "epoch =  569 ; loss =  0.109944\n",
      "epoch =  570 ; loss =  0.110608\n",
      "epoch =  571 ; loss =  0.109326\n",
      "epoch =  572 ; loss =  0.109662\n",
      "epoch =  573 ; loss =  0.109864\n",
      "epoch =  574 ; loss =  0.111224\n",
      "epoch =  575 ; loss =  0.109509\n",
      "epoch =  576 ; loss =  0.108934\n",
      "epoch =  577 ; loss =  0.110066\n",
      "epoch =  578 ; loss =  0.109192\n",
      "epoch =  579 ; loss =  0.109672\n",
      "epoch =  580 ; loss =  0.111856\n",
      "epoch =  581 ; loss =  0.10949\n",
      "epoch =  582 ; loss =  0.109107\n",
      "epoch =  583 ; loss =  0.109493\n",
      "epoch =  584 ; loss =  0.109408\n",
      "epoch =  585 ; loss =  0.108783\n",
      "epoch =  586 ; loss =  0.109178\n",
      "epoch =  587 ; loss =  0.109625\n",
      "epoch =  588 ; loss =  0.11131\n",
      "epoch =  589 ; loss =  0.109972\n",
      "epoch =  590 ; loss =  0.109034\n",
      "epoch =  591 ; loss =  0.108612\n",
      "epoch =  592 ; loss =  0.109223\n",
      "epoch =  593 ; loss =  0.108607\n",
      "epoch =  594 ; loss =  0.10857\n",
      "epoch =  595 ; loss =  0.108672\n",
      "epoch =  596 ; loss =  0.108845\n",
      "epoch =  597 ; loss =  0.108543\n",
      "epoch =  598 ; loss =  0.109957\n",
      "epoch =  599 ; loss =  0.108508\n",
      "Obtaining new batch of pieces\n",
      "epoch =  600 ; loss =  0.115317\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  601 ; loss =  0.11422\n",
      "epoch =  602 ; loss =  0.114808\n",
      "epoch =  603 ; loss =  0.115138\n",
      "epoch =  604 ; loss =  0.116121\n",
      "epoch =  605 ; loss =  0.115075\n",
      "epoch =  606 ; loss =  0.116273\n",
      "epoch =  607 ; loss =  0.113868\n",
      "epoch =  608 ; loss =  0.11474\n",
      "epoch =  609 ; loss =  0.113521\n",
      "epoch =  610 ; loss =  0.114146\n",
      "epoch =  611 ; loss =  0.113804\n",
      "epoch =  612 ; loss =  0.114407\n",
      "epoch =  613 ; loss =  0.114191\n",
      "epoch =  614 ; loss =  0.114736\n",
      "epoch =  615 ; loss =  0.112638\n",
      "epoch =  616 ; loss =  0.113249\n",
      "epoch =  617 ; loss =  0.112362\n",
      "epoch =  618 ; loss =  0.113169\n",
      "epoch =  619 ; loss =  0.113367\n",
      "epoch =  620 ; loss =  0.112728\n",
      "epoch =  621 ; loss =  0.112336\n",
      "epoch =  622 ; loss =  0.112532\n",
      "epoch =  623 ; loss =  0.112499\n",
      "epoch =  624 ; loss =  0.11348\n",
      "epoch =  625 ; loss =  0.112397\n",
      "epoch =  626 ; loss =  0.111522\n",
      "epoch =  627 ; loss =  0.111953\n",
      "epoch =  628 ; loss =  0.112537\n",
      "epoch =  629 ; loss =  0.112692\n",
      "epoch =  630 ; loss =  0.114538\n",
      "epoch =  631 ; loss =  0.112484\n",
      "epoch =  632 ; loss =  0.112587\n",
      "epoch =  633 ; loss =  0.112716\n",
      "epoch =  634 ; loss =  0.112505\n",
      "epoch =  635 ; loss =  0.112025\n",
      "epoch =  636 ; loss =  0.112132\n",
      "epoch =  637 ; loss =  0.112042\n",
      "epoch =  638 ; loss =  0.113578\n",
      "epoch =  639 ; loss =  0.111994\n",
      "epoch =  640 ; loss =  0.111199\n",
      "epoch =  641 ; loss =  0.111791\n",
      "epoch =  642 ; loss =  0.112365\n",
      "epoch =  643 ; loss =  0.110676\n",
      "epoch =  644 ; loss =  0.111812\n",
      "epoch =  645 ; loss =  0.111334\n",
      "epoch =  646 ; loss =  0.112885\n",
      "epoch =  647 ; loss =  0.111654\n",
      "epoch =  648 ; loss =  0.112061\n",
      "epoch =  649 ; loss =  0.11108\n",
      "epoch =  650 ; loss =  0.113046\n",
      "epoch =  651 ; loss =  0.112391\n",
      "epoch =  652 ; loss =  0.113155\n",
      "epoch =  653 ; loss =  0.111091\n",
      "epoch =  654 ; loss =  0.111971\n",
      "epoch =  655 ; loss =  0.11116\n",
      "epoch =  656 ; loss =  0.110317\n",
      "epoch =  657 ; loss =  0.11104\n",
      "epoch =  658 ; loss =  0.110336\n",
      "epoch =  659 ; loss =  0.110545\n",
      "epoch =  660 ; loss =  0.111732\n",
      "epoch =  661 ; loss =  0.112893\n",
      "epoch =  662 ; loss =  0.114988\n",
      "epoch =  663 ; loss =  0.112237\n",
      "epoch =  664 ; loss =  0.111873\n",
      "epoch =  665 ; loss =  0.111132\n",
      "epoch =  666 ; loss =  0.110417\n",
      "epoch =  667 ; loss =  0.110429\n",
      "epoch =  668 ; loss =  0.111586\n",
      "epoch =  669 ; loss =  0.110014\n",
      "epoch =  670 ; loss =  0.110941\n",
      "epoch =  671 ; loss =  0.110108\n",
      "epoch =  672 ; loss =  0.11065\n",
      "epoch =  673 ; loss =  0.110351\n",
      "epoch =  674 ; loss =  0.110583\n",
      "epoch =  675 ; loss =  0.110372\n",
      "epoch =  676 ; loss =  0.110097\n",
      "epoch =  677 ; loss =  0.110072\n",
      "epoch =  678 ; loss =  0.110523\n",
      "epoch =  679 ; loss =  0.111193\n",
      "epoch =  680 ; loss =  0.112849\n",
      "epoch =  681 ; loss =  0.110159\n",
      "epoch =  682 ; loss =  0.1105\n",
      "epoch =  683 ; loss =  0.10986\n",
      "epoch =  684 ; loss =  0.109879\n",
      "epoch =  685 ; loss =  0.110235\n",
      "epoch =  686 ; loss =  0.110407\n",
      "epoch =  687 ; loss =  0.110695\n",
      "epoch =  688 ; loss =  0.11043\n",
      "epoch =  689 ; loss =  0.110214\n",
      "epoch =  690 ; loss =  0.109664\n",
      "epoch =  691 ; loss =  0.110863\n",
      "epoch =  692 ; loss =  0.109953\n",
      "epoch =  693 ; loss =  0.110237\n",
      "epoch =  694 ; loss =  0.110344\n",
      "epoch =  695 ; loss =  0.110846\n",
      "epoch =  696 ; loss =  0.11017\n",
      "epoch =  697 ; loss =  0.11035\n",
      "epoch =  698 ; loss =  0.109666\n",
      "epoch =  699 ; loss =  0.109762\n",
      "Obtaining new batch of pieces\n",
      "epoch =  700 ; loss =  0.100886\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  701 ; loss =  0.100674\n",
      "epoch =  702 ; loss =  0.100184\n",
      "epoch =  703 ; loss =  0.0993021\n",
      "epoch =  704 ; loss =  0.0990477\n",
      "epoch =  705 ; loss =  0.0989907\n",
      "epoch =  706 ; loss =  0.0993949\n",
      "epoch =  707 ; loss =  0.0995322\n",
      "epoch =  708 ; loss =  0.100494\n",
      "epoch =  709 ; loss =  0.0996009\n",
      "epoch =  710 ; loss =  0.101492\n",
      "epoch =  711 ; loss =  0.0995937\n",
      "epoch =  712 ; loss =  0.0989827\n",
      "epoch =  713 ; loss =  0.0985195\n",
      "epoch =  714 ; loss =  0.0988565\n",
      "epoch =  715 ; loss =  0.0988389\n",
      "epoch =  716 ; loss =  0.102353\n",
      "epoch =  717 ; loss =  0.0995355\n",
      "epoch =  718 ; loss =  0.0986753\n",
      "epoch =  719 ; loss =  0.0984923\n",
      "epoch =  720 ; loss =  0.0985253\n",
      "epoch =  721 ; loss =  0.0989303\n",
      "epoch =  722 ; loss =  0.100788\n",
      "epoch =  723 ; loss =  0.0998045\n",
      "epoch =  724 ; loss =  0.0982706\n",
      "epoch =  725 ; loss =  0.0979084\n",
      "epoch =  726 ; loss =  0.098207\n",
      "epoch =  727 ; loss =  0.0975199\n",
      "epoch =  728 ; loss =  0.0981399\n",
      "epoch =  729 ; loss =  0.100645\n",
      "epoch =  730 ; loss =  0.0991085\n",
      "epoch =  731 ; loss =  0.0984348\n",
      "epoch =  732 ; loss =  0.100001\n",
      "epoch =  733 ; loss =  0.098487\n",
      "epoch =  734 ; loss =  0.0981287\n",
      "epoch =  735 ; loss =  0.0992704\n",
      "epoch =  736 ; loss =  0.101327\n",
      "epoch =  737 ; loss =  0.100225\n",
      "epoch =  738 ; loss =  0.098006\n",
      "epoch =  739 ; loss =  0.0983059\n",
      "epoch =  740 ; loss =  0.0983232\n",
      "epoch =  741 ; loss =  0.0987752\n",
      "epoch =  742 ; loss =  0.100528\n",
      "epoch =  743 ; loss =  0.0982741\n",
      "epoch =  744 ; loss =  0.0979043\n",
      "epoch =  745 ; loss =  0.0974269\n",
      "epoch =  746 ; loss =  0.0971345\n",
      "epoch =  747 ; loss =  0.097277\n",
      "epoch =  748 ; loss =  0.0972408\n",
      "epoch =  749 ; loss =  0.0986725\n",
      "epoch =  750 ; loss =  0.100102\n",
      "epoch =  751 ; loss =  0.102941\n",
      "epoch =  752 ; loss =  0.0999131\n",
      "epoch =  753 ; loss =  0.0992154\n",
      "epoch =  754 ; loss =  0.0984543\n",
      "epoch =  755 ; loss =  0.0987115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  756 ; loss =  0.0981191\n",
      "epoch =  757 ; loss =  0.0977553\n",
      "epoch =  758 ; loss =  0.0984968\n",
      "epoch =  759 ; loss =  0.0976794\n",
      "epoch =  760 ; loss =  0.0980425\n",
      "epoch =  761 ; loss =  0.0972267\n",
      "epoch =  762 ; loss =  0.0978641\n",
      "epoch =  763 ; loss =  0.0984207\n",
      "epoch =  764 ; loss =  0.097713\n",
      "epoch =  765 ; loss =  0.0982151\n",
      "epoch =  766 ; loss =  0.097501\n",
      "epoch =  767 ; loss =  0.0976172\n",
      "epoch =  768 ; loss =  0.0978729\n",
      "epoch =  769 ; loss =  0.0986061\n",
      "epoch =  770 ; loss =  0.09704\n",
      "epoch =  771 ; loss =  0.0968995\n",
      "epoch =  772 ; loss =  0.0967845\n",
      "epoch =  773 ; loss =  0.0986988\n",
      "epoch =  774 ; loss =  0.0970477\n",
      "epoch =  775 ; loss =  0.0970729\n",
      "epoch =  776 ; loss =  0.0976711\n",
      "epoch =  777 ; loss =  0.099458\n",
      "epoch =  778 ; loss =  0.0974609\n",
      "epoch =  779 ; loss =  0.0965844\n",
      "epoch =  780 ; loss =  0.0968473\n",
      "epoch =  781 ; loss =  0.0988864\n",
      "epoch =  782 ; loss =  0.0971201\n",
      "epoch =  783 ; loss =  0.0967669\n",
      "epoch =  784 ; loss =  0.0969539\n",
      "epoch =  785 ; loss =  0.0993626\n",
      "epoch =  786 ; loss =  0.0963952\n",
      "epoch =  787 ; loss =  0.0963474\n",
      "epoch =  788 ; loss =  0.0964509\n",
      "epoch =  789 ; loss =  0.0961755\n",
      "epoch =  790 ; loss =  0.0970813\n",
      "epoch =  791 ; loss =  0.099192\n",
      "epoch =  792 ; loss =  0.0971143\n",
      "epoch =  793 ; loss =  0.0971225\n",
      "epoch =  794 ; loss =  0.0978421\n",
      "epoch =  795 ; loss =  0.100688\n",
      "epoch =  796 ; loss =  0.0985022\n",
      "epoch =  797 ; loss =  0.0969327\n",
      "epoch =  798 ; loss =  0.0961624\n",
      "epoch =  799 ; loss =  0.0962423\n",
      "Obtaining new batch of pieces\n",
      "epoch =  800 ; loss =  0.120096\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  801 ; loss =  0.119475\n",
      "epoch =  802 ; loss =  0.121145\n",
      "epoch =  803 ; loss =  0.123181\n",
      "epoch =  804 ; loss =  0.120152\n",
      "epoch =  805 ; loss =  0.118912\n",
      "epoch =  806 ; loss =  0.119252\n",
      "epoch =  807 ; loss =  0.11878\n",
      "epoch =  808 ; loss =  0.11969\n",
      "epoch =  809 ; loss =  0.118954\n",
      "epoch =  810 ; loss =  0.119959\n",
      "epoch =  811 ; loss =  0.118635\n",
      "epoch =  812 ; loss =  0.118406\n",
      "epoch =  813 ; loss =  0.119097\n",
      "epoch =  814 ; loss =  0.119088\n",
      "epoch =  815 ; loss =  0.117516\n",
      "epoch =  816 ; loss =  0.117738\n",
      "epoch =  817 ; loss =  0.117664\n",
      "epoch =  818 ; loss =  0.117774\n",
      "epoch =  819 ; loss =  0.11744\n",
      "epoch =  820 ; loss =  0.11682\n",
      "epoch =  821 ; loss =  0.117401\n",
      "epoch =  822 ; loss =  0.117864\n",
      "epoch =  823 ; loss =  0.117908\n",
      "epoch =  824 ; loss =  0.117902\n",
      "epoch =  825 ; loss =  0.117271\n",
      "epoch =  826 ; loss =  0.117671\n",
      "epoch =  827 ; loss =  0.117125\n",
      "epoch =  828 ; loss =  0.118098\n",
      "epoch =  829 ; loss =  0.11747\n",
      "epoch =  830 ; loss =  0.118372\n",
      "epoch =  831 ; loss =  0.116808\n",
      "epoch =  832 ; loss =  0.116822\n",
      "epoch =  833 ; loss =  0.116043\n",
      "epoch =  834 ; loss =  0.116321\n",
      "epoch =  835 ; loss =  0.117282\n",
      "epoch =  836 ; loss =  0.117001\n",
      "epoch =  837 ; loss =  0.116768\n",
      "epoch =  838 ; loss =  0.116555\n",
      "epoch =  839 ; loss =  0.116522\n",
      "epoch =  840 ; loss =  0.116733\n",
      "epoch =  841 ; loss =  0.116738\n",
      "epoch =  842 ; loss =  0.11627\n",
      "epoch =  843 ; loss =  0.116094\n",
      "epoch =  844 ; loss =  0.116004\n",
      "epoch =  845 ; loss =  0.116289\n",
      "epoch =  846 ; loss =  0.116852\n",
      "epoch =  847 ; loss =  0.116184\n",
      "epoch =  848 ; loss =  0.116724\n",
      "epoch =  849 ; loss =  0.116144\n",
      "epoch =  850 ; loss =  0.116626\n",
      "epoch =  851 ; loss =  0.116033\n",
      "epoch =  852 ; loss =  0.116833\n",
      "epoch =  853 ; loss =  0.115512\n",
      "epoch =  854 ; loss =  0.116615\n",
      "epoch =  855 ; loss =  0.115214\n",
      "epoch =  856 ; loss =  0.116686\n",
      "epoch =  857 ; loss =  0.115781\n",
      "epoch =  858 ; loss =  0.115753\n",
      "epoch =  859 ; loss =  0.115742\n",
      "epoch =  860 ; loss =  0.115556\n",
      "epoch =  861 ; loss =  0.115642\n",
      "epoch =  862 ; loss =  0.116111\n",
      "epoch =  863 ; loss =  0.115834\n",
      "epoch =  864 ; loss =  0.115474\n",
      "epoch =  865 ; loss =  0.115594\n",
      "epoch =  866 ; loss =  0.116647\n",
      "epoch =  867 ; loss =  0.115451\n",
      "epoch =  868 ; loss =  0.115511\n",
      "epoch =  869 ; loss =  0.11494\n",
      "epoch =  870 ; loss =  0.11579\n",
      "epoch =  871 ; loss =  0.115286\n",
      "epoch =  872 ; loss =  0.116213\n",
      "epoch =  873 ; loss =  0.115134\n",
      "epoch =  874 ; loss =  0.115429\n",
      "epoch =  875 ; loss =  0.115076\n",
      "epoch =  876 ; loss =  0.115277\n",
      "epoch =  877 ; loss =  0.115458\n",
      "epoch =  878 ; loss =  0.115502\n",
      "epoch =  879 ; loss =  0.114872\n",
      "epoch =  880 ; loss =  0.114992\n",
      "epoch =  881 ; loss =  0.115215\n",
      "epoch =  882 ; loss =  0.115499\n",
      "epoch =  883 ; loss =  0.115009\n",
      "epoch =  884 ; loss =  0.115996\n",
      "epoch =  885 ; loss =  0.114779\n",
      "epoch =  886 ; loss =  0.114747\n",
      "epoch =  887 ; loss =  0.114556\n",
      "epoch =  888 ; loss =  0.114669\n",
      "epoch =  889 ; loss =  0.114005\n",
      "epoch =  890 ; loss =  0.114363\n",
      "epoch =  891 ; loss =  0.115037\n",
      "epoch =  892 ; loss =  0.115548\n",
      "epoch =  893 ; loss =  0.114173\n",
      "epoch =  894 ; loss =  0.11469\n",
      "epoch =  895 ; loss =  0.113802\n",
      "epoch =  896 ; loss =  0.114363\n",
      "epoch =  897 ; loss =  0.113963\n",
      "epoch =  898 ; loss =  0.114999\n",
      "epoch =  899 ; loss =  0.1146\n",
      "Obtaining new batch of pieces\n",
      "epoch =  900 ; loss =  0.111715\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  901 ; loss =  0.111715\n",
      "epoch =  902 ; loss =  0.112022\n",
      "epoch =  903 ; loss =  0.112572\n",
      "epoch =  904 ; loss =  0.113924\n",
      "epoch =  905 ; loss =  0.111861\n",
      "epoch =  906 ; loss =  0.111401\n",
      "epoch =  907 ; loss =  0.111687\n",
      "epoch =  908 ; loss =  0.11418\n",
      "epoch =  909 ; loss =  0.110401\n",
      "epoch =  910 ; loss =  0.10962\n",
      "epoch =  911 ; loss =  0.111072\n",
      "epoch =  912 ; loss =  0.110333\n",
      "epoch =  913 ; loss =  0.110711\n",
      "epoch =  914 ; loss =  0.109488\n",
      "epoch =  915 ; loss =  0.109813\n",
      "epoch =  916 ; loss =  0.109775\n",
      "epoch =  917 ; loss =  0.110372\n",
      "epoch =  918 ; loss =  0.110007\n",
      "epoch =  919 ; loss =  0.109977\n",
      "epoch =  920 ; loss =  0.1097\n",
      "epoch =  921 ; loss =  0.110762\n",
      "epoch =  922 ; loss =  0.10901\n",
      "epoch =  923 ; loss =  0.109365\n",
      "epoch =  924 ; loss =  0.109156\n",
      "epoch =  925 ; loss =  0.110136\n",
      "epoch =  926 ; loss =  0.109568\n",
      "epoch =  927 ; loss =  0.110433\n",
      "epoch =  928 ; loss =  0.109382\n",
      "epoch =  929 ; loss =  0.109165\n",
      "epoch =  930 ; loss =  0.109765\n",
      "epoch =  931 ; loss =  0.110259\n",
      "epoch =  932 ; loss =  0.109122\n",
      "epoch =  933 ; loss =  0.109475\n",
      "epoch =  934 ; loss =  0.109615\n",
      "epoch =  935 ; loss =  0.109809\n",
      "epoch =  936 ; loss =  0.108742\n",
      "epoch =  937 ; loss =  0.108636\n",
      "epoch =  938 ; loss =  0.108876\n",
      "epoch =  939 ; loss =  0.109476\n",
      "epoch =  940 ; loss =  0.109789\n",
      "epoch =  941 ; loss =  0.11172\n",
      "epoch =  942 ; loss =  0.109085\n",
      "epoch =  943 ; loss =  0.108053\n",
      "epoch =  944 ; loss =  0.108339\n",
      "epoch =  945 ; loss =  0.109296\n",
      "epoch =  946 ; loss =  0.108361\n",
      "epoch =  947 ; loss =  0.111541\n",
      "epoch =  948 ; loss =  0.107778\n",
      "epoch =  949 ; loss =  0.107681\n",
      "epoch =  950 ; loss =  0.108308\n",
      "epoch =  951 ; loss =  0.107941\n",
      "epoch =  952 ; loss =  0.108716\n",
      "epoch =  953 ; loss =  0.109868\n",
      "epoch =  954 ; loss =  0.108236\n",
      "epoch =  955 ; loss =  0.110308\n",
      "epoch =  956 ; loss =  0.108503\n",
      "epoch =  957 ; loss =  0.108735\n",
      "epoch =  958 ; loss =  0.108469\n",
      "epoch =  959 ; loss =  0.109086\n",
      "epoch =  960 ; loss =  0.108313\n",
      "epoch =  961 ; loss =  0.109417\n",
      "epoch =  962 ; loss =  0.1083\n",
      "epoch =  963 ; loss =  0.108347\n",
      "epoch =  964 ; loss =  0.108799\n",
      "epoch =  965 ; loss =  0.108688\n",
      "epoch =  966 ; loss =  0.108619\n",
      "epoch =  967 ; loss =  0.109166\n",
      "epoch =  968 ; loss =  0.109274\n",
      "epoch =  969 ; loss =  0.110483\n",
      "epoch =  970 ; loss =  0.107837\n",
      "epoch =  971 ; loss =  0.106997\n",
      "epoch =  972 ; loss =  0.107473\n",
      "epoch =  973 ; loss =  0.107048\n",
      "epoch =  974 ; loss =  0.106854\n",
      "epoch =  975 ; loss =  0.107559\n",
      "epoch =  976 ; loss =  0.107835\n",
      "epoch =  977 ; loss =  0.110076\n",
      "epoch =  978 ; loss =  0.108322\n",
      "epoch =  979 ; loss =  0.109303\n",
      "epoch =  980 ; loss =  0.108284\n",
      "epoch =  981 ; loss =  0.110107\n",
      "epoch =  982 ; loss =  0.107232\n",
      "epoch =  983 ; loss =  0.106927\n",
      "epoch =  984 ; loss =  0.106559\n",
      "epoch =  985 ; loss =  0.107568\n",
      "epoch =  986 ; loss =  0.108266\n",
      "epoch =  987 ; loss =  0.108023\n",
      "epoch =  988 ; loss =  0.110471\n",
      "epoch =  989 ; loss =  0.107788\n",
      "epoch =  990 ; loss =  0.108174\n",
      "epoch =  991 ; loss =  0.107975\n",
      "epoch =  992 ; loss =  0.107287\n",
      "epoch =  993 ; loss =  0.108179\n",
      "epoch =  994 ; loss =  0.107217\n",
      "epoch =  995 ; loss =  0.109054\n",
      "epoch =  996 ; loss =  0.107581\n",
      "epoch =  997 ; loss =  0.107697\n",
      "epoch =  998 ; loss =  0.107136\n",
      "epoch =  999 ; loss =  0.107995\n",
      "Obtaining new batch of pieces\n",
      "epoch =  1000 ; loss =  0.120063\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  1001 ; loss =  0.120773\n",
      "epoch =  1002 ; loss =  0.120581\n",
      "epoch =  1003 ; loss =  0.123195\n",
      "epoch =  1004 ; loss =  0.11974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1005 ; loss =  0.118747\n",
      "epoch =  1006 ; loss =  0.118734\n",
      "epoch =  1007 ; loss =  0.119277\n",
      "epoch =  1008 ; loss =  0.118615\n",
      "epoch =  1009 ; loss =  0.119063\n",
      "epoch =  1010 ; loss =  0.118355\n",
      "epoch =  1011 ; loss =  0.118565\n",
      "epoch =  1012 ; loss =  0.120164\n",
      "epoch =  1013 ; loss =  0.12221\n",
      "epoch =  1014 ; loss =  0.117964\n",
      "epoch =  1015 ; loss =  0.117869\n",
      "epoch =  1016 ; loss =  0.118214\n",
      "epoch =  1017 ; loss =  0.117869\n",
      "epoch =  1018 ; loss =  0.117813\n",
      "epoch =  1019 ; loss =  0.118227\n",
      "epoch =  1020 ; loss =  0.11949\n",
      "epoch =  1021 ; loss =  0.118738\n",
      "epoch =  1022 ; loss =  0.122763\n",
      "epoch =  1023 ; loss =  0.118307\n",
      "epoch =  1024 ; loss =  0.117508\n",
      "epoch =  1025 ; loss =  0.116741\n",
      "epoch =  1026 ; loss =  0.117648\n",
      "epoch =  1027 ; loss =  0.117589\n",
      "epoch =  1028 ; loss =  0.117548\n",
      "epoch =  1029 ; loss =  0.117773\n",
      "epoch =  1030 ; loss =  0.11806\n",
      "epoch =  1031 ; loss =  0.121138\n",
      "epoch =  1032 ; loss =  0.117399\n",
      "epoch =  1033 ; loss =  0.118215\n",
      "epoch =  1034 ; loss =  0.118143\n",
      "epoch =  1035 ; loss =  0.119235\n",
      "epoch =  1036 ; loss =  0.118251\n",
      "epoch =  1037 ; loss =  0.118496\n",
      "epoch =  1038 ; loss =  0.11814\n",
      "epoch =  1039 ; loss =  0.119226\n",
      "epoch =  1040 ; loss =  0.117993\n",
      "epoch =  1041 ; loss =  0.119209\n",
      "epoch =  1042 ; loss =  0.117339\n",
      "epoch =  1043 ; loss =  0.117934\n",
      "epoch =  1044 ; loss =  0.117895\n",
      "epoch =  1045 ; loss =  0.118354\n",
      "epoch =  1046 ; loss =  0.117471\n",
      "epoch =  1047 ; loss =  0.117907\n",
      "epoch =  1048 ; loss =  0.116907\n",
      "epoch =  1049 ; loss =  0.117865\n",
      "epoch =  1050 ; loss =  0.117409\n",
      "epoch =  1051 ; loss =  0.118442\n",
      "epoch =  1052 ; loss =  0.117017\n",
      "epoch =  1053 ; loss =  0.117918\n",
      "epoch =  1054 ; loss =  0.117725\n",
      "epoch =  1055 ; loss =  0.11862\n",
      "epoch =  1056 ; loss =  0.116879\n",
      "epoch =  1057 ; loss =  0.117561\n",
      "epoch =  1058 ; loss =  0.116977\n",
      "epoch =  1059 ; loss =  0.116669\n",
      "epoch =  1060 ; loss =  0.117375\n",
      "epoch =  1061 ; loss =  0.116755\n",
      "epoch =  1062 ; loss =  0.117491\n",
      "epoch =  1063 ; loss =  0.118094\n",
      "epoch =  1064 ; loss =  0.117286\n",
      "epoch =  1065 ; loss =  0.11875\n",
      "epoch =  1066 ; loss =  0.117347\n",
      "epoch =  1067 ; loss =  0.11772\n",
      "epoch =  1068 ; loss =  0.117672\n",
      "epoch =  1069 ; loss =  0.118122\n",
      "epoch =  1070 ; loss =  0.116846\n",
      "epoch =  1071 ; loss =  0.11863\n",
      "epoch =  1072 ; loss =  0.116968\n",
      "epoch =  1073 ; loss =  0.117673\n",
      "epoch =  1074 ; loss =  0.117279\n",
      "epoch =  1075 ; loss =  0.117045\n",
      "epoch =  1076 ; loss =  0.115979\n",
      "epoch =  1077 ; loss =  0.1173\n",
      "epoch =  1078 ; loss =  0.117094\n",
      "epoch =  1079 ; loss =  0.117478\n",
      "epoch =  1080 ; loss =  0.116403\n",
      "epoch =  1081 ; loss =  0.118421\n",
      "epoch =  1082 ; loss =  0.117135\n",
      "epoch =  1083 ; loss =  0.116758\n",
      "epoch =  1084 ; loss =  0.116328\n",
      "epoch =  1085 ; loss =  0.117564\n",
      "epoch =  1086 ; loss =  0.117038\n",
      "epoch =  1087 ; loss =  0.117018\n",
      "epoch =  1088 ; loss =  0.116218\n",
      "epoch =  1089 ; loss =  0.117213\n",
      "epoch =  1090 ; loss =  0.116082\n",
      "epoch =  1091 ; loss =  0.116863\n",
      "epoch =  1092 ; loss =  0.116335\n",
      "epoch =  1093 ; loss =  0.118133\n",
      "epoch =  1094 ; loss =  0.117299\n",
      "epoch =  1095 ; loss =  0.118466\n",
      "epoch =  1096 ; loss =  0.116497\n",
      "epoch =  1097 ; loss =  0.117434\n",
      "epoch =  1098 ; loss =  0.116553\n",
      "epoch =  1099 ; loss =  0.116782\n",
      "Obtaining new batch of pieces\n",
      "epoch =  1100 ; loss =  0.119089\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  1101 ; loss =  0.118331\n",
      "epoch =  1102 ; loss =  0.118392\n",
      "epoch =  1103 ; loss =  0.121361\n",
      "epoch =  1104 ; loss =  0.121433\n",
      "epoch =  1105 ; loss =  0.127907\n",
      "epoch =  1106 ; loss =  0.120508\n",
      "epoch =  1107 ; loss =  0.11837\n",
      "epoch =  1108 ; loss =  0.117938\n",
      "epoch =  1109 ; loss =  0.119633\n",
      "epoch =  1110 ; loss =  0.127143\n",
      "epoch =  1111 ; loss =  0.120959\n",
      "epoch =  1112 ; loss =  0.118093\n",
      "epoch =  1113 ; loss =  0.116928\n",
      "epoch =  1114 ; loss =  0.117272\n",
      "epoch =  1115 ; loss =  0.117661\n",
      "epoch =  1116 ; loss =  0.124238\n",
      "epoch =  1117 ; loss =  0.118976\n",
      "epoch =  1118 ; loss =  0.116938\n",
      "epoch =  1119 ; loss =  0.117867\n",
      "epoch =  1120 ; loss =  0.123149\n",
      "epoch =  1121 ; loss =  0.118034\n",
      "epoch =  1122 ; loss =  0.11728\n",
      "epoch =  1123 ; loss =  0.117448\n",
      "epoch =  1124 ; loss =  0.121598\n",
      "epoch =  1125 ; loss =  0.117793\n",
      "epoch =  1126 ; loss =  0.121576\n",
      "epoch =  1127 ; loss =  0.118693\n",
      "epoch =  1128 ; loss =  0.123482\n",
      "epoch =  1129 ; loss =  0.116918\n",
      "epoch =  1130 ; loss =  0.116457\n",
      "epoch =  1131 ; loss =  0.116569\n",
      "epoch =  1132 ; loss =  0.117882\n",
      "epoch =  1133 ; loss =  0.118968\n",
      "epoch =  1134 ; loss =  0.125329\n",
      "epoch =  1135 ; loss =  0.11954\n",
      "epoch =  1136 ; loss =  0.115975\n",
      "epoch =  1137 ; loss =  0.115761\n",
      "epoch =  1138 ; loss =  0.116047\n",
      "epoch =  1139 ; loss =  0.115985\n",
      "epoch =  1140 ; loss =  0.115364\n",
      "epoch =  1141 ; loss =  0.116712\n",
      "epoch =  1142 ; loss =  0.118778\n",
      "epoch =  1143 ; loss =  0.118625\n",
      "epoch =  1144 ; loss =  0.123637\n",
      "epoch =  1145 ; loss =  0.11776\n",
      "epoch =  1146 ; loss =  0.115106\n",
      "epoch =  1147 ; loss =  0.115619\n",
      "epoch =  1148 ; loss =  0.115618\n",
      "epoch =  1149 ; loss =  0.11573\n",
      "epoch =  1150 ; loss =  0.116515\n",
      "epoch =  1151 ; loss =  0.121803\n",
      "epoch =  1152 ; loss =  0.115952\n",
      "epoch =  1153 ; loss =  0.116192\n",
      "epoch =  1154 ; loss =  0.117049\n",
      "epoch =  1155 ; loss =  0.121044\n",
      "epoch =  1156 ; loss =  0.116321\n",
      "epoch =  1157 ; loss =  0.116681\n",
      "epoch =  1158 ; loss =  0.117712\n",
      "epoch =  1159 ; loss =  0.12191\n",
      "epoch =  1160 ; loss =  0.116606\n",
      "epoch =  1161 ; loss =  0.115312\n",
      "epoch =  1162 ; loss =  0.114922\n",
      "epoch =  1163 ; loss =  0.116609\n",
      "epoch =  1164 ; loss =  0.116886\n",
      "epoch =  1165 ; loss =  0.120682\n",
      "epoch =  1166 ; loss =  0.115751\n",
      "epoch =  1167 ; loss =  0.114552\n",
      "epoch =  1168 ; loss =  0.11502\n",
      "epoch =  1169 ; loss =  0.115241\n",
      "epoch =  1170 ; loss =  0.116001\n",
      "epoch =  1171 ; loss =  0.120355\n",
      "epoch =  1172 ; loss =  0.115552\n",
      "epoch =  1173 ; loss =  0.116128\n",
      "epoch =  1174 ; loss =  0.116102\n",
      "epoch =  1175 ; loss =  0.119911\n",
      "epoch =  1176 ; loss =  0.115555\n",
      "epoch =  1177 ; loss =  0.114256\n",
      "epoch =  1178 ; loss =  0.114989\n",
      "epoch =  1179 ; loss =  0.115249\n",
      "epoch =  1180 ; loss =  0.115762\n",
      "epoch =  1181 ; loss =  0.119211\n",
      "epoch =  1182 ; loss =  0.115881\n",
      "epoch =  1183 ; loss =  0.116453\n",
      "epoch =  1184 ; loss =  0.116022\n",
      "epoch =  1185 ; loss =  0.118321\n",
      "epoch =  1186 ; loss =  0.11557\n",
      "epoch =  1187 ; loss =  0.116395\n",
      "epoch =  1188 ; loss =  0.115838\n",
      "epoch =  1189 ; loss =  0.118611\n",
      "epoch =  1190 ; loss =  0.11543\n",
      "epoch =  1191 ; loss =  0.115707\n",
      "epoch =  1192 ; loss =  0.115753\n",
      "epoch =  1193 ; loss =  0.117405\n",
      "epoch =  1194 ; loss =  0.11553\n",
      "epoch =  1195 ; loss =  0.116641\n",
      "epoch =  1196 ; loss =  0.115653\n",
      "epoch =  1197 ; loss =  0.116602\n",
      "epoch =  1198 ; loss =  0.115422\n",
      "epoch =  1199 ; loss =  0.11658\n",
      "Obtaining new batch of pieces\n",
      "epoch =  1200 ; loss =  0.108416\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  1201 ; loss =  0.109469\n",
      "epoch =  1202 ; loss =  0.10633\n",
      "epoch =  1203 ; loss =  0.106469\n",
      "epoch =  1204 ; loss =  0.106557\n",
      "epoch =  1205 ; loss =  0.10615\n",
      "epoch =  1206 ; loss =  0.106135\n",
      "epoch =  1207 ; loss =  0.106244\n",
      "epoch =  1208 ; loss =  0.10602\n",
      "epoch =  1209 ; loss =  0.107057\n",
      "epoch =  1210 ; loss =  0.106225\n",
      "epoch =  1211 ; loss =  0.10769\n",
      "epoch =  1212 ; loss =  0.10609\n",
      "epoch =  1213 ; loss =  0.1065\n",
      "epoch =  1214 ; loss =  0.107148\n",
      "epoch =  1215 ; loss =  0.110127\n",
      "epoch =  1216 ; loss =  0.10611\n",
      "epoch =  1217 ; loss =  0.10646\n",
      "epoch =  1218 ; loss =  0.105916\n",
      "epoch =  1219 ; loss =  0.10566\n",
      "epoch =  1220 ; loss =  0.105738\n",
      "epoch =  1221 ; loss =  0.107042\n",
      "epoch =  1222 ; loss =  0.106158\n",
      "epoch =  1223 ; loss =  0.107632\n",
      "epoch =  1224 ; loss =  0.105414\n",
      "epoch =  1225 ; loss =  0.106526\n",
      "epoch =  1226 ; loss =  0.10607\n",
      "epoch =  1227 ; loss =  0.107739\n",
      "epoch =  1228 ; loss =  0.105128\n",
      "epoch =  1229 ; loss =  0.106442\n",
      "epoch =  1230 ; loss =  0.104693\n",
      "epoch =  1231 ; loss =  0.105141\n",
      "epoch =  1232 ; loss =  0.105019\n",
      "epoch =  1233 ; loss =  0.105631\n",
      "epoch =  1234 ; loss =  0.104435\n",
      "epoch =  1235 ; loss =  0.106181\n",
      "epoch =  1236 ; loss =  0.10529\n",
      "epoch =  1237 ; loss =  0.106298\n",
      "epoch =  1238 ; loss =  0.104509\n",
      "epoch =  1239 ; loss =  0.105039\n",
      "epoch =  1240 ; loss =  0.10412\n",
      "epoch =  1241 ; loss =  0.104922\n",
      "epoch =  1242 ; loss =  0.104603\n",
      "epoch =  1243 ; loss =  0.105497\n",
      "epoch =  1244 ; loss =  0.104979\n",
      "epoch =  1245 ; loss =  0.106009\n",
      "epoch =  1246 ; loss =  0.1044\n",
      "epoch =  1247 ; loss =  0.104637\n",
      "epoch =  1248 ; loss =  0.104006\n",
      "epoch =  1249 ; loss =  0.105132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1250 ; loss =  0.104255\n",
      "epoch =  1251 ; loss =  0.10479\n",
      "epoch =  1252 ; loss =  0.103913\n",
      "epoch =  1253 ; loss =  0.104687\n",
      "epoch =  1254 ; loss =  0.104772\n",
      "epoch =  1255 ; loss =  0.104625\n",
      "epoch =  1256 ; loss =  0.1038\n",
      "epoch =  1257 ; loss =  0.104596\n",
      "epoch =  1258 ; loss =  0.104045\n",
      "epoch =  1259 ; loss =  0.105081\n",
      "epoch =  1260 ; loss =  0.104241\n",
      "epoch =  1261 ; loss =  0.105247\n",
      "epoch =  1262 ; loss =  0.104037\n",
      "epoch =  1263 ; loss =  0.105152\n",
      "epoch =  1264 ; loss =  0.104602\n",
      "epoch =  1265 ; loss =  0.104055\n",
      "epoch =  1266 ; loss =  0.103366\n",
      "epoch =  1267 ; loss =  0.10355\n",
      "epoch =  1268 ; loss =  0.103623\n",
      "epoch =  1269 ; loss =  0.103513\n",
      "epoch =  1270 ; loss =  0.103207\n",
      "epoch =  1271 ; loss =  0.104189\n",
      "epoch =  1272 ; loss =  0.103943\n",
      "epoch =  1273 ; loss =  0.105964\n",
      "epoch =  1274 ; loss =  0.104021\n",
      "epoch =  1275 ; loss =  0.104702\n",
      "epoch =  1276 ; loss =  0.103766\n",
      "epoch =  1277 ; loss =  0.104722\n",
      "epoch =  1278 ; loss =  0.103664\n",
      "epoch =  1279 ; loss =  0.104654\n",
      "epoch =  1280 ; loss =  0.103717\n",
      "epoch =  1281 ; loss =  0.104669\n",
      "epoch =  1282 ; loss =  0.103062\n",
      "epoch =  1283 ; loss =  0.103986\n",
      "epoch =  1284 ; loss =  0.103408\n",
      "epoch =  1285 ; loss =  0.103868\n",
      "epoch =  1286 ; loss =  0.102988\n",
      "epoch =  1287 ; loss =  0.105559\n",
      "epoch =  1288 ; loss =  0.103435\n",
      "epoch =  1289 ; loss =  0.104382\n",
      "epoch =  1290 ; loss =  0.103985\n",
      "epoch =  1291 ; loss =  0.104195\n",
      "epoch =  1292 ; loss =  0.103302\n",
      "epoch =  1293 ; loss =  0.103949\n",
      "epoch =  1294 ; loss =  0.103512\n",
      "epoch =  1295 ; loss =  0.104225\n",
      "epoch =  1296 ; loss =  0.103168\n",
      "epoch =  1297 ; loss =  0.103938\n",
      "epoch =  1298 ; loss =  0.102835\n",
      "epoch =  1299 ; loss =  0.104068\n",
      "Obtaining new batch of pieces\n",
      "epoch =  1300 ; loss =  0.104889\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  1301 ; loss =  0.105469\n",
      "epoch =  1302 ; loss =  0.104212\n",
      "epoch =  1303 ; loss =  0.104167\n",
      "epoch =  1304 ; loss =  0.104405\n",
      "epoch =  1305 ; loss =  0.104762\n",
      "epoch =  1306 ; loss =  0.104975\n",
      "epoch =  1307 ; loss =  0.105513\n",
      "epoch =  1308 ; loss =  0.104613\n",
      "epoch =  1309 ; loss =  0.104004\n",
      "epoch =  1310 ; loss =  0.103419\n",
      "epoch =  1311 ; loss =  0.102899\n",
      "epoch =  1312 ; loss =  0.102829\n",
      "epoch =  1313 ; loss =  0.10399\n",
      "epoch =  1314 ; loss =  0.103574\n",
      "epoch =  1315 ; loss =  0.105558\n",
      "epoch =  1316 ; loss =  0.103466\n",
      "epoch =  1317 ; loss =  0.103725\n",
      "epoch =  1318 ; loss =  0.102773\n",
      "epoch =  1319 ; loss =  0.102621\n",
      "epoch =  1320 ; loss =  0.102924\n",
      "epoch =  1321 ; loss =  0.102802\n",
      "epoch =  1322 ; loss =  0.102757\n",
      "epoch =  1323 ; loss =  0.104305\n",
      "epoch =  1324 ; loss =  0.103909\n",
      "epoch =  1325 ; loss =  0.103537\n",
      "epoch =  1326 ; loss =  0.102629\n",
      "epoch =  1327 ; loss =  0.102899\n",
      "epoch =  1328 ; loss =  0.102237\n",
      "epoch =  1329 ; loss =  0.102602\n",
      "epoch =  1330 ; loss =  0.10247\n",
      "epoch =  1331 ; loss =  0.102822\n",
      "epoch =  1332 ; loss =  0.102375\n",
      "epoch =  1333 ; loss =  0.103279\n",
      "epoch =  1334 ; loss =  0.102533\n",
      "epoch =  1335 ; loss =  0.103155\n",
      "epoch =  1336 ; loss =  0.102026\n",
      "epoch =  1337 ; loss =  0.101918\n",
      "epoch =  1338 ; loss =  0.102155\n",
      "epoch =  1339 ; loss =  0.102595\n",
      "epoch =  1340 ; loss =  0.102732\n",
      "epoch =  1341 ; loss =  0.102775\n",
      "epoch =  1342 ; loss =  0.102523\n",
      "epoch =  1343 ; loss =  0.103166\n",
      "epoch =  1344 ; loss =  0.101768\n",
      "epoch =  1345 ; loss =  0.101734\n",
      "epoch =  1346 ; loss =  0.101217\n",
      "epoch =  1347 ; loss =  0.10204\n",
      "epoch =  1348 ; loss =  0.10156\n",
      "epoch =  1349 ; loss =  0.102581\n",
      "epoch =  1350 ; loss =  0.10131\n",
      "epoch =  1351 ; loss =  0.101566\n",
      "epoch =  1352 ; loss =  0.101995\n",
      "epoch =  1353 ; loss =  0.10143\n",
      "epoch =  1354 ; loss =  0.101683\n",
      "epoch =  1355 ; loss =  0.101721\n",
      "epoch =  1356 ; loss =  0.101986\n",
      "epoch =  1357 ; loss =  0.102519\n",
      "epoch =  1358 ; loss =  0.101698\n",
      "epoch =  1359 ; loss =  0.102193\n",
      "epoch =  1360 ; loss =  0.101374\n",
      "epoch =  1361 ; loss =  0.100874\n",
      "epoch =  1362 ; loss =  0.100835\n",
      "epoch =  1363 ; loss =  0.101261\n",
      "epoch =  1364 ; loss =  0.100756\n",
      "epoch =  1365 ; loss =  0.10142\n",
      "epoch =  1366 ; loss =  0.101107\n",
      "epoch =  1367 ; loss =  0.100744\n",
      "epoch =  1368 ; loss =  0.100986\n",
      "epoch =  1369 ; loss =  0.101523\n",
      "epoch =  1370 ; loss =  0.102329\n",
      "epoch =  1371 ; loss =  0.102038\n",
      "epoch =  1372 ; loss =  0.101238\n",
      "epoch =  1373 ; loss =  0.10094\n",
      "epoch =  1374 ; loss =  0.100684\n",
      "epoch =  1375 ; loss =  0.100217\n",
      "epoch =  1376 ; loss =  0.10078\n",
      "epoch =  1377 ; loss =  0.101572\n",
      "epoch =  1378 ; loss =  0.10181\n",
      "epoch =  1379 ; loss =  0.100553\n",
      "epoch =  1380 ; loss =  0.100086\n",
      "epoch =  1381 ; loss =  0.100721\n",
      "epoch =  1382 ; loss =  0.100151\n",
      "epoch =  1383 ; loss =  0.100332\n",
      "epoch =  1384 ; loss =  0.100603\n",
      "epoch =  1385 ; loss =  0.101402\n",
      "epoch =  1386 ; loss =  0.101243\n",
      "epoch =  1387 ; loss =  0.101022\n",
      "epoch =  1388 ; loss =  0.100466\n",
      "epoch =  1389 ; loss =  0.100695\n",
      "epoch =  1390 ; loss =  0.1009\n",
      "epoch =  1391 ; loss =  0.100464\n",
      "epoch =  1392 ; loss =  0.100175\n",
      "epoch =  1393 ; loss =  0.100401\n",
      "epoch =  1394 ; loss =  0.100956\n",
      "epoch =  1395 ; loss =  0.101571\n",
      "epoch =  1396 ; loss =  0.101282\n",
      "epoch =  1397 ; loss =  0.101076\n",
      "epoch =  1398 ; loss =  0.0999611\n",
      "epoch =  1399 ; loss =  0.0994515\n",
      "Obtaining new batch of pieces\n",
      "epoch =  1400 ; loss =  0.0952374\n",
      "Model saved in file: model/Practice_Dropout\n",
      "epoch =  1401 ; loss =  0.0944757\n",
      "epoch =  1402 ; loss =  0.0950142\n",
      "epoch =  1403 ; loss =  0.0948\n",
      "epoch =  1404 ; loss =  0.0945458\n",
      "epoch =  1405 ; loss =  0.0941836\n",
      "epoch =  1406 ; loss =  0.094318\n",
      "epoch =  1407 ; loss =  0.0952247\n",
      "epoch =  1408 ; loss =  0.0950486\n",
      "epoch =  1409 ; loss =  0.0944749\n",
      "epoch =  1410 ; loss =  0.0938701\n",
      "epoch =  1411 ; loss =  0.0941655\n",
      "epoch =  1412 ; loss =  0.0934994\n",
      "epoch =  1413 ; loss =  0.0937949\n",
      "epoch =  1414 ; loss =  0.0937186\n",
      "epoch =  1415 ; loss =  0.0930432\n",
      "epoch =  1416 ; loss =  0.0938559\n",
      "epoch =  1417 ; loss =  0.0944063\n",
      "epoch =  1418 ; loss =  0.0946968\n",
      "epoch =  1419 ; loss =  0.0946012\n",
      "epoch =  1420 ; loss =  0.0942844\n",
      "epoch =  1421 ; loss =  0.0939789\n",
      "epoch =  1422 ; loss =  0.0936955\n",
      "epoch =  1423 ; loss =  0.0934539\n",
      "epoch =  1424 ; loss =  0.0936401\n",
      "epoch =  1425 ; loss =  0.0931159\n",
      "epoch =  1426 ; loss =  0.0935559\n",
      "epoch =  1427 ; loss =  0.092939\n",
      "epoch =  1428 ; loss =  0.0926898\n",
      "epoch =  1429 ; loss =  0.093908\n",
      "epoch =  1430 ; loss =  0.0935166\n",
      "epoch =  1431 ; loss =  0.0938591\n",
      "epoch =  1432 ; loss =  0.0936813\n",
      "epoch =  1433 ; loss =  0.0929786\n",
      "epoch =  1434 ; loss =  0.0936853\n",
      "epoch =  1435 ; loss =  0.095015\n",
      "epoch =  1436 ; loss =  0.0945133\n",
      "epoch =  1437 ; loss =  0.0946149\n",
      "epoch =  1438 ; loss =  0.093911\n",
      "epoch =  1439 ; loss =  0.093243\n",
      "epoch =  1440 ; loss =  0.0929566\n",
      "epoch =  1441 ; loss =  0.0923197\n",
      "epoch =  1442 ; loss =  0.092472\n",
      "epoch =  1443 ; loss =  0.092833\n",
      "epoch =  1444 ; loss =  0.0930614\n",
      "epoch =  1445 ; loss =  0.0931993\n",
      "epoch =  1446 ; loss =  0.092632\n",
      "epoch =  1447 ; loss =  0.0933799\n",
      "epoch =  1448 ; loss =  0.093494\n",
      "epoch =  1449 ; loss =  0.093447\n",
      "epoch =  1450 ; loss =  0.0932992\n",
      "epoch =  1451 ; loss =  0.0925555\n",
      "epoch =  1452 ; loss =  0.0926249\n",
      "epoch =  1453 ; loss =  0.0932093\n",
      "epoch =  1454 ; loss =  0.0925845\n",
      "epoch =  1455 ; loss =  0.0931824\n",
      "epoch =  1456 ; loss =  0.0924975\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-3f751744b512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mNote_State_Batch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_input_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimewise_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtimewise_state_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotewise_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnotewise_state_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_init\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mloss_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;31m#except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m#   save_path = saver.save(sess, 'model/{}'.format(save_model_name))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "N_epochs = 2000\n",
    "loss_hist=[]\n",
    "restore_model_name = None\n",
    "save_model_name = 'Practice_Dropout'\n",
    "batch_size = 10\n",
    "num_timesteps = 128\n",
    "keep_prob=.5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # try to restore the pre_trained\n",
    "    if restore_model_name is not None:\n",
    "        print(\"Load the model from: {}\".format(restore_model_name))\n",
    "        saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "    # Initial States\n",
    "    timewise_state_val=[]\n",
    "    for i in range(len(num_t_units)):\n",
    "        c_t = np.zeros((batch_size*num_notes, num_t_units[i])) #start every batch with zero state in LSTM time cells\n",
    "        h_t = np.zeros((batch_size*num_notes, num_t_units[i]))\n",
    "        timewise_state_val.append(LSTMStateTuple(h_t, c_t))\n",
    "        \n",
    "    notewise_state_val=[]\n",
    "    for i in range(len(num_n_units)):\n",
    "        c_n = np.zeros((batch_size*num_timesteps, num_n_units[i])) #start every batch with zero state in LSTM time cells\n",
    "        h_n = np.zeros((batch_size*num_timesteps, num_n_units[i]))\n",
    "        notewise_state_val.append(LSTMStateTuple(h_n, c_n))\n",
    "    \n",
    "  \n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(N_epochs):\n",
    "        \n",
    "        #Generate random batch of training data\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print('Obtaining new batch of pieces')\n",
    "            _, batch_input_state = multi_training.getPieceBatch(training_pieces, batch_size, num_timesteps) # not using their 'convolution' filter\n",
    "            batch_input_state = np.array(batch_input_state)\n",
    "            batch_input_state = np.swapaxes(batch_input_state, axis1=1, axis2=2)           \n",
    "     \n",
    "        \n",
    "        \"\"\"\n",
    "        print('Note_State_Batch shape = ', Note_State_Batch.get_shape())\n",
    "        print('batch_input_state shape = ', batch_input_state.shape)\n",
    "        print('')\n",
    "        print('timewise_state shape = ', Note_State_Batch.get_shape())\n",
    "        print('timewise_state_val shape = ', batch_input_state.shape)      \n",
    "        print('')\n",
    "        print('notewise_state shape = ', Note_State_Batch.get_shape())\n",
    "        print('notewise_state_val shape = ', batch_input_state.shape)\n",
    "        ('')\n",
    "        print('time_init shape = ', time_init.get_shape())\n",
    "        \"\"\"\n",
    "    \n",
    "        feed_dict = {Note_State_Batch: batch_input_state, timewise_state: timewise_state_val, notewise_state: notewise_state_val, time_init: 0, output_keep_prob: keep_prob}\n",
    "        #try:\n",
    "        loss_run, _ = sess.run([loss, optimizer], feed_dict=feed_dict)\n",
    "        #except:\n",
    "        #   save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "        #    print(\"Model saved in file: %s\" % save_path)\n",
    "        \n",
    "        print('epoch = ', epoch, '; loss = ', loss_run)\n",
    "        loss_hist.append(loss_run)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "    save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "    print(\" Final Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in range(len(tf.trainable_variables())):\n",
    "    print(tf.trainable_variables()[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1457"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8XXWd//HXJzc3e9KkSbqmuy1QoC00lH2RWllEiuMw\nFpRFdBh+ivgbHWdA/TnIjA6IjqgwVmQq4DAiOrIMVAuyWkRtgFK670u6Jk3bJE2zf35/3JtwG5L2\nNr3J3d7PxyOP3nPuued8ctO87zefs5m7IyIiqSUj3gWIiEjsKdxFRFKQwl1EJAUp3EVEUpDCXUQk\nBSncRURSkMJdRCQFKdxFRFKQwl1EJAVlxmvDZWVlPn78+HhtXkQkKb355pu17l5+tOXiFu7jx4+n\nqqoqXpsXEUlKZrYlmuXUlhERSUEKdxGRFKRwFxFJQXHruYtIYmtra6O6uprm5uZ4l5KWcnJyqKio\nIBgM9uv1UYW7mV0K/AAIAA+5+909nv8K8MmIdZ4ElLt7Xb+qEpG4q66uprCwkPHjx2Nm8S4nrbg7\ne/fupbq6mgkTJvRrHUdty5hZAHgAuAyYClxjZlN7FHKvu89w9xnAHcCrCnaR5Nbc3ExpaamCPQ7M\njNLS0uP6qymanvssYL27b3T3VuBxYO4Rlr8G+EW/KxKRhKFgj5/jfe+jCffRwLaI6erwvN6KyQMu\nBf7nuKo6gjW7Gvje82uobWwZqE2IiCS9WB8t81Hg9b5aMmZ2s5lVmVlVTU1NvzawoaaRH720XuEu\nkgYKCgoGfBvjx4+ntra2e/qVV17hiiuuAOCZZ57h7rvv7uulLF26lIULFw54jf0RTbhvB8ZETFeE\n5/VmHkdoybj7g+5e6e6V5eVHPXu2V8FAqOT2Dt3YW0QG1pVXXsntt9/e5/P9Cff29vbjLSsq0YT7\nEmCymU0wsyxCAf5Mz4XMbAhwIfB0bEs8XDAQ6kO1dnQO5GZEJEFt3ryZiy++mGnTpjF79my2bt0K\nwK9+9StOOeUUpk+fzgUXXADAihUrmDVrFjNmzGDatGmsW7fumLb18MMPc+utt/a6/tbWVr7xjW/w\ny1/+khkzZvDLX/6Suro6rrrqKqZNm8ZZZ53FsmXLALjzzju57rrrOPfcc7nuuuu44IILWLp0afd2\nzjvvPN55551YvD3djnoopLu3m9mtwCJCh0IucPcVZnZL+Pn54UU/Bjzv7gdjWmEPWeGRe1u7wl1k\nsHzzf1ewckd9TNc5dVQR//zRk4/5dV/4whe44YYbuOGGG1iwYAG33XYbTz31FHfddReLFi1i9OjR\n7N+/H4D58+fzxS9+kU9+8pO0trbS0dHR6zo/+MEPEggEAGhsbOTEE0983zI915+VlcVdd91FVVUV\n999/f3dtp512Gk899RQvvfQS119/fXeIr1y5ksWLF5Obm8sjjzzCww8/zH333cfatWtpbm5m+vTp\nx/xeHElUPXd3X+juU9x9krt/KzxvfkSw4+4Pu/u8mFbXi2BmONzVlhFJS2+88QbXXnstANdddx2L\nFy8G4Nxzz+XGG2/kpz/9aXeIn3322Xz729/mnnvuYcuWLeTm5va6zpdffpmlS5eydOlSHnrooV6X\n6W39PS1evJjrrrsOgIsvvpi9e/dSXx/6ULzyyiu7t3/11Vfz7LPP0tbWxoIFC7jxxhv792YcQdKd\nodrVc29TW0Zk0PRnhD3Y5s+fz5///Geee+45Zs6cyZtvvsm1117LmWeeyXPPPcfll1/OT37yEy6+\n+OKYrf9Y5Ofndz/Oy8tjzpw5PP300zzxxBPHvK5oJN21Zbp67gp3kfR0zjnn8PjjjwPw2GOPcf75\n5wOwYcMGzjzzTO666y7Ky8vZtm0bGzduZOLEidx2223MnTu3uwfeH72tv7CwkIaGhu5lzj//fB57\n7DEgdNRNWVkZRUVFva7vs5/9LLfddhtnnHEGJSUl/a6rL0k3cu/uuastI5LympqaqKio6J7+0pe+\nxI9+9CM+/elPc++991JeXs7PfvYzAL7yla+wbt063J3Zs2czffp07rnnHn7+858TDAYZMWIEX/3q\nV/tdS2/rHzt2LHfffTczZszgjjvu4M477+Smm25i2rRp5OXl8cgjj/S5vpkzZ1JUVMSnP/3pftd0\nJOYen5CsrKz0/tysY3PtQS767ivc94kZXHVar+dSiUgMrFq1ipNOOineZaSsHTt2cNFFF7F69Woy\nMnpvovT2MzCzN9298mjrT7q2TFZ4h2pLe+87NEREEt2jjz7KmWeeybe+9a0+g/14JV1bJjcYOlyp\nqVXhLiLJ6frrr+f6668f0G0k3cg9N0vhLjJY4tW2leN/75Mu3LMzMzCDQwp3kQGVk5PD3r17FfBx\n0HU995ycnH6vI+naMmZGXjCgkbvIAKuoqKC6upr+XuRPjk/XnZj6K+nCHSA/O5ODLYNz8R2RdBUM\nBvt9FyCJv6RrywAMyQ1y4FBbvMsQEUlYCncRkRSUlOFenBdkv8JdRKRPSRnuRblB6hXuIiJ9Sspw\nV1tGROTIkjbcG1vaadeVIUVEepWU4V6cGwSgvlmHQ4qI9CYpw31IXijc9ze1xrkSEZHElJzhHh65\nq+8uItI7hbuISApK0nDPAhTuIiJ9SdJw18hdRORIkjLci8M7VPcdVLiLiPQmKcM9GMigMCeTfTpa\nRkSkV1GFu5ldamZrzGy9md3exzIXmdlSM1thZq/Gtsz3K8nLUriLiPThqNdzN7MA8AAwB6gGlpjZ\nM+6+MmKZYuA/gEvdfauZDRuogruU5GdRd1DhLiLSm2hG7rOA9e6+0d1bgceBuT2WuRb4jbtvBXD3\nPbEt8/2G5gXZ36Seu4hIb6IJ99HAtojp6vC8SFOAEjN7xczeNLNeb+ttZjebWZWZVR3vrbtK8jRy\nFxHpS6x2qGYCM4GPAJcA/8/MpvRcyN0fdPdKd68sLy8/rg2W5Gfp8gMiIn2I5h6q24ExEdMV4XmR\nqoG97n4QOGhmrwHTgbUxqbIXJXlBDrZ20NzWQU4wMFCbERFJStGM3JcAk81sgpllAfOAZ3os8zRw\nnpllmlkecCawKralHq60IBtArRkRkV4cdeTu7u1mdiuwCAgAC9x9hZndEn5+vruvMrPfAcuATuAh\nd18+kIWX5ocuQbC3sZVRxbkDuSkRkaQTTVsGd18ILOwxb36P6XuBe2NX2pF1jdxrD7YM1iZFRJJG\nUp6hClDeFe4NCncRkZ6SNtxLC8JtGfXcRUTeJ2nDPS8rQE4wQyN3EZFeJG24mxllBdkauYuI9CJp\nwx1CO1VrGzVyFxHpKanDvbwgi9pGjdxFRHpK6nAvzc9mr0buIiLvk9zhXhC6eFhnp8e7FBGRhJLU\n4V5WkE17p+teqiIiPSR1uL93rLtaMyIikZI63Mu6zlLVTlURkcMkdbh3j9wV7iIih0nqcB+aFwp3\n3ShbRORwSR3uxV3hrrNURUQOk9ThnpWZQUF2Jvt0o2wRkcMkdbgDlOQH1ZYREekh+cM9L0u32hMR\n6SElwn2/Ru4iIodJ+nAfmp9FncJdROQwKRHutQ2tuOv6MiIiXZI+3EcV53KorUPXlxERiZD04T66\nOAeA6n2H4lyJiEjiSPpwH1WcC8CO/Qp3EZEuUYW7mV1qZmvMbL2Z3d7L8xeZ2QEzWxr++kbsS+2d\nwl1E5P0yj7aAmQWAB4A5QDWwxMyecfeVPRb9g7tfMQA1HlFpfhbZmRlsV7iLiHSLZuQ+C1jv7hvd\nvRV4HJg7sGVFz8wYOSSHnQea412KiEjCiCbcRwPbIqarw/N6OsfMlpnZb83s5JhUF6WRQ3IV7iIi\nEWK1Q/UtYKy7TwN+BDzV20JmdrOZVZlZVU1NTYw2DSOLc9ilcBcR6RZNuG8HxkRMV4TndXP3endv\nDD9eCATNrKznitz9QXevdPfK8vLy4yj7cCOKcthd36wTmUREwqIJ9yXAZDObYGZZwDzgmcgFzGyE\nmVn48azwevfGuti+DMkN0t7pHGrrGKxNiogktKMeLePu7WZ2K7AICAAL3H2Fmd0Sfn4+8NfA/zGz\nduAQMM8HcRhdlBsEoP5QO3lZR/2WRERSXlRJGG61LOwxb37E4/uB+2NbWvQKc0LfRn1zGyOG5MSr\nDBGRhJH0Z6gCFOV0jdx1fRkREUiVcA+3ZRqa2+NciYhIYkiNcI9oy4iISIqEe6HaMiIih0mRcO8a\nuastIyICKRLuOcEA2ZkZasuIiISlRLhDqDVTf0gjdxERSKFwL8rN1MhdRCQsdcI9J6gdqiIiYakT\n7rlB7VAVEQlLmXAvzg2yv6k13mWIiCSElAn3oflZ1DUq3EVEIIXCvTQ/i4aWdlraddlfEZHUCfeC\nbADqDmr0LiKSMuE+ND8LgL1qzYiIpE64lxaEwl0jdxGRFAr3rpG7wl1EJIXCvbSrLaNwFxFJnXAv\nygmSmWHsbWyJdykiInGXMuGekWGU5GepLSMiQgqFO4RaM2rLiIikWLgP1chdRARIsXAvLchWuIuI\nkGrhnp9FrXaoiohEF+5mdqmZrTGz9WZ2+xGWO8PM2s3sr2NXYvSG5mfR0NxOa3tnPDYvIpIwjhru\nZhYAHgAuA6YC15jZ1D6Wuwd4PtZFRqssfH2Z36/aTWenx6sMEZG4i2bkPgtY7+4b3b0VeByY28ty\nXwD+B9gTw/qOybDCULh/7rG3WPD6pniVISISd9GE+2hgW8R0dXheNzMbDXwM+HHsSjt2w4qyux9v\nrWuKYyUiIvEVqx2q9wH/5O5HbHab2c1mVmVmVTU1NTHa9HuGFeZ0Py7Izoz5+kVEkkU0CbgdGBMx\nXRGeF6kSeNzMAMqAy82s3d2filzI3R8EHgSorKyMeVO8LHxlSIDCnGCsVy8ikjSiCfclwGQzm0Ao\n1OcB10Yu4O4Tuh6b2cPAsz2DfTBkBt77Q8TRDlURSV9Hbcu4eztwK7AIWAU84e4rzOwWM7tloAs8\nVk9+7hwAmtt0OKSIpK+oGtPuvhBY2GPe/D6WvfH4y+q/08aWkBPMoLlN91IVkfSVUmeodskJBhTu\nIpLWUjPcMxXuIpLeUjLcc7MCHFLPXUTSWEqGe3ameu4ikt5SMtzVcxeRdJeS4Z4bDNCitoyIpLGU\nDPecYAaHNHIXkTSWouGutoyIpLeUDPfcYIDmdoW7iKSvlAz37GCAQ63quYtI+krJcM9VW0ZE0lxK\nhntpQRaNLe0KeBFJWykZ7uXh2+3tqW+JcyUiIvGRkuE+vCh0R6Y9Dc1xrkREJD5SMty7bpS9WyN3\nEUlTKRnuI8Ij950HDsW5EhGR+EjJcC/OC5ITzGDXAbVlRCQ9pWS4mxmjhuSyU+EuImkqJcMdYMSQ\nHHaoLSMiaSplw33kkFy1ZUQkbaVsuI8qzmF3fTPtHboMgYikn5QN95FDcul02NOgwyFFJP2kcLjr\ncEgRSV+pG+7FXeGuvruIpJ+owt3MLjWzNWa23sxu7+X5uWa2zMyWmlmVmZ0X+1KPzcghuQDs3K9w\nF5H0k3m0BcwsADwAzAGqgSVm9oy7r4xY7EXgGXd3M5sGPAGcOBAFR6soJ5P8rIAOhxSRtBTNyH0W\nsN7dN7p7K/A4MDdyAXdvdHcPT+YDTpyZGRUleWzd2xTvUkREBl004T4a2BYxXR2edxgz+5iZrQae\nA27qbUVmdnO4bVNVU1PTn3qPyaRh+WysPTjg2xERSTQx26Hq7k+6+4nAVcC/9LHMg+5e6e6V5eXl\nsdp0nyaVF7C1ronWdh3rLiLpJZpw3w6MiZiuCM/rlbu/Bkw0s7LjrO24TSzPp6PT2Vqn0buIpJdo\nwn0JMNnMJphZFjAPeCZyATP7gJlZ+PHpQDawN9bFHqtJ5QUArN+jcBeR9HLUo2Xcvd3MbgUWAQFg\ngbuvMLNbws/PBz4OXG9mbcAh4BMRO1jjZkJZPgAbahrjXImIyOA6argDuPtCYGGPefMjHt8D3BPb\n0o5fYU6Q4UXZbKzRyF1E0kvKnqHaZVJ5gUbuIpJ2Uj7cJ5bns7GmkQToEomIDJqUD/dJ5QXUN7dT\n29ga71JERAZNWoQ7aKeqiKSXlA/3ieWhI2a0U1VE0knKh/uoIbnkBgOs29MQ71JERAZNyod7RoYx\nZXgBa3Yp3EUkfaR8uAOcMKJQ4S4iaSVNwr2IvQdb2V2vG3eISHpIi3A/c8JQAJ5dtjPOlYiIDI60\nCPeTRxVx4ohC7nthLR2dOplJRFJfWoS7mXHjOeNpaGln+z7ddk9EUl9ahDvAB4bpZCYRSR9pE+46\nU1VE0knahHtJfhZlBVk6JFJE0kLahDvAqaOH8E71/niXISIy4NIq3GeMKWHdnkYamtviXYqIyIBK\nq3A/fVwx7lC1eV+8SxERGVBpFe5njB9KbjDAi6t3x7sUEZEBlVbhnhMMcNEJ5SxasVsnM4lISkur\ncAe4Ytooahpa+N93dsS7FBGRAZN24X7pKSMozMnk3kVr4l2KiMiASbtwD2QYV0wbxfb9h1i5oz7e\n5YiIDIiowt3MLjWzNWa23sxu7+X5T5rZMjN718z+aGbTY19q7PzDh6dgBi+u0o5VEUlNRw13MwsA\nDwCXAVOBa8xsao/FNgEXuvupwL8AD8a60FgqLchm6sginnx7O+7asSoiqSeakfssYL27b3T3VuBx\nYG7kAu7+R3fvOnj8T0BFbMuMvXmzxrKx9iBrd+taMyKSeqIJ99HAtojp6vC8vnwG+O3xFDUY5pw0\nHIDvv7A2zpWIiMReTHeomtkHCYX7P/Xx/M1mVmVmVTU1NbHc9DEbMSSHa2aN5XcrdvHWVp2xKiKp\nJZpw3w6MiZiuCM87jJlNAx4C5rr73t5W5O4Punulu1eWl5f3p96Y+vwHJ5EbDPC1J5fT3tEZ73JE\nRGImmnBfAkw2swlmlgXMA56JXMDMxgK/Aa5z96Tpc1SU5HHv1dNYtbOe/3hlQ7zLERGJmaOGu7u3\nA7cCi4BVwBPuvsLMbjGzW8KLfQMoBf7DzJaaWdWAVRxjl50ykuzMDP79hbVsrj0Y73JERGLC4nUo\nYGVlpVdVJcZnwEurd3PTw1XMPnEYD91QiZnFuyQRkV6Z2ZvuXnm05dLuDNXeXHzicM6ZVMqLq/fo\n6BkRSQkK97AFN57BsMJsfvjSeu5dtDre5YiIHBeFe1hOMMBvPncOAA+8vIEXVurSBCKSvBTuESpK\n8njz6x9i7NA8/vbRKj7/2FvxLklEpF8U7j2UFmTz1OfPBeC5d3fykR/+gea2jjhXJSJybBTuvRia\nn0XV1z8EwIod9cz+3qu6gqSIJBWFex/KCrLZ9G+X8+U5U9i+/xCfeaSKO37zLgcOtcW7NBGRo1K4\nH4GZ8YXZk3n2C+eRGwzwi79sZfo3n+dfn12pVo2IJDSdxBSljk7nx6+s57vPv3cc/N9UVnDVaaM5\ne2KpTnwSkUER7UlMCvdj5O58Z9EafhxxLZpJ5fnM/9RMJg8vjGNlIpIOFO4DrLPT+fTDS3h17XuX\nLj7vA2WcPraYScMKmFRewNjSPIpygnGsUkRSTbThnjkYxaSijAzjkZtmAbB6Vz1Pvb2D51fuYvFL\ntd3LnDa2mCc/d268ShSRNKYdqjFw4ogibr/sRF74+wv5uwsmkhFuv7+9dT9PL9V9WkVk8KktM0Be\nWbOHG3+2pHs6KzODmWNL+NePncKk8oI4ViYiyUw99wTw+vpa/rCulvmv9n4jkJNHFfHITbMoK8ge\n5MpEJFkp3BNIZ6ezoaaROd9/rdfnzcAd/uHDU7hwyjBOrRhCc1sHOcEAADUNLXR0OsGA8cLK3cyZ\nOpxSfSCIpCWFewJbt7uBYCCDn7y2gWXVB1ixo77X5QpzMvn46RU8/MfNAFx+6ggWvrsLgDPGl9DQ\n3M5vPncOueEPAR1rL5L6FO5JZE9DM29t2cefNtaxdncDa3c3UtvYcszrKcjOpLGlnQ+eUM4/f/Rk\nsjIzKMoNUpCdyctr9nDyyCKGFeUMwHcgAq3tnby2toaZ40ooyc+KdzkpS+Ge5Nydg60dvL11H9X7\nDvG959dS29jC966ezpThhXz+v98ikGFsiuK+r9MqhrCs+gAA40vzuOTkEdx47ng6Op2C7EyK8/SL\nKMfv2wtX8eBrGwGY/6mZzD5pGMFABodaO1jw+ib+9vyJZGXqAL3jpXBPI81tHXS6s3Z3Iw3NbTz+\nl2089+7O7ufHleaxZW9Tn6//zsen8TdnjBmMUlPey6v3sOD1TfzsxjPIDCRukP3oxXXUNLZwzayx\nrN3dAEDdwVY+dtpoMgMZFGQf+ykwH/nhH/psMQJ85rwJ/OfiTfzrVadwwohCdtc3c+6kMo3yj5HC\nXWjv6AQgM5DB3sYWfrt8F3/cUEtZQTZVm/excud7v4jLv3lJv36h5T0t7R2c8PXfdU9/6KRh/L8r\npgKwff8hpo4sSoi/kjbVHuSD333lqMvNO2MMV0wbxcbaRs6ZVMa2uiZ21TdTkJ3JpaeMYFn1fk4b\nU8Ku+maqtuzjtl+8fcT1lRVkUdvY2ufz18way/CibKZVDGFiWQHjy/KP9VtLCwp3icr8Vzdw92/f\nu2fsmKG53HTuBDo6neljiplUXkBxbpCMjPd21rr7oO+8XbHjAP/462WcN7mMv//QFLICGWRkGO6O\nO4fV16WmoYXCnMzuo44GWvW+Js675+UjLjOuNI/hhTn8ZXNd97yrZ1bw9rb9bKtr4rbZkxlVnENT\naweThxVSkJ1JWWEWwwpjt69k4bs7+VyS3GXsmllj+be/OjXeZSQUhbtExd15eukOXl1bw5Nvb4/6\ndZOHFTC6JJezJ5YSyDAmDy+kua2DsoIsGls6+P4La1m6bT8A3/7YqVxdWcFnHqniw1OH86mzxtHR\n6bR1dJKZYb22L/Y0NFOWn90d2uNvf+59y8yZOpyXVu+ho9M5f3IZo4bksn3/ITbUNPKDeafxNz95\ng0tOHs6PrjmdDINfLNnGx08fTV7WwPyF0jUi/v4npnPZKSNZ+O5Oqrbso72jkyeqqjGDcUPzqG9u\np+5g3yPYvowvzePlf7jofR+sre2dtHd2khXIiKoV9ETVNv7x18t46csX4sC63Y3kZwd4cdUeOt0p\nzc8mPzvAH9bVHnbtJAgdwdXQ3N7rej9y6khuv+xEXltXw++Wh47qKivIpraxhT+sq+31NdHYfPdH\n+v3aVKRwl37Zd7CVFTvq+dWb29ha18TuA820dTq1jS0M1H+VC6aUU5wbpO5gK4vXvz8EvnLJCdy7\naE1Mt5kVyGD2ScP4/idmxGxkv2ZXA5fc9xoPXHs6H5k28qjLNzS3caitg6KcIDv2H2JT7UEyMoz2\nDmdrXRMvrd7N6+v3vu91+VkBDrZ2ML40j3Gl+fxlUx2HwvcXGF2cy6jiHK6eOYaNtQeZWJbP4vW1\nbKlr4sNThzOiKIc/b9rLE1XVLP3GnEFtEzU0t9HZCZ3ulORn0dTazrrdjeyqb6ZyXAkLl+9i7oxR\nZAUyaG7r4OtPLefZZTvZ+O3LqWtq5ZE/buaLsycn9L6MwRDTcDezS4EfAAHgIXe/u8fzJwI/A04H\nvubu3z3aOhXuyWlbXRPlhdlU72tixY569ja28tvlOzl9XAk79jezY/8hhhdl88XZUyjIyWRvYwt3\n/3Y1+5vaMKPXHW5ZgQxaw/sHjuTLc6bwhdmTcXcOtXWw80Azm2sPcuLIIt7cso9vPbeS3fUtnDK6\niOXb67n4xGEsXldLa0cnE8ry2VR7kGGF2expeO8w04eur+RDU4fH5L15t/oAH71/MT+9vpI5MVqn\nu/PGhr38ZXMd9/1+XUzW2WXdty4jmMBBefOjVTy/cjfDi7LZXX/4ocFnTyzlohPKufCEcg61dnDy\nqCFkZWZ0X8fJzFi9q54ThhdiZjQ0t1EYvkJrS3sHre2d3YcOFybZlVtjFu5mFgDWAnOAamAJcI27\nr4xYZhgwDrgK2Kdwl2h19e9rGlowg2BGBvXNbbiHWjOtHZ0s3bYf99DRFrEaZW+ra+L877zcfaRQ\nZ6fT6d7rqLCz01mzu4GTRhYdcZ1vbqnj4z9+g0dumsWFU8pjUmckd6fToa2jky17myjJD7LrQDP7\nmtr43fJdPPX2dsYMzWVcaT6dnc4JIwp5fMm2XltAnzlvQvfO3kTV9TMaaLPGD2VYUTYzx5XQ0t7J\nzHEl5GQGGF+WRzCQQVtHJ4U5QVraOwhmZPS6f2cwxTLczwbudPdLwtN3ALj7v/Wy7J1Ao8JdEl1D\ncxun3vk8c6YO59U1Nd1/OXzlkhMYVpjNGxv20unOaWNLOHCojX9/YS3P3Hou0yqKu9fR2NJOdmYG\n7R1OVmYGf/fzKn6/ag+/+NuzOHtSaby+tT7FY0f48Wpu62D7/kMEzOh0Z92eRt7cso+HX98c1V97\nfelqbR2LQIZRmJNJS1sn48vyKckL4g752QHu+fi0QbskSCyv5z4a2BYxXQ2c2c+ibgZuBhg7dmx/\nViESEwXZmVSOK+GFlbsPm9+zt//U0h3dj6+8/3Xg6G2kRD1RJ9mCHSAnGDjsKqoTywu45OQRfPXy\nk474usaWdnIyQzuYDzS10drRSXFe6C+dUcW5ZBis3tVAQXYmW+ua2FrXxM4DzSzffoAzJwzl6aU7\nWLmznlnjh7JixwEOtnYwJLxfCGDVzsPbiz94cR13zT0l9m/AcRjUA5vd/UHgQQiN3Adz2yKRzIxH\nPzOLJ9/eTl1jKxtrD1K9r4mVO+p7HdF9YFgB6/c0Ahx1xJifPTiHXkrfIs/ZGJL3Xk99zNC87sdd\nbbYxQ/PoeUudv7twUq/rbWnvoKPTyTAjJxjA3fmrH/+RR9/Ywltb9zFjTDFZgQCjS3IpL8xmU81B\nVu48wM0XTGRcaT71h9oozc8+rKaBEk24bwciT1+sCM8TSWp5WZl88sxxR10ucmdcR6cTyDC27D1I\nIMPYXd/M7voWsgIZTB1VxLLqA5yge+mmrOzMwz+4zYxPVI5h1c56lm8PffVm0YrD/0K8/bITuaWP\nD5BYiSbclwCTzWwCoVCfB1w7oFWJJJDIoykC4Z1p40pDZ09WlOQdtuyo4tzBK0wSwrxZY5k3ayxt\nHZ28uGrGhyLPAAAFVklEQVQ3eVmZDMkN8uTb28kOZnDhlHIWLd9FR3j/5n/9aSvTKoYMeF3RHgp5\nOXAfoUMhF7j7t8zsFgB3n29mI4AqoAjoBBqBqe7e54UmtENVROTYxfQG2e6+EFjYY978iMe7CLVr\nREQkASTmbn0RETkuCncRkRSkcBcRSUEKdxGRFKRwFxFJQQp3EZEUpHAXEUlBcbtZh5nVAFv6+fIy\noP+3dhk8qjO2VGfsJEONoDp7M87dj3pN6biF+/Ews6poztCKN9UZW6ozdpKhRlCdx0NtGRGRFKRw\nFxFJQcka7g/Gu4Aoqc7YUp2xkww1gurst6TsuYuIyJEl68hdRESOIOnC3cwuNbM1ZrbezG6PYx1j\nzOxlM1tpZivM7Ivh+UPN7AUzWxf+tyTiNXeE615jZpcMcr0BM3vbzJ5N1DrNrNjMfm1mq81slZmd\nnaB1/n34Z77czH5hZjmJUKeZLTCzPWa2PGLeMddlZjPN7N3wcz+0GN98tY867w3/3JeZ2ZNmVhzx\n3KDX2VuNEc992czczMriWeNRuXvSfBG6WcgGYCKQBbxD6KYg8ahlJHB6+HEhsBaYCnwHuD08/3bg\nnvDjqeF6s4EJ4e8jMIj1fgn4b+DZ8HTC1Qk8Anw2/DgLKE60OgndMH4TkBuefgK4MRHqBC4ATgeW\nR8w75rqAvwBnAQb8FrhsEOr8MJAZfnxPvOvsrcbw/DHAIkLn6JTF+7080leyjdxnAevdfaO7twKP\nA3PjUYi773T3t8KPG4BVhH7x5xIKKcL/XhV+PBd43N1b3H0TsJ7Q9zPgzKwC+AjwUMTshKrTzIYQ\n+oX6TwB3b3X3/YlWZ1gmkGtmmUAesCMR6nT314C6HrOPqS4zGwkUufufPJROj0a8ZsDqdPfn3b09\nPPkn3rv5T1zq7OO9BPg+8I9A5M7KuL2XR5Js4T4a2BYxXR2eF1dmNh44DfgzMNzdd4af2gUMDz+O\nZ+33EfoP2RkxL9HqnADUAD8Lt48eMrP8RKvT3bcD3wW2AjuBA+7+fKLVGeFY6xodftxz/mC6idAo\nFxKoTjObC2x393d6PJUwNUZKtnBPOGZWAPwP8H+9xz1jw5/WcT0cycyuAPa4+5t9LZMIdRIaDZ8O\n/NjdTwMOEmojdEuEOsM967mEPoxGAflm9qnIZRKhzt4kal2RzOxrQDvwWLxriWRmecBXgW/Eu5Zo\nJVu4byfU8+pSEZ4XF2YWJBTsj7n7b8Kzd4f/HCP8757w/HjVfi5wpZltJtTGutjM/isB66wGqt39\nz+HpXxMK+0Sr80PAJnevcfc24DfAOQlYZ5djrWs7h98PedDqNbMbgSuAT4Y/iCBx6pxE6AP9nfDv\nUgXwlpmNSKAaD5Ns4b4EmGxmE8wsC5gHPBOPQsJ7vf8TWOXu/x7x1DPADeHHNwBPR8yfZ2bZZjYB\nmExoZ8uAcvc73L3C3ccTer9ecvdPJWCdu4BtZnZCeNZsYGWi1UmoHXOWmeWF/w/MJrS/JdHq7HJM\ndYVbOPVmdlb4+7s+4jUDxswuJdQ6vNLdm3rUH/c63f1ddx/m7uPDv0vVhA6o2JUoNfZWdFJ9AZcT\nOjJlA/C1ONZxHqE/cZcBS8NflwOlwIvAOuD3wNCI13wtXPcaBnGvecT2L+K9o2USrk5gBlAVfk+f\nAkoStM5vAquB5cDPCR0lEfc6gV8Q2g/QRih8PtOfuoDK8Pe2Abif8MmOA1znekJ9667fpfnxrLO3\nGns8v5nw0TLxfC+P9KUzVEVEUlCytWVERCQKCncRkRSkcBcRSUEKdxGRFKRwFxFJQQp3EZEUpHAX\nEUlBCncRkRT0/wG752zIDVdHKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64457c06d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist, label=\"Loss History\")\n",
    "plt.legend()\n",
    "plt.show\n",
    "len(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: Practice_Dropout\n",
      "INFO:tensorflow:Restoring parameters from model/Practice_Dropout\n",
      "Timestep =  0\n",
      "Timestep =  50\n",
      "Timestep =  100\n",
      "Timestep =  150\n",
      "Timestep =  200\n",
      "Timestep =  250\n",
      "(5, 78, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# Music Generation\n",
    "# input = initial note vector\n",
    "# for t = 1:Tsong\n",
    "#    input --> input kernel\n",
    "#    run through 1 'call' of Model LSTM with present parameters / states\n",
    "#    run through note-wise LSTM block as normally done to produce vector of generated samples\n",
    "#    input = generated samples\n",
    "#    music_sequence.append(input)\n",
    "\n",
    "# store batch of music sequences in .MIDI files\n",
    "\n",
    "\n",
    "#Load Model\n",
    "restore_model_name = 'Practice_Dropout'\n",
    "\n",
    "#Length of generated music\n",
    "T_gen = 16*16\n",
    "batch_gen_size = 5\n",
    "keep_prob = 1\n",
    "\n",
    "# start with initial Note_State_Batch with 't' dimension = 1 (can still a batch of samples run in parallel)\n",
    "notes_gen_initial = np.zeros((batch_gen_size, num_notes, 1,2))\n",
    "\n",
    "# Initial States\n",
    "notes_gen = notes_gen_initial\n",
    "    \n",
    "timewise_state_val=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    c = np.zeros((batch_gen_size*num_notes, num_t_units[i])) #start every batch with zero state in LSTM time cells\n",
    "    h = np.zeros((batch_gen_size*num_notes, num_t_units[i]))\n",
    "    timewise_state_val.append(LSTMStateTuple(h, c))\n",
    "        \n",
    "notewise_state_val=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    c = np.zeros((batch_gen_size*1, num_n_units[i])) #start every batch with zero state in LSTM time cells\n",
    "    h = np.zeros((batch_gen_size*1, num_n_units[i]))\n",
    "    notewise_state_val.append(LSTMStateTuple(h, c))\n",
    "        \n",
    "notes_gen_arr=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    print(\"Load the model from: {}\".format(restore_model_name))\n",
    "    saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "\n",
    "    for t in range(T_gen):\n",
    "        feed_dict = {Note_State_Batch: notes_gen, timewise_state: timewise_state_val, notewise_state: notewise_state_val, time_init: t % 16, output_keep_prob: keep_prob}    \n",
    "        timewise_state_val, notes_gen = np.squeeze(sess.run([timewise_state_out, note_gen_out], feed_dict = feed_dict), axis=2)\n",
    "        #print('notes_gen shape = ', notes_gen.shape)\n",
    "        #notes_gen = np.squeeze(notes_gen, axis=2)\n",
    "        notes_gen_arr.append(np.squeeze(notes_gen))\n",
    "        \n",
    "        \n",
    "        if t % 50 == 0:\n",
    "            print('Timestep = ', t)\n",
    "    \n",
    "notes_gen_out = np.stack(notes_gen_arr, axis=2)\n",
    "print(notes_gen_out.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 256, 78, 2)\n"
     ]
    }
   ],
   "source": [
    "# Save Generate Notes to .MIDI file\n",
    "\n",
    "notes_gen_out = np.swapaxes(notes_gen_out, axis1=1, axis2=2)\n",
    "print(notes_gen_out.shape)\n",
    "#_, notes_gen_out = Utils.multi_training.getPieceBatch(training_pieces)\n",
    "\n",
    "\n",
    "#print(test_batch.shape)\n",
    "for iter in range(3):\n",
    "    file = 'Generated_Midi_Files/PracticeDropout' + str(iter+3)\n",
    "    midi_out = midi_musical_matrix.noteStateMatrixToMidi(notes_gen_out[iter,:,:,:], name=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to Experiment with:\n",
    "- different T length or variable length T from batch-to-batch for training\n",
    "- categorize music, either through (unsupervised) clustering or (supervised) labeled music folders.  For clustering, the model would possibly find 'k' 'centroids' in an unsupervised manner each with its own music distribution, so during the music generation stage, 1 of these centroids would be selected for a piece of music.  \n",
    "- use encoder to reduce dimensionality of each note vector (vector of 79 notes in 1 time step), similiar to encoding the words from the tweets in homework 3 (i.e. there are restricted combinations of notes that can be played simultaneously)\n",
    "- more advanced sampling/exploring for training/music generation.  This may help prevent the algorithm from getting 'stuck' on a chord, or "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
