{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#% reset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import midi_musical_matrix\n",
    "import data\n",
    "import multi_training\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "from MyFunctions import Input_Kernel, LSTM_TimeWise_Training_Layer, LSTM_NoteWise_Layer, Loss_Function\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 01Allemande\n",
      "Loaded 01Prelude\n",
      "Loaded 02Ichdankdir\n",
      "Loaded 04Allemande\n",
      "Loaded 04Bourree\n",
      "Loaded 04Prelude\n",
      "Loaded 05AnWasserflussen\n",
      "Loaded 08Freueteuch\n",
      "Loaded 09Ermuntredich\n",
      "Loaded 10AustieferNot\n",
      "Loaded 11Jesu\n",
      "Loaded 13Alleinzudir\n",
      "Loaded 14OHerreGott\n",
      "Loaded 15ChristlaginTode\n",
      "Loaded BRAND1\n",
      "Loaded BRAND3\n",
      "Loaded BRAND43\n",
      "Loaded BRAND51\n",
      "Loaded BRAND52\n",
      "Loaded BRAND53\n",
      "Loaded BSGJG_B\n",
      "Loaded BSGJG_G\n",
      "Loaded BSGJG_H\n",
      "Loaded BSGJG_I\n",
      "Loaded BSGJG_J\n",
      "Loaded BSGJG_K\n",
      "Loaded can4\n",
      "Loaded cap2\n",
      "Loaded catech1\n",
      "Loaded catech10\n",
      "Loaded catech6\n",
      "Loaded catech7\n",
      "Loaded catech8\n",
      "Loaded catech9\n",
      "Loaded cnt1 (1)\n",
      "Loaded cnt1\n",
      "Loaded cnt2\n",
      "Loaded cnt3\n",
      "Loaded dou1\n",
      "Loaded dou2\n",
      "Loaded Fugue1 (1)\n",
      "Loaded Fugue1\n",
      "Skip bad file =  Fugue11\n",
      "Loaded Fugue12 (1)\n",
      "Skip bad file =  Fugue12\n",
      "Skip bad file =  Fugue13\n",
      "Skip bad file =  Fugue15\n",
      "Loaded Fugue16\n",
      "Loaded Fugue17\n",
      "Loaded Fugue18\n",
      "Skip bad file =  Fugue19\n",
      "Loaded Fugue2\n",
      "Loaded Fugue20\n",
      "Loaded Fugue22\n",
      "Loaded Fugue23\n",
      "Loaded Fugue24\n",
      "Loaded Fugue3 (1)\n",
      "Loaded Fugue3\n",
      "Loaded Fugue4\n",
      "Loaded Fugue5 (1)\n",
      "Loaded Fugue5\n",
      "Skip bad file =  Fugue6\n",
      "Loaded Fugue7 (1)\n",
      "Loaded Fugue7\n",
      "Loaded Fugue8 (1)\n",
      "Loaded Fugue8\n",
      "Loaded Fugue9 (1)\n",
      "Loaded Fugue9\n",
      "Loaded fuguecm\n",
      "Loaded fuguegm\n",
      "Loaded gig1\n",
      "Loaded invent1\n",
      "Loaded invent11\n",
      "Loaded invent13\n",
      "Loaded invent14\n",
      "Loaded invent15\n",
      "Loaded invent2\n",
      "Loaded invent5\n",
      "Loaded invent7\n",
      "Loaded inver1\n",
      "Loaded inver2\n",
      "Loaded mir2\n",
      "Loaded orgel19\n",
      "Loaded pre1\n",
      "Loaded prefug1\n",
      "Loaded prefug2\n",
      "Loaded prefug3\n",
      "Loaded prefug5\n",
      "Loaded prefug7\n",
      "Loaded prefug8\n",
      "Loaded Prelude1 (1)\n",
      "Loaded Prelude1\n",
      "Loaded Prelude10\n",
      "Loaded Prelude12 (1)\n",
      "Loaded Prelude12\n",
      "Skip bad file =  Prelude13\n",
      "Skip bad file =  Prelude14\n",
      "Skip bad file =  Prelude15\n",
      "Loaded Prelude16\n",
      "Skip bad file =  Prelude19\n",
      "Loaded Prelude2 (1)\n",
      "Loaded Prelude2\n",
      "Skip bad file =  Prelude20\n",
      "Loaded Prelude21\n",
      "Loaded Prelude22\n",
      "Loaded Prelude23\n",
      "Skip bad file =  Prelude24\n",
      "Loaded Prelude3 (1)\n",
      "Loaded Prelude5\n",
      "Loaded Prelude6\n",
      "Loaded Prelude7\n",
      "Loaded Prelude8 (1)\n",
      "Loaded reg1\n",
      "Loaded reg2\n",
      "Loaded schub5\n",
      "Loaded schub6\n",
      "Loaded sin2\n",
      "Loaded sinfon1 (1)\n",
      "Loaded sinfon1\n",
      "Loaded sinfon12\n",
      "Loaded sinfon14\n",
      "Loaded sinfon3\n",
      "Loaded sinfon4\n",
      "Loaded sinfon8\n",
      "Loaded sinfon9\n",
      "Loaded toccata1\n",
      "Loaded toccata2\n",
      "Loaded tri1\n",
      "Loaded tri2\n",
      "Loaded trio3a\n",
      "Loaded unfin\n",
      "\n",
      "Number of training pieces =  119\n",
      "Sample of State Input Batch: shape =  (15, 78, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "# Import All Training Data\n",
    "# Convert Entire Music .MIDI set to list of musical 'pieces'\n",
    "# During training runs, getPieceBatch will return a tensor for Note_State_Batch, and corresponding Note_State_Expand\n",
    "# Note_State_Expand will be fed into the graph input, and Note_State_Batch will be used for the loss function.\n",
    "\n",
    "# Import Midi files to list\n",
    "Working_Directory = os.getcwd()\n",
    "Training_Midi_Folder = Working_Directory + \"/Midi_Files/Bach\"\n",
    "max_time_steps = 256 # only files atleast this many 16th note steps are saved\n",
    "\n",
    "practice_batch_size = 15\n",
    "practice_num_timesteps = 128\n",
    "\n",
    "\n",
    "training_pieces = multi_training.loadPieces(Training_Midi_Folder, max_time_steps)\n",
    "print('')\n",
    "print('Number of training pieces = ', len(training_pieces))\n",
    "\n",
    "# Generate sample Note State Matrix for dimension measurement and numerical checking purposes\n",
    "# (Using external code to generate the Note State Matrix but using our own NoteInputForm (as defined in author's code) function\n",
    "_, sample_state = multi_training.getPieceBatch(training_pieces, practice_batch_size, practice_num_timesteps)\n",
    "sample_state = np.array(sample_state)\n",
    "sample_state = np.swapaxes(sample_state, axis1=1, axis2=2)\n",
    "print('Sample of State Input Batch: shape = ', sample_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note_State_Batch Placeholder Shape =  (?, 78, ?, 2)\n",
      "Note_State_Expand output Shape =  (?, 78, ?, 80)\n"
     ]
    }
   ],
   "source": [
    "# Beginning of Model Graph:\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#input_size = sample_state.shape[-1]\n",
    "num_notes = sample_state.shape[1]\n",
    "\n",
    "\n",
    "#place holder inputs\n",
    "# num_batches and num_time steps are variable lengths.  These values do not affect the model parameters\n",
    "# Dimension(0) =  num_batches. Dimension(2) = num_time_steps\n",
    "\n",
    "#final_t_sample_run = np.zeros((batch_size, num_notes, 1, 2)) #start every batch with zero previous input\n",
    "\n",
    "\n",
    "        \n",
    "Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 2])\n",
    "#prev_t_sample = tf.placeholder(dtype=tf.float32, shape=[None, num_notes,1,2])\n",
    "time_init = tf.placeholder(dtype=tf.int32, shape=())\n",
    "#Generates expanded tensor input to LSTM-timewise layer\n",
    "Note_State_Expand = Input_Kernel(Note_State_Batch, Midi_low=24, Midi_high=101, time_init=time_init)\n",
    "\n",
    "print('Note_State_Batch Placeholder Shape = ', Note_State_Batch.get_shape())\n",
    "print('Note_State_Expand output Shape = ', Note_State_Expand.get_shape())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_expand shape =  (15, 78, 128, 80)\n",
      "MIDI note_0, t_0 =  [ 24.]\n",
      "MIDI note_1, t_0 =  [ 25.]\n",
      "MIDI note_2, t_0 =  [ 26.]\n",
      "MIDI note_0, t_0 =  [ 24.]\n",
      "MIDI note_0, t_1 =  [ 24.]\n",
      "MIDI note_0, t_29 =  [ 24.]\n",
      "\n",
      "pitchclass note_0, t_0 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_1, t_0 =  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_11, t_0 =  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "pitchclass note_0, t_0 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_0, t_1 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "pitchclass note_0, t_29 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "sample state local vicinity =  [[1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "calculated vicinity note_45, t_29 =  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "calculated context note_45, t_29 =  [ 0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.]\n",
      "actual all note plays at, t_29 =  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0]\n",
      "\n",
      "beat note_0, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_1, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_2, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_0, t_0 =  [ 1.  0.  0.  0.]\n",
      "beat note_0, t_1 =  [ 0.  1.  0.  0.]\n",
      "beat note_0, t_29 =  [ 0.  1.  1.  1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Input Kernel on sample data\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sample_expand = sess.run(Note_State_Expand, feed_dict={Note_State_Batch: sample_state, time_init: 1})\n",
    "\n",
    "\n",
    "\n",
    "#check MIDI note\n",
    "print('sample_expand shape = ', sample_expand.shape)\n",
    "print('MIDI note_0, t_0 = ', sample_expand[0,0,0,[0]]) \n",
    "print('MIDI note_1, t_0 = ', sample_expand[0,1,0,[0]])  \n",
    "print('MIDI note_2, t_0 = ', sample_expand[0,2,0,[0]]) \n",
    "\n",
    "print('MIDI note_0, t_0 = ', sample_expand[0,0,0,[0]]) \n",
    "print('MIDI note_0, t_1 = ', sample_expand[0,0,1,[0]])  \n",
    "print('MIDI note_0, t_29 = ', sample_expand[0,0,29,[0]]) \n",
    "print('') \n",
    "\n",
    "#check pitchclass\n",
    "print('pitchclass note_0, t_0 = ', sample_expand[0,0,0,1:13]) \n",
    "print('pitchclass note_1, t_0 = ', sample_expand[0,1,0,1:13])  \n",
    "print('pitchclass note_11, t_0 = ', sample_expand[0,11,0,1:13]) \n",
    "\n",
    "print('pitchclass note_0, t_0 = ', sample_expand[0,0,0,1:13]) \n",
    "print('pitchclass note_0, t_1 = ', sample_expand[0,0,1,1:13])  \n",
    "print('pitchclass note_0, t_29 = ', sample_expand[0,0,29,1:13]) \n",
    "print('') \n",
    "\n",
    "#check vicinity\n",
    "print('sample state local vicinity = ', sample_state[0,33:58,29,:])\n",
    "print('calculated vicinity note_45, t_29 = ', sample_expand[0,45,29,13:63])\n",
    "print('')\n",
    "\n",
    "#check  context\n",
    "print('calculated context note_45, t_29 = ', sample_expand[0,45,29,63:75])\n",
    "print('actual all note plays at, t_29 = ', sample_state[0,:,29,0])\n",
    "print('')\n",
    "\n",
    "#check beat\n",
    "print('beat note_0, t_0 = ', sample_expand[0,0,0,75:79]) \n",
    "print('beat note_1, t_0 = ', sample_expand[0,1,0,75:79])  \n",
    "print('beat note_2, t_0 = ', sample_expand[0,2,0,75:79]) \n",
    "\n",
    "print('beat note_0, t_0 = ', sample_expand[0,0,0,75:79]) \n",
    "print('beat note_0, t_1 = ', sample_expand[0,0,1,75:79])  \n",
    "print('beat note_0, t_29 = ', sample_expand[0,0,29,75:79]) \n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-wise output shape =  (?, 78, ?, 200)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#lSTM Time Wise Training Graph \n",
    "#tf.reset_default_graph()\n",
    "#Note_State_Expand = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 80])\n",
    "#Note_State_Expand_val = np.ones((10,78,128,80))\n",
    "\n",
    "num_t_units=[300,200]\n",
    "output_keep_prob = tf.placeholder(dtype=tf.float32, shape=())\n",
    "\n",
    "# Generate initial state (at t=0) placeholder\n",
    "timewise_state=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    timewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]]) #None = batch_size * num_notes\n",
    "    timewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]])\n",
    "    timewise_state.append(LSTMStateTuple(timewise_h, timewise_c))\n",
    "\n",
    "timewise_state=tuple(timewise_state)\n",
    "\n",
    "\n",
    "timewise_out, timewise_state_out = LSTM_TimeWise_Training_Layer(input_data=Note_State_Expand, state_init=timewise_state, output_keep_prob=output_keep_prob)\n",
    "\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())\n",
    "print(len(timewise_state_out))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_out shape =  (?, 78, ?, 2, 2)\n",
      "generated samples shape =  (?, 78, ?, 2)\n"
     ]
    }
   ],
   "source": [
    "#LSTM Note Wise Graph\n",
    "#tf.reset_default_graph()\n",
    "#timewise_out = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 50])\n",
    "#output_keep_prob=1\n",
    "num_n_units = [100,50]\n",
    "\n",
    "# Generate initial state (at n=0) placeholder\n",
    "notewise_state=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    notewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]]) #None = batch_size * num_timesteps\n",
    "    notewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]])\n",
    "    notewise_state.append(LSTMStateTuple(notewise_h, notewise_c))\n",
    "\n",
    "notewise_state=tuple(notewise_state)\n",
    "\n",
    "\n",
    "y_out, note_gen_out = LSTM_NoteWise_Layer(timewise_out, state_init=notewise_state, output_keep_prob=output_keep_prob)\n",
    "\n",
    "\n",
    "print('y_out shape = ', y_out.get_shape())\n",
    "print('generated samples shape = ', note_gen_out.get_shape())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_align shape = :  (?, ?, ?, ?, ?)\n",
      "Note_State_Batch_align shape = :  (?, ?, ?, ?)\n"
     ]
    }
   ],
   "source": [
    "# Loss Function and Optimizer\n",
    "\n",
    "#y_out_val = np.random.randn(1, 78, 128, 2, 2)*5\n",
    "\n",
    "\n",
    "loss, cross_entropy = Loss_Function(Note_State_Batch, y_out)\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate = 1).minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run(tf.global_variables_initializer())\n",
    "#    cross_entropy_out, loss_out = sess.run([cross_entropy, loss], feed_dict={y_out: y_out_val, Note_State_Batch: batch_input_state})\n",
    "#print('cross entropy shape = ', cross_entropy_out.shape)\n",
    "#print('loss = ', loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining new batch of pieces\n",
      "epoch =  0 ; loss =  0.689041\n",
      "Model saved in file: model/NoteGen_Fix\n",
      "epoch =  1 ; loss =  0.669605\n",
      "epoch =  2 ; loss =  0.656091\n",
      "epoch =  3 ; loss =  0.650238\n",
      "epoch =  4 ; loss =  0.641927\n",
      "epoch =  5 ; loss =  0.633967\n",
      "epoch =  6 ; loss =  0.627989\n",
      "epoch =  7 ; loss =  0.620979\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ca502b27acac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mNote_State_Batch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_input_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimewise_state\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtimewise_state_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotewise_state\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnotewise_state_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_init\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_keep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m#try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mloss_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;31m#except:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m#   save_path = saver.save(sess, 'model/{}'.format(save_model_name))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "N_epochs = 2000\n",
    "loss_hist=[]\n",
    "restore_model_name = None\n",
    "save_model_name = 'NoteGen_Fix'\n",
    "batch_size = 3\n",
    "num_timesteps = 32\n",
    "keep_prob=.5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # try to restore the pre_trained\n",
    "    if restore_model_name is not None:\n",
    "        print(\"Load the model from: {}\".format(restore_model_name))\n",
    "        saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "    # Initial States\n",
    "    timewise_state_val=[]\n",
    "    for i in range(len(num_t_units)):\n",
    "        c_t = np.zeros((batch_size*num_notes, num_t_units[i])) #start every batch with zero state in LSTM time cells\n",
    "        h_t = np.zeros((batch_size*num_notes, num_t_units[i]))\n",
    "        timewise_state_val.append(LSTMStateTuple(h_t, c_t))\n",
    "        \n",
    "    notewise_state_val=[]\n",
    "    for i in range(len(num_n_units)):\n",
    "        c_n = np.zeros((batch_size*num_timesteps, num_n_units[i])) #start every batch with zero state in LSTM time cells\n",
    "        h_n = np.zeros((batch_size*num_timesteps, num_n_units[i]))\n",
    "        notewise_state_val.append(LSTMStateTuple(h_n, c_n))\n",
    "    \n",
    "  \n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(N_epochs):\n",
    "        \n",
    "        #Generate random batch of training data\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print('Obtaining new batch of pieces')\n",
    "            _, batch_input_state = multi_training.getPieceBatch(training_pieces, batch_size, num_timesteps) # not using their 'convolution' filter\n",
    "            batch_input_state = np.array(batch_input_state)\n",
    "            batch_input_state = np.swapaxes(batch_input_state, axis1=1, axis2=2)           \n",
    "     \n",
    "        \n",
    "        \"\"\"\n",
    "        print('Note_State_Batch shape = ', Note_State_Batch.get_shape())\n",
    "        print('batch_input_state shape = ', batch_input_state.shape)\n",
    "        print('')\n",
    "        print('timewise_state shape = ', Note_State_Batch.get_shape())\n",
    "        print('timewise_state_val shape = ', batch_input_state.shape)      \n",
    "        print('')\n",
    "        print('notewise_state shape = ', Note_State_Batch.get_shape())\n",
    "        print('notewise_state_val shape = ', batch_input_state.shape)\n",
    "        ('')\n",
    "        print('time_init shape = ', time_init.get_shape())\n",
    "        \"\"\"\n",
    "    \n",
    "        feed_dict = {Note_State_Batch: batch_input_state, timewise_state: timewise_state_val, notewise_state: notewise_state_val, time_init: 0, output_keep_prob: keep_prob}\n",
    "        #try:\n",
    "        loss_run, _ = sess.run([loss, optimizer], feed_dict=feed_dict)\n",
    "        #except:\n",
    "        #   save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "        #    print(\"Model saved in file: %s\" % save_path)\n",
    "        \n",
    "        print('epoch = ', epoch, '; loss = ', loss_run)\n",
    "        loss_hist.append(loss_run)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "    save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "    print(\" Final Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in range(len(tf.trainable_variables())):\n",
    "    print(tf.trainable_variables()[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1457"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEUlBCncRkRT0/wG752zIDVdHKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64457c06d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist, label=\"Loss History\")\n",
    "plt.legend()\n",
    "plt.show\n",
    "len(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: Practice_Dropout\n",
      "INFO:tensorflow:Restoring parameters from model/Practice_Dropout\n",
      "Timestep =  0\n",
      "Timestep =  50\n",
      "Timestep =  100\n",
      "Timestep =  150\n",
      "Timestep =  200\n",
      "Timestep =  250\n",
      "(5, 78, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# Music Generation\n",
    "# input = initial note vector\n",
    "# for t = 1:Tsong\n",
    "#    input --> input kernel\n",
    "#    run through 1 'call' of Model LSTM with present parameters / states\n",
    "#    run through note-wise LSTM block as normally done to produce vector of generated samples\n",
    "#    input = generated samples\n",
    "#    music_sequence.append(input)\n",
    "\n",
    "# store batch of music sequences in .MIDI files\n",
    "\n",
    "\n",
    "#Load Model\n",
    "restore_model_name = 'Practice_Dropout'\n",
    "\n",
    "#Length of generated music\n",
    "T_gen = 16*16\n",
    "batch_gen_size = 5\n",
    "keep_prob = 1\n",
    "\n",
    "# start with initial Note_State_Batch with 't' dimension = 1 (can still a batch of samples run in parallel)\n",
    "notes_gen_initial = np.zeros((batch_gen_size, num_notes, 1,2))\n",
    "\n",
    "# Initial States\n",
    "notes_gen = notes_gen_initial\n",
    "    \n",
    "timewise_state_val=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    c = np.zeros((batch_gen_size*num_notes, num_t_units[i])) #start every batch with zero state in LSTM time cells\n",
    "    h = np.zeros((batch_gen_size*num_notes, num_t_units[i]))\n",
    "    timewise_state_val.append(LSTMStateTuple(h, c))\n",
    "        \n",
    "notewise_state_val=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    c = np.zeros((batch_gen_size*1, num_n_units[i])) #start every batch with zero state in LSTM time cells\n",
    "    h = np.zeros((batch_gen_size*1, num_n_units[i]))\n",
    "    notewise_state_val.append(LSTMStateTuple(h, c))\n",
    "        \n",
    "notes_gen_arr=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    print(\"Load the model from: {}\".format(restore_model_name))\n",
    "    saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "\n",
    "    for t in range(T_gen):\n",
    "        feed_dict = {Note_State_Batch: notes_gen, timewise_state: timewise_state_val, notewise_state: notewise_state_val, time_init: t % 16, output_keep_prob: keep_prob}    \n",
    "        timewise_state_val, notes_gen = np.squeeze(sess.run([timewise_state_out, note_gen_out], feed_dict = feed_dict), axis=2)\n",
    "        #print('notes_gen shape = ', notes_gen.shape)\n",
    "        #notes_gen = np.squeeze(notes_gen, axis=2)\n",
    "        notes_gen_arr.append(np.squeeze(notes_gen))\n",
    "        \n",
    "        \n",
    "        if t % 50 == 0:\n",
    "            print('Timestep = ', t)\n",
    "    \n",
    "notes_gen_out = np.stack(notes_gen_arr, axis=2)\n",
    "print(notes_gen_out.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 256, 78, 2)\n"
     ]
    }
   ],
   "source": [
    "# Save Generate Notes to .MIDI file\n",
    "\n",
    "notes_gen_out = np.swapaxes(notes_gen_out, axis1=1, axis2=2)\n",
    "print(notes_gen_out.shape)\n",
    "#_, notes_gen_out = Utils.multi_training.getPieceBatch(training_pieces)\n",
    "\n",
    "\n",
    "#print(test_batch.shape)\n",
    "for iter in range(3):\n",
    "    file = 'Generated_Midi_Files/PracticeDropout' + str(iter+3)\n",
    "    midi_out = midi_musical_matrix.noteStateMatrixToMidi(notes_gen_out[iter,:,:,:], name=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to Experiment with:\n",
    "- different T length or variable length T from batch-to-batch for training\n",
    "- categorize music, either through (unsupervised) clustering or (supervised) labeled music folders.  For clustering, the model would possibly find 'k' 'centroids' in an unsupervised manner each with its own music distribution, so during the music generation stage, 1 of these centroids would be selected for a piece of music.  \n",
    "- use encoder to reduce dimensionality of each note vector (vector of 79 notes in 1 time step), similiar to encoding the words from the tweets in homework 3 (i.e. there are restricted combinations of notes that can be played simultaneously)\n",
    "- more advanced sampling/exploring for training/music generation.  This may help prevent the algorithm from getting 'stuck' on a chord, or "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
