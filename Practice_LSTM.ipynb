{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0863118\n",
      "(92, 32)\n",
      "(92, 32)\n",
      "(32,)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "#Practice Cell\n",
    "\n",
    "from tensorflow.contrib.rnn import BasicRNNCell\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "input_size = 60\n",
    "num_units = 32\n",
    "batch_size = 5\n",
    "\n",
    "state_initial = tf.zeros([batch_size, num_units])\n",
    "inputs = tf.ones([batch_size,input_size])\n",
    "\n",
    "cell = BasicRNNCell(num_units=num_units, activation=math_ops.tanh, reuse=None)\n",
    "\n",
    "out, state = cell(inputs, state_initial)\n",
    "\n",
    "func = tf.reduce_mean(out)\n",
    "gradients = tf.train.GradientDescentOptimizer(learning_rate=.01).compute_gradients(func)\n",
    "#print('cell output size: ', cell.output_size)\n",
    "#print('cell state size: ', cell.state_size)\n",
    "#print(state.get_shape())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    func_run = sess.run(func)\n",
    "    gradients_run = sess.run(gradients)\n",
    "    \n",
    "print(func_run)\n",
    "print(gradients_run[0][0].shape)\n",
    "print(gradients_run[0][1].shape)\n",
    "\n",
    "print(gradients_run[1][0].shape)\n",
    "print(gradients_run[1][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note_State_Filt Shape =  (10, 79, 128, 55)\n"
     ]
    }
   ],
   "source": [
    "#Input to Network\n",
    "\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "from MyFunctions import Input_Kernel, LSTM_TimeWise_Training_Layer, LSTM_NoteWise_Layer, Loss_Function\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Convert Entire Music .MIDI set to Tensor form 1st.  \n",
    "# During training, the amount of training data sampled will likely greatly outnumber the data we have\n",
    "# The NSB generator and Input Kernel are not trainable, it would be more efficient to just run the entire training and validation sets \n",
    "# through these functions one time at the beginning to generate a massive numpy tensor used for the model graph input.\n",
    "# However, this will make it trickier to do batches with different #time steps\n",
    "# For now: during the training loop, each iteration will involve converting the batch of .MIDI data to Note_State_Batch\n",
    "# Note_State_Batch (numpy) will be used for the placeholder input to the graph\n",
    "\n",
    "\n",
    "#Note State Batch (NSB) Generator\n",
    "Midi_high = 102\n",
    "Midi_low = 24\n",
    "batch_size = 10\n",
    "num_timesteps = 128\n",
    "num_notes = Midi_high - Midi_low + 1\n",
    "Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[batch_size, num_notes, num_timesteps])\n",
    "\n",
    "\n",
    "#Input Kernel\n",
    "input_size = 1 + 12 + 25 + 12 + 4 + 1\n",
    "Note_State_Expand = Input_Kernel(Note_State_Batch)\n",
    "\n",
    "print('Note_State_Filt Shape = ', Note_State_Expand.get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-wise output shape =  (10, 79, 128, 100)\n"
     ]
    }
   ],
   "source": [
    "#lSTM Time Wise Training Graph\n",
    "\n",
    "timewise_out = LSTM_TimeWise_Training_Layer(Note_State_Expand, num_units=100)\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP out shape =  (10, 79, 128, 3)\n",
      "generated samples shape =  (10, 79, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#LSTM Note Wise Graph\n",
    "\n",
    "logP_out, pa_gen_out = LSTM_NoteWise_Layer(timewise_out)\n",
    "\n",
    "\n",
    "print('logP out shape = ', logP_out.get_shape())\n",
    "print('generated samples shape = ', pa_gen_out.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "loss = Loss_Function(Note_State_Batch, logP_out)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = .1).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 79, 128)\n",
      "(10, 79, 128)\n",
      "epoch =  0 ; loss =  1.16361\n",
      "epoch =  1 ; loss =  1.1071\n",
      "epoch =  2 ; loss =  1.10074\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-4584f74bc924>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mbatch_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_notes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_timesteps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mNote_State_Batch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'; loss = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss_hist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "N_epochs = 10\n",
    "loss_hist=[]\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Note_State_Batch.get_shape())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(N_epochs):\n",
    "        \n",
    "        #Generate Note_State Batch numpy tensor\n",
    "        batch_input = np.random.randint(low=0, high=3, size=[batch_size, num_notes, num_timesteps]).astype(np.float32)\n",
    "        \n",
    "        loss_out, _ = sess.run([loss, optimizer], feed_dict={Note_State_Batch: X_train})\n",
    "        print('epoch = ', epoch, '; loss = ', loss_out)\n",
    "        loss_hist.append(loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyqjxi4hEGTV+EZEo8/+HeZ1k8WlG4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26229269f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist, label=\"Loss History\")\n",
    "plt.legend()\n",
    "plt.show\n",
    "len(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Music Generation\n",
    "\n",
    "# start with initial Note_State_Batch with 't' dimension = 1 (can still a batch of samples run in parallel)\n",
    "\n",
    "# input = initial note vector\n",
    "# for t = 1:Tsong\n",
    "#    input --> input kernel\n",
    "#    run through 1 'call' of Model LSTM with present parameters / states\n",
    "#    run through note-wise LSTM block as normally done to produce vector of generated samples\n",
    "#    input = generated samples\n",
    "#    music_sequence.append(input)\n",
    "\n",
    "# store batch of music sequences in .MIDI files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to Experiment with:\n",
    "- different T length or variable length T from batch-to-batch for training\n",
    "- categorize music, either through (unsupervised) clustering or (supervised) labeled music folders.  For clustering, the model would possibly find 'k' 'centroids' in an unsupervised manner each with its own music distribution, so during the music generation stage, 1 of these centroids would be selected for a piece of music.  \n",
    "- more advanced sampling/exploring for training/music generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93954\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([3, 3, 5], dtype=np.float32)\n",
    "#label_rest = np.array([1, 0, 0])\n",
    "#label_play_hold = np.array([0, .85, .15])\n",
    "#label_play_artic= np.array([0, .15, .85])\n",
    "\n",
    "#labels = label_play_hold\n",
    "\n",
    "softmax = tf.n.softmax(logits=logits)\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "num_classes = 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    p=sess.run(softmax)\n",
    "    loss_run = sess.run(loss\n",
    "                       )\n",
    "note_gen = np.random.choice(range(num_classes), p=p)\n",
    "\n",
    "print(loss_run)\n",
    "\n",
    "\n",
    "#Will need some sort of 'for' loop for musical generation\n",
    "#state_initial = tf.zeros([batch_size*num_notes, num_units])\n",
    "#state = LSTMStateTuple(state_initial, state_initial) #(c, h)\n",
    "#for t in range(num_timesteps):\n",
    "#    cell_inputs = Note_State_Flatten[:,:,t]\n",
    "#    out, state = lstmcell(cell_inputs, state)\n",
    "#func = tf.reduce_mean(out_unflatten)\n",
    "#gradients =  tf.train.GradientDescentOptimizer(learning_rate=.01).compute_gradients(func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
