{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0699093\n",
      "(92, 32)\n",
      "(92, 32)\n",
      "(32,)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.rnn import BasicRNNCell\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_size = 60\n",
    "num_units = 32\n",
    "batch_size = 5\n",
    "\n",
    "state_initial = tf.zeros([batch_size, num_units])\n",
    "inputs = tf.ones([batch_size,input_size])\n",
    "\n",
    "cell = BasicRNNCell(num_units=num_units, activation=math_ops.tanh, reuse=None)\n",
    "\n",
    "out, state = cell(inputs, state_initial)\n",
    "\n",
    "func = tf.reduce_mean(out)\n",
    "gradients = tf.train.GradientDescentOptimizer(learning_rate=.01).compute_gradients(func)\n",
    "#print('cell output size: ', cell.output_size)\n",
    "#print('cell state size: ', cell.state_size)\n",
    "#print(state.get_shape())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    func_run = sess.run(func)\n",
    "    gradients_run = sess.run(gradients)\n",
    "    \n",
    "print(func_run)\n",
    "print(gradients_run[0][0].shape)\n",
    "print(gradients_run[0][1].shape)\n",
    "\n",
    "print(gradients_run[1][0].shape)\n",
    "print(gradients_run[1][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_Midi shape =  (10, 79, 128, 1)\n",
      "x_pitch_class shape =  (10, 79, 128, 12)\n",
      "\n",
      "NSB flat shape (1280, 79, 1)\n",
      "x_vicinity shape =  (10, 79, 128, 25)\n",
      "\n",
      "NSB flat bool =  (1280, 79, 1)\n",
      "filt context shape =  (144, 1, 12)\n",
      "x context shape =  (10, 79, 128, 12)\n",
      "\n",
      "x beat shape =  (10, 79, 128, 4)\n",
      "\n",
      "Note_State_Filt Shape =  (10, 79, 128, 55)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# Dimensions\n",
    "batch_size = 10\n",
    "Midi_high = 102\n",
    "Midi_low = 24\n",
    "\n",
    "num_timesteps = 128\n",
    "input_size = 1 + 12 + 25 + 12 + 4 + 1\n",
    "\n",
    "num_notes = Midi_high - Midi_low + 1\n",
    "\n",
    "#Note State Batch (NSB) Generator\n",
    "Note_State_Batch = tf.placeholder(tf.float32, shape=[batch_size, num_notes, num_timesteps])\n",
    "\n",
    "# Input Kernel Pre-processing segments\n",
    "\n",
    "# MIDI note number\n",
    "Midi_indices = tf.range(start=Midi_low, limit = Midi_high+1, delta=1)\n",
    "x_Midi = tf.reshape(tf.tile(Midi_indices, multiples=[batch_size*num_timesteps]), shape=[batch_size, num_notes, num_timesteps,1])\n",
    "print('x_Midi shape = ', x_Midi.get_shape())\n",
    "\n",
    "# part_pitchclass\n",
    "Midi_pitchclasses = tf.squeeze(x_Midi % 12)\n",
    "x_pitch_class = tf.one_hot(Midi_pitchclasses, depth=12)\n",
    "print('x_pitch_class shape = ', x_pitch_class.get_shape())\n",
    "print('')\n",
    "\n",
    "# part_prev_vicinity (need to change to 1 time step in past)\n",
    "NSB_flatten = tf.reshape(Note_State_Batch, [batch_size*num_timesteps, num_notes, 1])\n",
    "filt_vicinity = tf.reshape(tf.reverse(tf.eye(25), axis=[0]), [25,1,25])\n",
    "prev_vicinity = tf.nn.conv1d(NSB_flatten, filt_vicinity, stride=1, padding='SAME')\n",
    "x_vicinity = tf.reshape(prev_vicinity, shape=[batch_size, num_notes, num_timesteps, 25])\n",
    "print('NSB flat shape', NSB_flatten.get_shape())\n",
    "print('x_vicinity shape = ', x_vicinity.get_shape())\n",
    "print('')\n",
    "\n",
    "#part_prev_context (need to change it to 1 time step in past)\n",
    "NSB_flat_bool = tf.minimum(NSB_flatten,1) # 1 if note is played, 0 if not played\n",
    "filt_context = tf.expand_dims(tf.tile(tf.reverse(tf.eye(12), axis=[0]), multiples=[(num_notes // 12)*2,1]), axis=1)\n",
    "print('NSB flat bool = ', NSB_flat_bool.get_shape())\n",
    "print('filt context shape = ', filt_context.get_shape())\n",
    "context = tf.nn.conv1d(NSB_flat_bool, filt_context, stride=1, padding='SAME')\n",
    "x_context = tf.reshape(context, shape=[batch_size, num_notes, num_timesteps, 12])\n",
    "print('x context shape = ',x_context.get_shape())\n",
    "print('')\n",
    "\n",
    "#beat\n",
    "Time_indices = tf.range(num_timesteps)\n",
    "x_Time = tf.reshape(tf.tile(Time_indices, multiples=[batch_size*num_notes]), shape=[batch_size, num_notes, num_timesteps,1])\n",
    "x_beat = tf.cast(tf.concat([x_Time%2, x_Time//2%2, x_Time//4%2, x_Time//8%2], axis=-1), dtype=tf.float32)\n",
    "print('x beat shape = ', x_beat.get_shape())\n",
    "print('')\n",
    "\n",
    "#zero\n",
    "x_zero = tf.zeros([batch_size, num_notes, num_timesteps,1])\n",
    "\n",
    "\n",
    "#Final Vector\n",
    "Note_State_Expand = tf.concat([tf.cast(x_Midi,dtype=tf.float32), x_pitch_class, x_vicinity, x_context, x_beat, x_zero], axis=-1)\n",
    "\n",
    "print('Note_State_Filt Shape = ', x.get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/while/Identity_2:0\", shape=(790, 50), dtype=float32)\n",
      "Time wise output shape:  (10, 79, 128, 50)\n"
     ]
    }
   ],
   "source": [
    "# LSTM time-wise \n",
    "# This section is the 'Model LSTM-TimeAxis' block and will run a number of LSTM cells over the time axis.\n",
    "# Every note and sample in the batch will be run in parallel with the same LSTM weights\n",
    "# The input data is 'Note_State_Filt' with dimensions batch_size x num_notes x num_timesteps x input_size\n",
    "# The output will be 'Hid_State_Final' with dimensions batch_size x num_notes x num_timesteps x num_units\n",
    "\n",
    "\n",
    "num_units = 50\n",
    "\n",
    "\n",
    "# Reshape the input\n",
    "# batch_size and num_notes dimensions of input are flattened to treat as single 'batch' dimension for LSTM cell\n",
    "# will be reshaped at the end of this block for the next stage\n",
    "Note_State_Expand_Flatten = tf.reshape(Note_State_Expand, shape=[batch_size*num_notes, num_timesteps, input_size])\n",
    "\n",
    "\n",
    "#Instantiate Time-Wise Cell\n",
    "lstmcell_time = BasicLSTMCell(num_units=num_units, forget_bias=1.0, state_is_tuple=True,activation=math_ops.tanh, reuse=None)\n",
    "\n",
    "\n",
    "#Run through LSTM time steps and generate time-wise sequence of outputs\n",
    "out_flat, _ = tf.nn.dynamic_rnn(lstmcell_time, Note_State_Expand_Flatten, dtype=tf.float32)\n",
    "\n",
    "\n",
    "#Unflatten the 1st 2 dimensions [Lbatch, Nnotes, num_timesteps, num_units]\n",
    "timewise_out = tf.reshape(out_flat, shape=[batch_size, num_notes, num_timesteps, num_units])\n",
    "\n",
    "print('Time wise output shape: ', timewise_out.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note-wise input reshape:  (1280, 79, 50)\n",
      "Tensor(\"zeros_1:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_1:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_3:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_5:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_7:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_9:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_11:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_13:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_15:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_17:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_19:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_21:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_23:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_25:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_27:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_29:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_31:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_33:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_35:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_37:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_39:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_41:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_43:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_45:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_47:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_49:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_51:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_53:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_55:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_57:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_59:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_61:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_63:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_65:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_67:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_69:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_71:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_73:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_75:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_77:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_79:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_81:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_83:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_85:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_87:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_89:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_91:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_93:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_95:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_97:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_99:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_101:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_103:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_105:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_107:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_109:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_111:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_113:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_115:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_117:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_119:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_121:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_123:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_125:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_127:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_129:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_131:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_133:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_135:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_137:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_139:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_141:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_143:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_145:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_147:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_149:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_151:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_153:0\", shape=(1280, 3), dtype=float32)\n",
      "Tensor(\"basic_lstm_cell/add_155:0\", shape=(1280, 3), dtype=float32)\n",
      "(10, 79, 128, 3)\n",
      "(10, 79, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# LSTM note-wise\n",
    "# This section is the 'Model LSTM-Note Axis' block and runs a number of LSTM cells from low note to high note\n",
    "# A batches and time steps are run in parallel in\n",
    "# The input sequence to the LSTM cell is the hidden state output from the previous block for each note\n",
    "#  concatenated with a sampled output from the previous note step\n",
    "# The input data is 'Hid_State_Final' with dimensions batch_size x num_notes x num_timesteps x num_units\n",
    "# The output will be:\n",
    "#    - LogP with dimensions batch_size x num_notes x num_timesteps x 3\n",
    "#    - note_gen with dimensions batch_size x num_notes x num_timesteps x 1\n",
    "\n",
    "# number of outputs is number of note+articulation combinations\n",
    "#    - 0: note is not played\n",
    "#    - 1: note is played and held\n",
    "#    - 2: note is played and articulated\n",
    "\n",
    "num_class = 3\n",
    "\n",
    "# Reshape the input\n",
    "# batch_size and num_timesteps dimensions of input are flattened to treat as single 'batch' dimension for LSTM cell\n",
    "notewise_in = tf.reshape(timewise_out, [batch_size*num_timesteps, num_notes, num_units])\n",
    "print('Note-wise input reshape: ', notewise_in.shape)\n",
    "\n",
    "\n",
    "\n",
    "# For this LSTM cell, can't use tf.nn.dynamic_rnn because samples have to be generated and fed back to for subsequent notes\n",
    "# need to feed the generated output for note 'n-1' into the generation of note 'n'\n",
    "# Will use 'for' loop and call the LSTM cell each time\n",
    "\n",
    "\n",
    "#Instantiate Note-Wise Cell\n",
    "lstmcell_note = BasicLSTMCell(num_units=num_class, forget_bias=1.0, state_is_tuple=True,activation=math_ops.tanh, reuse=None)\n",
    "\n",
    "\n",
    "#Set values for initial LSTM state and sampled note\n",
    "logP_state_initial = tf.zeros([batch_size*num_timesteps, num_class])\n",
    "pa_gen_initial = tf.zeros([batch_size*num_timesteps,1])\n",
    "\n",
    "logP_n_state = LSTMStateTuple(logP_state_initial, logP_state_initial) #(c, h)\n",
    "pa_gen_n = pa_gen_initial\n",
    "\n",
    "logP_out_list=[]\n",
    "va_gen_out_list=[]\n",
    "\n",
    "#Run through notes for note-wise LSTM to obtain P(va(n) | va(<n))\n",
    "for n in range(timewise_out.shape[1]):\n",
    "    cell_inputs = tf.concat([notewise_in[:,n,:], tf.cast(pa_gen_n, dtype=tf.float32)], axis=1)\n",
    "    logP_n_out, logP_n_state = lstmcell_note(cell_inputs, logP_n_state)\n",
    "    pa_gen_n = tf.multinomial(logits=logP_n_out, num_samples=1)   \n",
    "    logP_out_list.append(logP_n_out)\n",
    "    va_gen_out_list.append(pa_gen_n)\n",
    "    \n",
    "# Convert output list to a Tensor\n",
    "logP_out = tf.reshape(tf.stack(logP_out_list, axis=1), [batch_size, num_notes, num_timesteps, num_class])\n",
    "va_gen_out = tf.reshape(tf.stack(va_gen_out_list, axis=1),  [batch_size, num_notes, num_timesteps, 1])\n",
    "    #p_note_out = tf.nn.softmax(logits=y_note_out)\n",
    "\n",
    "\n",
    "print(logP_out.get_shape())\n",
    "print(va_gen_out.get_shape())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 79, 128, 3)\n",
      "(10, 79, 128)\n",
      "(10, 79, 127, 3)\n",
      "(10, 79, 127)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Loss Function\n",
    "\n",
    "# This section is the Loss Function Block\n",
    "# y_out generates the 3x play-articulate log probabilities for each note, at every time step, for every batch\n",
    "# Input Note_State_Batch contains the actual class played for each note, at every time step, for every batch\n",
    "# The Loss Function should match up the y_out log probabilities at time 't-1' to the ground truth class at time 't'\n",
    "# Remove the following:\n",
    "#    - 1st element of Note_State Batch in 't' dimension.  This is irrelevant as a label, anyways.\n",
    "#    - last element of logP_out in 't' dimension.  There is no corresponding future Note_State_Batch element , anyways\n",
    "# y_out elements will now correspond to the Note_State_Batch elements that it is trying to predict.\n",
    "\n",
    "\n",
    "print(logP_out.get_shape())\n",
    "print(Note_State_Batch.get_shape())\n",
    "\n",
    "logP_out_align = tf.slice(logP_out, [0,0,0,0],[batch_size, num_notes, num_timesteps-1, num_class])\n",
    "Note_State_Batch_align = tf.slice(Note_State_Batch, [0,0,1],[batch_size, num_notes, num_timesteps-1])\n",
    "\n",
    "print(logP_out_align.get_shape())\n",
    "print(Note_State_Batch_align.get_shape())\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logP_out_align, labels=tf.cast(Note_State_Batch_align,dtype=tf.int64))\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = .1).minimize(loss)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 79, 128)\n",
      "(10, 79, 128)\n",
      "epoch =  0 ; loss =  1.12509\n",
      "epoch =  1 ; loss =  1.10727\n",
      "epoch =  2 ; loss =  1.1029\n",
      "epoch =  3 ; loss =  1.10188\n",
      "epoch =  4 ; loss =  1.1014\n",
      "epoch =  5 ; loss =  1.10102\n",
      "epoch =  6 ; loss =  1.10063\n",
      "epoch =  7 ; loss =  1.10007\n",
      "epoch =  8 ; loss =  1.09961\n",
      "epoch =  9 ; loss =  1.09922\n",
      "epoch =  10 ; loss =  1.09913\n",
      "epoch =  11 ; loss =  1.10096\n",
      "epoch =  12 ; loss =  1.10364\n",
      "epoch =  13 ; loss =  1.10026\n",
      "epoch =  14 ; loss =  1.09901\n",
      "epoch =  15 ; loss =  1.09878\n",
      "epoch =  16 ; loss =  1.09874\n",
      "epoch =  17 ; loss =  1.09878\n",
      "epoch =  18 ; loss =  1.09863\n",
      "epoch =  19 ; loss =  1.09846\n",
      "epoch =  20 ; loss =  1.09842\n",
      "epoch =  21 ; loss =  1.09828\n",
      "epoch =  22 ; loss =  1.09817\n",
      "epoch =  23 ; loss =  1.09804\n",
      "epoch =  24 ; loss =  1.09809\n",
      "epoch =  25 ; loss =  1.0979\n",
      "epoch =  26 ; loss =  1.09778\n",
      "epoch =  27 ; loss =  1.09763\n",
      "epoch =  28 ; loss =  1.09763\n",
      "epoch =  29 ; loss =  1.09757\n",
      "epoch =  30 ; loss =  1.09742\n",
      "epoch =  31 ; loss =  1.09734\n",
      "epoch =  32 ; loss =  1.09728\n",
      "epoch =  33 ; loss =  1.09721\n",
      "epoch =  34 ; loss =  1.09715\n",
      "epoch =  35 ; loss =  1.09705\n",
      "epoch =  36 ; loss =  1.09695\n",
      "epoch =  37 ; loss =  1.09693\n",
      "epoch =  38 ; loss =  1.09681\n",
      "epoch =  39 ; loss =  1.09671\n",
      "epoch =  40 ; loss =  1.09664\n",
      "epoch =  41 ; loss =  1.09642\n",
      "epoch =  42 ; loss =  1.09636\n",
      "epoch =  43 ; loss =  1.09628\n",
      "epoch =  44 ; loss =  1.09626\n",
      "epoch =  45 ; loss =  1.09607\n",
      "epoch =  46 ; loss =  1.09586\n",
      "epoch =  47 ; loss =  1.09616\n",
      "epoch =  48 ; loss =  1.09712\n",
      "epoch =  49 ; loss =  1.10075\n",
      "epoch =  50 ; loss =  1.10073\n",
      "epoch =  51 ; loss =  1.10369\n",
      "epoch =  52 ; loss =  1.09615\n",
      "epoch =  53 ; loss =  1.09629\n",
      "epoch =  54 ; loss =  1.09638\n",
      "epoch =  55 ; loss =  1.09691\n",
      "epoch =  56 ; loss =  1.09685\n",
      "epoch =  57 ; loss =  1.09798\n",
      "epoch =  58 ; loss =  1.0968\n",
      "epoch =  59 ; loss =  1.09737\n",
      "epoch =  60 ; loss =  1.09678\n",
      "epoch =  61 ; loss =  1.09638\n",
      "epoch =  62 ; loss =  1.09573\n",
      "epoch =  63 ; loss =  1.09614\n",
      "epoch =  64 ; loss =  1.09771\n",
      "epoch =  65 ; loss =  1.09685\n",
      "epoch =  66 ; loss =  1.09554\n",
      "epoch =  67 ; loss =  1.09502\n",
      "epoch =  68 ; loss =  1.09462\n",
      "epoch =  69 ; loss =  1.0943\n",
      "epoch =  70 ; loss =  1.09617\n",
      "epoch =  71 ; loss =  1.10246\n",
      "epoch =  72 ; loss =  1.09779\n",
      "epoch =  73 ; loss =  1.09617\n",
      "epoch =  74 ; loss =  1.09522\n",
      "epoch =  75 ; loss =  1.095\n",
      "epoch =  76 ; loss =  1.09464\n",
      "epoch =  77 ; loss =  1.09436\n",
      "epoch =  78 ; loss =  1.09414\n",
      "epoch =  79 ; loss =  1.09386\n",
      "epoch =  80 ; loss =  1.09455\n",
      "epoch =  81 ; loss =  1.099\n",
      "epoch =  82 ; loss =  1.09593\n",
      "epoch =  83 ; loss =  1.09508\n",
      "epoch =  84 ; loss =  1.09498\n",
      "epoch =  85 ; loss =  1.0957\n",
      "epoch =  86 ; loss =  1.09573\n",
      "epoch =  87 ; loss =  1.09722\n",
      "epoch =  88 ; loss =  1.09546\n",
      "epoch =  89 ; loss =  1.09603\n",
      "epoch =  90 ; loss =  1.09497\n",
      "epoch =  91 ; loss =  1.09571\n",
      "epoch =  92 ; loss =  1.09478\n",
      "epoch =  93 ; loss =  1.09638\n",
      "epoch =  94 ; loss =  1.09413\n",
      "epoch =  95 ; loss =  1.09456\n",
      "epoch =  96 ; loss =  1.09503\n",
      "epoch =  97 ; loss =  1.09852\n",
      "epoch =  98 ; loss =  1.09429\n",
      "epoch =  99 ; loss =  1.09371\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "N_epochs = 100\n",
    "loss_hist=[]\n",
    "X_train = np.random.randint(low=0, high=3, size=[batch_size, num_notes, num_timesteps]).astype(np.float32)\n",
    "print(X_train.shape)\n",
    "print(Note_State_Batch.get_shape())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(N_epochs):\n",
    "        loss_out, _ = sess.run([loss, optimizer], feed_dict={Note_State_Batch: X_train})\n",
    "        print('epoch = ', epoch, '; loss = ', loss_out)\n",
    "        loss_hist.append(loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21885c6f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist, label=\"Loss History\")\n",
    "plt.legend()\n",
    "plt.show\n",
    "len(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Music Generation\n",
    "\n",
    "# start with initial Note_State_Batch with 't' dimension = 1 (can still a batch of samples run in parallel)\n",
    "\n",
    "# input = initial note vector\n",
    "# for t = 1:Tsong\n",
    "#    input --> input kernel\n",
    "#    run through 1 'call' of Model LSTM with present parameters / states\n",
    "#    run through note-wise LSTM block as normally done to produce vector of generated samples\n",
    "#    input = generated samples\n",
    "#    music_sequence.append(input)\n",
    "\n",
    "# store batch of music sequences in .MIDI files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to Experiment with:\n",
    "- different T length or variable length T from batch-to-batch for training\n",
    "- categorize music, either through (unsupervised) clustering or (supervised) labeled music folders.  For clustering, the model would possibly find 'k' 'centroids' in an unsupervised manner each with its own music distribution, so during the music generation stage, 1 of these centroids would be selected for a piece of music.  \n",
    "- more advanced sampling/exploring for training/music generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93954\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([3, 3, 5], dtype=np.float32)\n",
    "#label_rest = np.array([1, 0, 0])\n",
    "#label_play_hold = np.array([0, .85, .15])\n",
    "#label_play_artic= np.array([0, .15, .85])\n",
    "\n",
    "#labels = label_play_hold\n",
    "\n",
    "softmax = tf.n.softmax(logits=logits)\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "num_classes = 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    p=sess.run(softmax)\n",
    "    loss_run = sess.run(loss\n",
    "                       )\n",
    "note_gen = np.random.choice(range(num_classes), p=p)\n",
    "\n",
    "print(loss_run)\n",
    "\n",
    "\n",
    "#Will need some sort of 'for' loop for musical generation\n",
    "#state_initial = tf.zeros([batch_size*num_notes, num_units])\n",
    "#state = LSTMStateTuple(state_initial, state_initial) #(c, h)\n",
    "#for t in range(num_timesteps):\n",
    "#    cell_inputs = Note_State_Flatten[:,:,t]\n",
    "#    out, state = lstmcell(cell_inputs, state)\n",
    "#func = tf.reduce_mean(out_unflatten)\n",
    "#gradients =  tf.train.GradientDescentOptimizer(learning_rate=.01).compute_gradients(func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
