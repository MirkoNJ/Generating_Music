{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note_State_Filt Shape =  (?, 79, ?, 55)\n"
     ]
    }
   ],
   "source": [
    "#Input to Network\n",
    "\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "from MyFunctions import Input_Kernel, LSTM_TimeWise_Training_Layer, LSTM_NoteWise_Layer, Loss_Function\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Convert Entire Music .MIDI set to numpy tensor form 1st.  \n",
    "# During training, the amount of training data sampled will likely greatly outnumber the data we have\n",
    "#     Since the NSB generator and Input Kernel are not trainable, it would be more computationally efficient to\n",
    "#     simply convert the entire training and validation sets of .MIDI files to a massive numpy tensor used for the model graph input.\n",
    "#     However, this will make it trickier to do batches with different #time steps\n",
    "\n",
    "# For now: during the training loop, each iteration will involve converting the batch of .MIDI data to Note_State_Batch\n",
    "# Note_State_Batch (numpy) will be used for the placeholder input to the graph\n",
    "\n",
    "\n",
    "# Model Graph: 1st stage = Input Kernel\n",
    "\n",
    "Midi_high = 102\n",
    "Midi_low = 24\n",
    "input_size = 1 + 12 + 25 + 12 + 4 + 1\n",
    "num_notes = Midi_high - Midi_low + 1\n",
    "\n",
    "#Place holder input to graph\n",
    "# shape = [num_batces x num_notes x num_time steps]\n",
    "# num_batches and num_time steps are variable lengths.  These values do not affect the model parameters\n",
    "Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None])\n",
    "\n",
    "#Generates expanded tensor input to LSTM-timewise layer\n",
    "Note_State_Expand = Input_Kernel(Note_State_Batch)\n",
    "\n",
    "print('Note_State_Filt Shape = ', Note_State_Expand.get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-wise output shape =  (?, 79, ?, 50)\n",
      "Time-wise state  =  Tensor(\"Reshape_11:0\", shape=(?, 79, 50), dtype=float32)\n",
      "Time-wise state  =  Tensor(\"Reshape_10:0\", shape=(?, 79, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#lSTM Time Wise Training Graph \n",
    "num_units=50\n",
    "timewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_notes, num_units])\n",
    "timewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_notes, num_units])\n",
    "timewise_state_in = LSTMStateTuple(timewise_h, timewise_c)\n",
    "\n",
    "#Note_State_Expand = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, input_size])\n",
    "timewise_out, timewise_state = LSTM_TimeWise_Training_Layer(input_data=Note_State_Expand, state_in=timewise_state_in)\n",
    "\n",
    "\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())\n",
    "print('Time-wise state  = ', timewise_state[0])\n",
    "print('Time-wise state  = ', timewise_state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP out shape =  (?, 79, ?, 3)\n",
      "generated samples shape =  (?, 79, ?, 1)\n"
     ]
    }
   ],
   "source": [
    "#LSTM Note Wise Graph\n",
    "\n",
    "logP_out, pa_gen_out = LSTM_NoteWise_Layer(timewise_out)\n",
    "\n",
    "\n",
    "print('logP out shape = ', logP_out.get_shape())\n",
    "print('generated samples shape = ', pa_gen_out.get_shape())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP :  Tensor(\"Reshape_13:0\", shape=(?, 79, ?, 3), dtype=float32)\n",
      "logP align:  Tensor(\"Slice:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "Note_State_Batch:  Tensor(\"Placeholder:0\", shape=(?, 79, ?), dtype=float32)\n",
      "Note_State_Batch_align:  Tensor(\"Cast_81:0\", shape=(?, ?, ?), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Loss Function and Optimizer\n",
    "\n",
    "\n",
    "loss = Loss_Function(Note_State_Batch, logP_out)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = .1).minimize(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: Trained Model\n",
      "INFO:tensorflow:Restoring parameters from model/Trained Model\n",
      "epoch =  0 ; loss =  0.395214\n",
      "epoch =  1 ; loss =  0.375831\n",
      "epoch =  2 ; loss =  0.365113\n",
      "epoch =  3 ; loss =  0.356633\n",
      "epoch =  4 ; loss =  0.3497\n",
      "epoch =  5 ; loss =  0.343747\n",
      "epoch =  6 ; loss =  0.338368\n",
      "epoch =  7 ; loss =  0.333146\n",
      "epoch =  8 ; loss =  0.327415\n",
      "epoch =  9 ; loss =  0.319794\n",
      "Model saved in file: model/Trained Model\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "N_epochs = 10\n",
    "loss_hist=[]\n",
    "restore_model_name = 'Trained Model'\n",
    "save_model_name = 'Trained Model'\n",
    "batch_size = 10\n",
    "num_timesteps = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    # try to restore the pre_trained\n",
    "    if restore_model_name is not None:\n",
    "        print(\"Load the model from: {}\".format(restore_model_name))\n",
    "        saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "    c_run = np.zeros((batch_size, num_notes, num_units))\n",
    "    h_run = np.zeros((batch_size, num_notes, num_units))\n",
    "    for epoch in range(N_epochs):\n",
    "        \n",
    "        #Generate Note_State Batch numpy tensor\n",
    "        batch_input = np.random.randint(low=0, high=1, size=[batch_size, num_notes, num_timesteps]).astype(np.float32)\n",
    "        feed_dict = {Note_State_Batch: batch_input,timewise_c: c_run, timewise_h: h_run}\n",
    "        state_run, loss_out, _ = sess.run([timewise_state, loss, optimizer], feed_dict=feed_dict)\n",
    "        c_run, h_run = state_run\n",
    "        \n",
    "        print('epoch = ', epoch, '; loss = ', loss_out)\n",
    "        loss_hist.append(loss_out)\n",
    "        \n",
    "    save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "    print(\"Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'rnn/basic_lstm_cell/kernel:0' shape=(105, 200) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/basic_lstm_cell/bias:0' shape=(200,) dtype=float32_ref>\n",
      "<tf.Variable 'basic_lstm_cell/kernel:0' shape=(54, 12) dtype=float32_ref>\n",
      "<tf.Variable 'basic_lstm_cell/bias:0' shape=(12,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "for v in range(len(tf.trainable_variables())):\n",
    "    print(tf.trainable_variables()[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQn8KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b90f20fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist, label=\"Loss History\")\n",
    "plt.legend()\n",
    "plt.show\n",
    "len(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: Trained Model\n",
      "INFO:tensorflow:Restoring parameters from model/Trained Model\n",
      "Timestep =  0\n",
      "Timestep =  50\n",
      "Timestep =  100\n",
      "Timestep =  150\n",
      "[[[0 0 2 ..., 1 0 0]\n",
      "  [0 2 0 ..., 0 2 2]\n",
      "  [0 2 1 ..., 0 2 0]\n",
      "  ..., \n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  [0 0 2 ..., 0 0 2]]\n",
      "\n",
      " [[2 0 0 ..., 2 1 0]\n",
      "  [0 0 0 ..., 2 1 2]\n",
      "  [2 2 0 ..., 2 0 0]\n",
      "  ..., \n",
      "  [0 1 0 ..., 2 0 0]\n",
      "  [0 1 2 ..., 1 2 0]\n",
      "  [0 1 0 ..., 2 2 0]]\n",
      "\n",
      " [[0 1 0 ..., 0 0 1]\n",
      "  [0 0 0 ..., 1 2 1]\n",
      "  [1 1 2 ..., 0 0 0]\n",
      "  ..., \n",
      "  [2 0 0 ..., 1 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [2 0 0 ..., 0 0 0]]\n",
      "\n",
      " ..., \n",
      " [[0 2 1 ..., 0 0 0]\n",
      "  [2 0 0 ..., 0 0 1]\n",
      "  [0 2 1 ..., 0 0 1]\n",
      "  ..., \n",
      "  [0 0 2 ..., 0 0 1]\n",
      "  [0 0 0 ..., 1 0 1]\n",
      "  [0 2 0 ..., 1 0 1]]\n",
      "\n",
      " [[0 1 1 ..., 1 2 0]\n",
      "  [0 0 0 ..., 1 1 0]\n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 2 0 ..., 1 0 0]\n",
      "  [2 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[1 1 1 ..., 1 0 1]\n",
      "  [0 0 2 ..., 2 0 0]\n",
      "  [0 1 2 ..., 1 0 1]\n",
      "  ..., \n",
      "  [0 1 0 ..., 1 0 0]\n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  [1 0 0 ..., 0 2 0]]]\n"
     ]
    }
   ],
   "source": [
    "# Music Generation\n",
    "# input = initial note vector\n",
    "# for t = 1:Tsong\n",
    "#    input --> input kernel\n",
    "#    run through 1 'call' of Model LSTM with present parameters / states\n",
    "#    run through note-wise LSTM block as normally done to produce vector of generated samples\n",
    "#    input = generated samples\n",
    "#    music_sequence.append(input)\n",
    "\n",
    "# store batch of music sequences in .MIDI files\n",
    "\n",
    "\n",
    "#Load Model\n",
    "restore_model_name = 'Trained Model'\n",
    "\n",
    "#Length of generated music\n",
    "T_gen = 200\n",
    "\n",
    "\n",
    "\n",
    "# start with initial Note_State_Batch with 't' dimension = 1 (can still a batch of samples run in parallel)\n",
    "notes_gen_initial = np.zeros((batch_size, num_notes, 1))\n",
    "notes_gen = notes_gen_initial\n",
    "c_run = np.zeros((batch_size, num_notes, num_units))\n",
    "h_run = np.zeros((batch_size, num_notes, num_units))   \n",
    "notes_gen_arr=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    print(\"Load the model from: {}\".format(restore_model_name))\n",
    "    saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "\n",
    "    for t in range(T_gen):\n",
    "        feed_dict = {Note_State_Batch: notes_gen,timewise_c: c_run, timewise_h: h_run}\n",
    "        state_run, notes_gen = np.squeeze(sess.run([timewise_state, pa_gen_out], feed_dict = feed_dict), axis=2)\n",
    "        c_run, h_run = state_run\n",
    "        notes_gen = np.squeeze(notes_gen, axis=2)\n",
    "        notes_gen_arr.append(np.squeeze(notes_gen))\n",
    "        if t % 50 == 0:\n",
    "            print('Timestep = ', t)\n",
    "    \n",
    "#notes_gen_out = np.stack(notes_gen_arr, axis=2)\n",
    "print(notes_gen_out)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to Experiment with:\n",
    "- different T length or variable length T from batch-to-batch for training\n",
    "- categorize music, either through (unsupervised) clustering or (supervised) labeled music folders.  For clustering, the model would possibly find 'k' 'centroids' in an unsupervised manner each with its own music distribution, so during the music generation stage, 1 of these centroids would be selected for a piece of music.  \n",
    "- more advanced sampling/exploring for training/music generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93954\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([3, 3, 5], dtype=np.float32)\n",
    "#label_rest = np.array([1, 0, 0])\n",
    "#label_play_hold = np.array([0, .85, .15])\n",
    "#label_play_artic= np.array([0, .15, .85])\n",
    "\n",
    "#labels = label_play_hold\n",
    "\n",
    "softmax = tf.n.softmax(logits=logits)\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "num_classes = 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    p=sess.run(softmax)\n",
    "    loss_run = sess.run(loss\n",
    "                       )\n",
    "note_gen = np.random.choice(range(num_classes), p=p)\n",
    "\n",
    "print(loss_run)\n",
    "\n",
    "\n",
    "#Will need some sort of 'for' loop for musical generation\n",
    "#state_initial = tf.zeros([batch_size*num_notes, num_units])\n",
    "#state = LSTMStateTuple(state_initial, state_initial) #(c, h)\n",
    "#for t in range(num_timesteps):\n",
    "#    cell_inputs = Note_State_Flatten[:,:,t]\n",
    "#    out, state = lstmcell(cell_inputs, state)\n",
    "#func = tf.reduce_mean(out_unflatten)\n",
    "#gradients =  tf.train.GradientDescentOptimizer(learning_rate=.01).compute_gradients(func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
