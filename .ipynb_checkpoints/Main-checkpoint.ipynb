{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape =  (?, 79, ?)\n",
      "input prev shape =  (?, 79, ?)\n",
      "latest sample shape =  (?, 79, 1)\n",
      "x_prev vicinity shape =  (?, 79, ?, 25)\n",
      "Note_State_Batch Shape =  (?, 79, ?)\n",
      "Note_State_Filt Shape =  (?, 79, ?, 55)\n"
     ]
    }
   ],
   "source": [
    "#Input to Network\n",
    "\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "from MyFunctions import Input_Kernel, LSTM_TimeWise_Training_Layer, LSTM_NoteWise_Layer, Loss_Function\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Convert Entire Music .MIDI set to numpy tensor form 1st.  \n",
    "# During training, the amount of training data sampled will likely greatly outnumber the data we have\n",
    "#     Since the NSB generator and Input Kernel are not trainable, it would be more computationally efficient to\n",
    "#     simply convert the entire training and validation sets of .MIDI files to a massive numpy tensor used for the model graph input.\n",
    "#     However, this will make it trickier to do batches with different #time steps\n",
    "\n",
    "# For now: during the training loop, each iteration will involve converting the batch of .MIDI data to Note_State_Batch\n",
    "# Note_State_Batch (numpy) will be used for the placeholder input to the graph\n",
    "\n",
    "\n",
    "# Model Graph: 1st stage = Input Kernel\n",
    "\n",
    "Midi_high = 102\n",
    "Midi_low = 24\n",
    "input_size = 1 + 12 + 25 + 12 + 4 + 1\n",
    "num_notes = Midi_high - Midi_low + 1\n",
    "\n",
    "#Place holder input to graph\n",
    "# shape = [num_batces x num_notes x num_time steps]\n",
    "# num_batches and num_time steps are variable lengths.  These values do not affect the model parameters\n",
    "#first_input_load = np.zeros((batch_size, num_notes, 1))\n",
    "#batch_input = np.random.randint(low=0, high=1, size=[batch_size, num_notes, num_timesteps]).astype(np.float32) \n",
    "\n",
    "\n",
    "Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None])\n",
    "prev_input = tf.placeholder(dtype=tf.float32, shape=[None, num_notes,1])\n",
    "#Generates expanded tensor input to LSTM-timewise layer\n",
    "Note_State_Expand, latest_input, input_data_prev = Input_Kernel(Note_State_Batch, prev_input)\n",
    "print('Note_State_Batch Shape = ', Note_State_Batch.get_shape())\n",
    "\n",
    "print('Note_State_Filt Shape = ', Note_State_Expand.get_shape())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-wise output shape =  (?, 79, ?, 50)\n",
      "Time-wise state  =  Tensor(\"Reshape_11:0\", shape=(?, 79, 50), dtype=float32)\n",
      "Time-wise state  =  Tensor(\"Reshape_10:0\", shape=(?, 79, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#lSTM Time Wise Training Graph \n",
    "num_units=50\n",
    "timewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_notes, num_units])\n",
    "timewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_notes, num_units])\n",
    "timewise_state_in = LSTMStateTuple(timewise_h, timewise_c)\n",
    "\n",
    "#Note_State_Expand = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, input_size])\n",
    "timewise_out, timewise_state = LSTM_TimeWise_Training_Layer(input_data=Note_State_Expand, state_in=timewise_state_in)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())\n",
    "print('Time-wise state  = ', timewise_state[0])\n",
    "print('Time-wise state  = ', timewise_state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP out shape =  (?, 79, ?, 3)\n",
      "generated samples shape =  (?, 79, ?, 1)\n"
     ]
    }
   ],
   "source": [
    "#LSTM Note Wise Graph\n",
    "\n",
    "logP_out, pa_gen_out = LSTM_NoteWise_Layer(timewise_out)\n",
    "\n",
    "\n",
    "print('logP out shape = ', logP_out.get_shape())\n",
    "print('generated samples shape = ', pa_gen_out.get_shape())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "\n",
    "\n",
    "loss = Loss_Function(Note_State_Batch, logP_out)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = .1).minimize(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: Trained Model\n",
      "INFO:tensorflow:Restoring parameters from model/Trained Model\n",
      "epoch =  0 ; loss =  0.423146\n",
      "epoch =  1 ; loss =  0.394728\n",
      "epoch =  2 ; loss =  0.375193\n",
      "epoch =  3 ; loss =  0.35909\n",
      "epoch =  4 ; loss =  0.345871\n",
      "epoch =  5 ; loss =  0.337265\n",
      "epoch =  6 ; loss =  0.330125\n",
      "epoch =  7 ; loss =  0.323667\n",
      "epoch =  8 ; loss =  0.318043\n",
      "epoch =  9 ; loss =  0.31354\n",
      "Model saved in file: model/Trained Model\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "N_epochs = 10\n",
    "loss_hist=[]\n",
    "restore_model_name = 'Trained Model'\n",
    "save_model_name = 'Trained Model'\n",
    "batch_size = 10\n",
    "num_timesteps = 96\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    # try to restore the pre_trained\n",
    "    if restore_model_name is not None:\n",
    "        print(\"Load the model from: {}\".format(restore_model_name))\n",
    "        saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "    c_run = np.zeros((batch_size, num_notes, num_units))\n",
    "    h_run = np.zeros((batch_size, num_notes, num_units))\n",
    "    first_input_load = np.zeros((batch_size, num_notes, 1))\n",
    "\n",
    "    for epoch in range(N_epochs):\n",
    "        \n",
    "        #Generate Note_State Batch numpy tensor (bogus data for now)\n",
    "        batch_input = np.random.randint(low=0, high=1, size=[batch_size, num_notes, num_timesteps]).astype(np.float32) \n",
    "        feed_dict = {Note_State_Batch: batch_input, timewise_c: c_run, timewise_h: h_run, prev_input: first_input_load}\n",
    "        latest_input_run, state_run, loss_run, _ = sess.run([latest_input, timewise_state, loss, optimizer], feed_dict=feed_dict)\n",
    "        c_run, h_run = state_run\n",
    "        \n",
    "        \n",
    "        print('epoch = ', epoch, '; loss = ', loss_run)\n",
    "        loss_hist.append(loss_run)\n",
    "        \n",
    "    save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "    print(\"Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'rnn/basic_lstm_cell/kernel:0' shape=(105, 200) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/basic_lstm_cell/bias:0' shape=(200,) dtype=float32_ref>\n",
      "<tf.Variable 'basic_lstm_cell/kernel:0' shape=(54, 12) dtype=float32_ref>\n",
      "<tf.Variable 'basic_lstm_cell/bias:0' shape=(12,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "for v in range(len(tf.trainable_variables())):\n",
    "    print(tf.trainable_variables()[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAQZFb+ISJBR8YuIBBkVv4hIkPn/Ker8z/E27awAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28886a72fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist, label=\"Loss History\")\n",
    "plt.legend()\n",
    "plt.show\n",
    "len(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: Trained Model\n",
      "INFO:tensorflow:Restoring parameters from model/Trained Model\n",
      "Timestep =  0\n",
      "Timestep =  50\n",
      "Timestep =  100\n",
      "Timestep =  150\n",
      "Timestep =  200\n",
      "Timestep =  250\n",
      "Timestep =  300\n",
      "Timestep =  350\n",
      "Timestep =  400\n",
      "Timestep =  450\n",
      "Timestep =  500\n",
      "Timestep =  550\n",
      "Timestep =  600\n",
      "Timestep =  650\n",
      "Timestep =  700\n",
      "Timestep =  750\n",
      "(10, 79, 768)\n"
     ]
    }
   ],
   "source": [
    "# Music Generation\n",
    "# input = initial note vector\n",
    "# for t = 1:Tsong\n",
    "#    input --> input kernel\n",
    "#    run through 1 'call' of Model LSTM with present parameters / states\n",
    "#    run through note-wise LSTM block as normally done to produce vector of generated samples\n",
    "#    input = generated samples\n",
    "#    music_sequence.append(input)\n",
    "\n",
    "# store batch of music sequences in .MIDI files\n",
    "\n",
    "\n",
    "#Load Model\n",
    "restore_model_name = 'Trained Model'\n",
    "\n",
    "#Length of generated music\n",
    "T_gen = 48*16\n",
    "batch_gen_size = 10\n",
    "\n",
    "\n",
    "# start with initial Note_State_Batch with 't' dimension = 1 (can still a batch of samples run in parallel)\n",
    "notes_gen_initial = np.zeros((batch_gen_size, num_notes, 1))\n",
    "notes_gen = notes_gen_initial\n",
    "c_run = np.zeros((batch_gen_size, num_notes, num_units))\n",
    "h_run = np.zeros((batch_gen_size, num_notes, num_units))   \n",
    "notes_gen_arr=[]\n",
    "latest_input_run = np.zeros((batch_size, num_notes, 1))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    print(\"Load the model from: {}\".format(restore_model_name))\n",
    "    saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "\n",
    "    for t in range(T_gen):\n",
    "        feed_dict = {Note_State_Batch: notes_gen,timewise_c: c_run, timewise_h: h_run, prev_input: latest_input_run}\n",
    "        latest_input_run, state_run, notes_gen = np.squeeze(sess.run([latest_input, timewise_state, pa_gen_out], feed_dict = feed_dict), axis=2)\n",
    "        c_run, h_run = state_run\n",
    "        notes_gen = np.squeeze(notes_gen, axis=2)\n",
    "        notes_gen_arr.append(np.squeeze(notes_gen))\n",
    "        if t % 50 == 0:\n",
    "            print('Timestep = ', t)\n",
    "    \n",
    "notes_gen_out = np.stack(notes_gen_arr, axis=2)\n",
    "print(notes_gen_out.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to Experiment with:\n",
    "- different T length or variable length T from batch-to-batch for training\n",
    "- categorize music, either through (unsupervised) clustering or (supervised) labeled music folders.  For clustering, the model would possibly find 'k' 'centroids' in an unsupervised manner each with its own music distribution, so during the music generation stage, 1 of these centroids would be selected for a piece of music.  \n",
    "- use encoder to reduce dimensionality of each note vector (vector of 79 notes in 1 time step), similiar to encoding the words from the tweets in homework 3 (i.e. there are restricted combinations of notes that can be played simultaneously)\n",
    "- more advanced sampling/exploring for training/music generation.  This may help prevent the algorithm from getting 'stuck' on a chord, or "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
