{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import Utils.midi_musical_matrix\n",
    "import Utils.data\n",
    "import Utils.multi_training\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "from MyFunctions import Input_Kernel, LSTM_TimeWise_Training_Layer, LSTM_NoteWise_Layer, Loss_Function\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 01Allemande\n",
      "Loaded 01Prelude\n",
      "Loaded 02Ichdankdir\n",
      "Loaded 03AchGott\n",
      "Loaded 04Allemande\n",
      "Loaded 04Bourree\n",
      "Loaded 04EsistdasHeiluns\n",
      "Loaded 04Prelude\n",
      "Loaded 05AnWasserflussen\n",
      "Loaded 06Christus\n",
      "Loaded 08Freueteuch\n",
      "Loaded 09Ermuntredich\n",
      "Loaded 10AustieferNot\n",
      "Loaded 11Jesu\n",
      "Loaded 13Alleinzudir\n",
      "Loaded 14OHerreGott\n",
      "Loaded 15ChristlaginTode\n",
      "Loaded BRAND1\n",
      "Loaded BRAND3\n",
      "Loaded BRAND43\n",
      "Loaded BRAND51\n",
      "Loaded BRAND52\n",
      "Loaded BRAND53\n",
      "Loaded BSGJG_A\n",
      "Loaded BSGJG_B\n",
      "Loaded BSGJG_C\n",
      "Loaded BSGJG_D\n",
      "Loaded BSGJG_E\n",
      "Loaded BSGJG_F\n",
      "Loaded BSGJG_G\n",
      "Loaded BSGJG_H\n",
      "Loaded BSGJG_I\n",
      "Loaded BSGJG_J\n",
      "Loaded BSGJG_K\n",
      "Loaded BSGJG_L\n",
      "Loaded can4\n",
      "Loaded cap2\n",
      "Loaded catech1\n",
      "Loaded catech10\n",
      "Loaded catech11\n",
      "Loaded catech2\n",
      "Loaded catech3\n",
      "Loaded catech4\n",
      "Loaded catech5\n",
      "Loaded catech6\n",
      "Loaded catech7\n",
      "Loaded catech8\n",
      "Loaded catech9\n",
      "Loaded catechor\n",
      "Loaded cnt1 (1)\n",
      "Loaded cnt1\n",
      "Loaded cnt2\n",
      "Loaded cnt3\n",
      "Loaded dou1\n",
      "Loaded dou2\n",
      "Loaded Fugue1 (1)\n",
      "Loaded Fugue1\n",
      "Skip bad file =  Fugue11\n",
      "Loaded Fugue12 (1)\n",
      "Skip bad file =  Fugue12\n",
      "Skip bad file =  Fugue13\n",
      "Skip bad file =  Fugue15\n",
      "Loaded Fugue16\n",
      "Loaded Fugue17\n",
      "Loaded Fugue18\n",
      "Skip bad file =  Fugue19\n",
      "Loaded Fugue2\n",
      "Loaded Fugue20\n",
      "Loaded Fugue22\n",
      "Loaded Fugue23\n",
      "Loaded Fugue24\n",
      "Loaded Fugue3 (1)\n",
      "Loaded Fugue3\n",
      "Loaded Fugue4\n",
      "Loaded Fugue5 (1)\n",
      "Loaded Fugue5\n",
      "Skip bad file =  Fugue6\n",
      "Loaded Fugue7 (1)\n",
      "Loaded Fugue7\n",
      "Loaded Fugue8 (1)\n",
      "Loaded Fugue8\n",
      "Loaded Fugue9 (1)\n",
      "Loaded Fugue9\n",
      "Loaded fuguecm\n",
      "Loaded fuguegm\n",
      "Loaded gig1\n",
      "Loaded invent1\n",
      "Loaded invent11\n",
      "Loaded invent13\n",
      "Loaded invent14\n",
      "Loaded invent15\n",
      "Loaded invent2\n",
      "Loaded invent5\n",
      "Loaded invent7\n",
      "Loaded inver1\n",
      "Loaded inver2\n",
      "Loaded mir2\n",
      "Loaded orgel19\n",
      "Loaded pre1\n",
      "Loaded prefug1\n",
      "Loaded prefug2\n",
      "Loaded prefug3\n",
      "Loaded prefug5\n",
      "Loaded prefug7\n",
      "Loaded prefug8\n",
      "Loaded Prelude1 (1)\n",
      "Loaded Prelude1\n",
      "Loaded Prelude10\n",
      "Loaded Prelude12 (1)\n",
      "Loaded Prelude12\n",
      "Skip bad file =  Prelude13\n",
      "Skip bad file =  Prelude14\n",
      "Skip bad file =  Prelude15\n",
      "Loaded Prelude16\n",
      "Skip bad file =  Prelude19\n",
      "Loaded Prelude2 (1)\n",
      "Loaded Prelude2\n",
      "Skip bad file =  Prelude20\n",
      "Loaded Prelude21\n",
      "Loaded Prelude22\n",
      "Loaded Prelude23\n",
      "Skip bad file =  Prelude24\n",
      "Loaded Prelude3 (1)\n",
      "Loaded Prelude5\n",
      "Loaded Prelude6\n",
      "Loaded Prelude7\n",
      "Loaded Prelude8 (1)\n",
      "Loaded reg1\n",
      "Loaded reg2\n",
      "Loaded schub5\n",
      "Loaded schub6\n",
      "Loaded sin2\n",
      "Loaded sinfon1 (1)\n",
      "Loaded sinfon1\n",
      "Loaded sinfon12\n",
      "Loaded sinfon14\n",
      "Loaded sinfon3\n",
      "Loaded sinfon4\n",
      "Loaded sinfon8\n",
      "Loaded sinfon9\n",
      "Loaded toccata1\n",
      "Loaded toccata2\n",
      "Loaded tri1\n",
      "Loaded tri2\n",
      "Loaded trio3a\n",
      "Loaded unfin\n",
      "\n",
      "Number of training pieces =  134\n",
      "Sample of Expanded Input Batch: shape =  (10, 78, 128, 80)\n",
      "Sample of State Input Batch: shape =  (10, 78, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "# Import All Training Data\n",
    "# Convert Entire Music .MIDI set to list of 'pieces'\n",
    "# During training runs, getPieceBatch will return a tensor for Note_State_Batch, and corresponding Note_State_Expand\n",
    "# Note_State_Expand will be fed into the graph input, and Note_State_Batch will be used for the loss function.\n",
    "\n",
    "\n",
    "Training_Midi_Folder = \"C:/Users/Paul/Neural_Networks/Project/Generating_Music/Midi_Files/Bach\"\n",
    "\n",
    "training_pieces = Utils.multi_training.loadPieces(Training_Midi_Folder)\n",
    "\n",
    "print('')\n",
    "print('Number of training pieces = ', len(training_pieces))\n",
    "sample_expand, sample_state = Utils.multi_training.getPieceBatch(training_pieces)\n",
    "sample_expand, sample_state = np.array(sample_expand), np.array(sample_state)\n",
    "\n",
    "sample_expand = np.swapaxes(sample_expand, axis1=1, axis2=2)\n",
    "sample_state = np.swapaxes(sample_state, axis1=1, axis2=2)\n",
    "\n",
    "print('Sample of Expanded Input Batch: shape = ', sample_expand.shape)\n",
    "print('Sample of State Input Batch: shape = ', sample_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_t_sample shape =  (?, 78, 1, 2)\n",
      "Note_State_Batch Placeholder Shape =  (?, 78, ?, 2)\n",
      "Note_State_Expand output Shape =  (?, 78, ?, 80)\n"
     ]
    }
   ],
   "source": [
    "# Beginning of Model Graph:\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_size = sample_expand.shape[-1]\n",
    "num_notes = sample_expand.shape[1]\n",
    "\n",
    "\n",
    "#place holder inputs\n",
    "# num_batches and num_time steps are variable lengths.  These values do not affect the model parameters\n",
    "# Dimension(0) =  num_batches. Dimension(2) = num_time_steps\n",
    "\n",
    "final_t_sample_run = np.zeros((batch_size, num_notes, 1, 2)) #start every batch with zero previous input\n",
    "\n",
    "\n",
    "        \n",
    "Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 2])\n",
    "prev_t_sample = tf.placeholder(dtype=tf.float32, shape=[None, num_notes,1,2])\n",
    "\n",
    "#Generates expanded tensor input to LSTM-timewise layer\n",
    "Note_State_Expand, final_t_sample = Input_Kernel(Note_State_Batch, prev_t_sample, Midi_low=24, Midi_high=101)\n",
    "\n",
    "print('Note_State_Batch Placeholder Shape = ', Note_State_Batch.get_shape())\n",
    "print('Note_State_Expand output Shape = ', Note_State_Expand.get_shape())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-wise output shape =  (?, 78, ?, 10)\n",
      "Time-wise state  =  Tensor(\"Reshape_10:0\", shape=(?, 78, 10), dtype=float32)\n",
      "Time-wise state  =  Tensor(\"Reshape_9:0\", shape=(?, 78, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#lSTM Time Wise Training Graph \n",
    "num_units=10\n",
    "timewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_notes, num_units])\n",
    "timewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_notes, num_units])\n",
    "timewise_state_in = LSTMStateTuple(timewise_h, timewise_c)\n",
    "\n",
    "#Note_State_Expand = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, input_size])\n",
    "timewise_out, timewise_state = LSTM_TimeWise_Training_Layer(input_data=Note_State_Expand, state_in=timewise_state_in)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())\n",
    "print('Time-wise state  = ', timewise_state[0])\n",
    "print('Time-wise state  = ', timewise_state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP out shape =  (?, 78, ?, 2, 2)\n",
      "generated samples shape =  (?, 78, ?, 2)\n"
     ]
    }
   ],
   "source": [
    "#LSTM Note Wise Graph\n",
    "#tf.reset_default_graph()\n",
    "#timewise_out = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 50])\n",
    "logP_out, pa_gen_out = LSTM_NoteWise_Layer(timewise_out)\n",
    "\n",
    "\n",
    "print('logP out shape = ', logP_out.get_shape())\n",
    "print('generated samples shape = ', pa_gen_out.get_shape())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "\n",
    "\n",
    "loss = Loss_Function(Note_State_Batch, logP_out)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 1e-2, beta1=.95, beta2=.999).minimize(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: AdamOptimizer\n",
      "INFO:tensorflow:Restoring parameters from model/AdamOptimizer\n",
      "epoch =  0 ; loss =  0.178771\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-4392fe0679b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#Generate random batch of training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_input_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_training\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPieceBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_pieces\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# not using their 'convolution' filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mbatch_input_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_input_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mbatch_input_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_input_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Neural_Networks\\Project\\Generating_Music\\Utils\\multi_training.py\u001b[0m in \u001b[0;36mgetPieceBatch\u001b[1;34m(pieces)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetPieceBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpieces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgetPieceSegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpieces\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Neural_Networks\\Project\\Generating_Music\\Utils\\multi_training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetPieceBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpieces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgetPieceSegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpieces\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Neural_Networks\\Project\\Generating_Music\\Utils\\multi_training.py\u001b[0m in \u001b[0;36mgetPieceSegment\u001b[1;34m(pieces)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mseg_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpiece_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mseg_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnoteStateMatrixToInputForm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mseg_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Neural_Networks\\Project\\Generating_Music\\Utils\\data.py\u001b[0m in \u001b[0;36mnoteStateMatrixToInputForm\u001b[1;34m(statematrix)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# NOTE: May have to transpose this or transform it in some way to make Theano like it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m#[startSentinel()] +\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0minputform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mnoteStateSingleToInputForm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatematrix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minputform\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Neural_Networks\\Project\\Generating_Music\\Utils\\data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# NOTE: May have to transpose this or transform it in some way to make Theano like it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m#[startSentinel()] +\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0minputform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mnoteStateSingleToInputForm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatematrix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minputform\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Neural_Networks\\Project\\Generating_Music\\Utils\\data.py\u001b[0m in \u001b[0;36mnoteStateSingleToInputForm\u001b[1;34m(state, time)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mbeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildBeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnoteInputForm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnote\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnoteStateMatrixToInputForm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatematrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Neural_Networks\\Project\\Generating_Music\\Utils\\data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mbeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildBeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnoteInputForm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnote\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnoteStateMatrixToInputForm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatematrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Neural_Networks\\Project\\Generating_Music\\Utils\\data.py\u001b[0m in \u001b[0;36mnoteInputForm\u001b[1;34m(note, state, context, beat)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mpart_pitchclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpitchclass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Concatenate the note states for the previous vicinity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mpart_prev_vicinity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetOrDefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnote\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mpart_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpitchclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpitchclass\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paul\\Neural_Networks\\Project\\Generating_Music\\Utils\\data.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mpart_pitchclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpitchclass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Concatenate the note states for the previous vicinity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mpart_prev_vicinity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetOrDefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnote\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mpart_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpitchclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpitchclass\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "N_epochs = 1000\n",
    "loss_hist=[]\n",
    "restore_model_name = 'AdamOptimizer'\n",
    "save_model_name = 'AdamOptimizer'\n",
    "batch_size = 10\n",
    "num_timesteps = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # try to restore the pre_trained\n",
    "    if restore_model_name is not None:\n",
    "        print(\"Load the model from: {}\".format(restore_model_name))\n",
    "        saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "    # Initial States\n",
    "    c_run = np.zeros((batch_size, num_notes, num_units)) #start every batch with zero state in LSTM time cells\n",
    "    h_run = np.zeros((batch_size, num_notes, num_units))\n",
    "    final_t_sample_run = np.zeros((batch_size, num_notes, 1, 2)) #start every batch with zero previous input\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(N_epochs):\n",
    "        \n",
    "        #Generate random batch of training data\n",
    "        _, batch_input_state = Utils.multi_training.getPieceBatch(training_pieces) # not using their 'convolution' filter\n",
    "        batch_input_state = np.array(batch_input_state)\n",
    "        batch_input_state = np.swapaxes(batch_input_state, axis1=1, axis2=2)       \n",
    "        #print('batch_input_state shape = ', batch_input_state.shape)\n",
    "\n",
    "        \n",
    "    \n",
    "        feed_dict = {Note_State_Batch: batch_input_state, timewise_c: c_run, timewise_h: h_run, prev_t_sample: final_t_sample_run}\n",
    "        state_run, loss_run, _ = sess.run([timewise_state, loss, optimizer], feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('epoch = ', epoch, '; loss = ', loss_run)\n",
    "        loss_hist.append(loss_run)\n",
    "        \n",
    "    save_path = saver.save(sess, 'model/{}'.format(save_model_name))\n",
    "    print(\"Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'rnn/basic_lstm_cell/kernel:0' shape=(90, 40) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/basic_lstm_cell/bias:0' shape=(40,) dtype=float32_ref>\n",
      "<tf.Variable 'basic_lstm_cell/kernel:0' shape=(16, 16) dtype=float32_ref>\n",
      "<tf.Variable 'basic_lstm_cell/bias:0' shape=(16,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "for v in range(len(tf.trainable_variables())):\n",
    "    print(tf.trainable_variables()[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cd88580d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist, label=\"Loss History\")\n",
    "plt.legend()\n",
    "plt.show\n",
    "len(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: AdamOptimizer\n",
      "INFO:tensorflow:Restoring parameters from model/AdamOptimizer\n",
      "Timestep =  0\n",
      "Timestep =  50\n",
      "Timestep =  100\n",
      "Timestep =  150\n",
      "Timestep =  200\n",
      "Timestep =  250\n",
      "(10, 78, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# Music Generation\n",
    "# input = initial note vector\n",
    "# for t = 1:Tsong\n",
    "#    input --> input kernel\n",
    "#    run through 1 'call' of Model LSTM with present parameters / states\n",
    "#    run through note-wise LSTM block as normally done to produce vector of generated samples\n",
    "#    input = generated samples\n",
    "#    music_sequence.append(input)\n",
    "\n",
    "# store batch of music sequences in .MIDI files\n",
    "\n",
    "\n",
    "#Load Model\n",
    "restore_model_name = 'AdamOptimizer'\n",
    "\n",
    "#Length of generated music\n",
    "T_gen = 16*16\n",
    "batch_gen_size = 10\n",
    "\n",
    "\n",
    "# start with initial Note_State_Batch with 't' dimension = 1 (can still a batch of samples run in parallel)\n",
    "notes_gen_initial = np.zeros((batch_gen_size, num_notes, 1,2))\n",
    "\n",
    "# Initial States\n",
    "notes_gen = notes_gen_initial\n",
    "c_run = np.zeros((batch_gen_size, num_notes, num_units)) # timewise states must care from 'batch' to 'batch' (single time steps)\n",
    "h_run = np.zeros((batch_gen_size, num_notes, num_units))   \n",
    "notes_gen_arr=[]\n",
    "final_t_sample_run = np.zeros((batch_size, num_notes, 1, 2))  # each time step utilizes information from previous note\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    print(\"Load the model from: {}\".format(restore_model_name))\n",
    "    saver.restore(sess, 'model/{}'.format(restore_model_name))\n",
    "    \n",
    "\n",
    "    for t in range(T_gen):\n",
    "        feed_dict = {Note_State_Batch: notes_gen_initial, timewise_c: c_run, timewise_h: h_run, prev_t_sample: final_t_sample_run}       \n",
    "        final_t_sample_run, state_run, notes_gen = np.squeeze(sess.run([final_t_sample, timewise_state, pa_gen_out], feed_dict = feed_dict), axis=2)\n",
    "        c_run, h_run = state_run\n",
    "        #print('notes_gen shape = ', notes_gen.shape)\n",
    "        #notes_gen = np.squeeze(notes_gen, axis=2)\n",
    "        notes_gen_arr.append(np.squeeze(notes_gen))\n",
    "        \n",
    "        \n",
    "        if t % 50 == 0:\n",
    "            print('Timestep = ', t)\n",
    "    \n",
    "notes_gen_out = np.stack(notes_gen_arr, axis=2)\n",
    "print(notes_gen_out.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 256, 78, 2)\n"
     ]
    }
   ],
   "source": [
    "# Save Generate Notes to .MIDI file\n",
    "\n",
    "notes_gen_out = np.swapaxes(notes_gen_out, axis1=1, axis2=2)\n",
    "print(notes_gen_out.shape)\n",
    "#_, test_batch = Utils.multi_training.getPieceBatch(training_pieces)\n",
    "\n",
    "\n",
    "#print(test_batch.shape)\n",
    "for iter in range(batch_gen_size // 3):\n",
    "    file = 'Generated_Midi_Files/AdamOptimizer' + str(iter)\n",
    "    midi_out = Utils.midi_musical_matrix.noteStateMatrixToMidi(notes_gen_out[iter,:,:,:], name=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to Experiment with:\n",
    "- different T length or variable length T from batch-to-batch for training\n",
    "- categorize music, either through (unsupervised) clustering or (supervised) labeled music folders.  For clustering, the model would possibly find 'k' 'centroids' in an unsupervised manner each with its own music distribution, so during the music generation stage, 1 of these centroids would be selected for a piece of music.  \n",
    "- use encoder to reduce dimensionality of each note vector (vector of 79 notes in 1 time step), similiar to encoding the words from the tweets in homework 3 (i.e. there are restricted combinations of notes that can be played simultaneously)\n",
    "- more advanced sampling/exploring for training/music generation.  This may help prevent the algorithm from getting 'stuck' on a chord, or "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
